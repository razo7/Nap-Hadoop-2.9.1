// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yarn_protos.proto

package org.apache.hadoop.yarn.proto;

public final class YarnProtos {
  private YarnProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  /**
   * Protobuf enum {@code hadoop.yarn.ContainerStateProto}
   */
  public enum ContainerStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>C_NEW = 1;</code>
     */
    C_NEW(0, 1),
    /**
     * <code>C_RUNNING = 2;</code>
     */
    C_RUNNING(1, 2),
    /**
     * <code>C_COMPLETE = 3;</code>
     */
    C_COMPLETE(2, 3),
    ;

    /**
     * <code>C_NEW = 1;</code>
     */
    public static final int C_NEW_VALUE = 1;
    /**
     * <code>C_RUNNING = 2;</code>
     */
    public static final int C_RUNNING_VALUE = 2;
    /**
     * <code>C_COMPLETE = 3;</code>
     */
    public static final int C_COMPLETE_VALUE = 3;


    public final int getNumber() { return value; }

    public static ContainerStateProto valueOf(int value) {
      switch (value) {
        case 1: return C_NEW;
        case 2: return C_RUNNING;
        case 3: return C_COMPLETE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ContainerStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ContainerStateProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ContainerStateProto>() {
            public ContainerStateProto findValueByNumber(int number) {
              return ContainerStateProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final ContainerStateProto[] VALUES = values();

    public static ContainerStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ContainerStateProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ContainerStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ContainerSubStateProto}
   */
  public enum ContainerSubStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CSS_SCHEDULED = 1;</code>
     *
     * <pre>
     **
     * NEW, LOCALIZING, SCHEDULED,
     * REINITIALIZING_AWAITING_KILL, RELAUNCHING,
     * </pre>
     */
    CSS_SCHEDULED(0, 1),
    /**
     * <code>CSS_RUNNING = 2;</code>
     *
     * <pre>
     **
     * RUNNING, REINITIALIZING, PAUSING, KILLING
     * </pre>
     */
    CSS_RUNNING(1, 2),
    /**
     * <code>CSS_PAUSED = 3;</code>
     *
     * <pre>
     **
     * PAUSED, RESUMING
     * </pre>
     */
    CSS_PAUSED(2, 3),
    /**
     * <code>CSS_COMPLETING = 4;</code>
     *
     * <pre>
     **
     * LOCALIZATION_FAILED, EXITED_WITH_SUCCESS,
     * EXITED_WITH_FAILURE,
     * CONTAINER_CLEANEDUP_AFTER_KILL,
     * CONTAINER_RESOURCES_CLEANINGUP
     * </pre>
     */
    CSS_COMPLETING(3, 4),
    /**
     * <code>CSS_DONE = 5;</code>
     *
     * <pre>
     **
     * DONE
     * </pre>
     */
    CSS_DONE(4, 5),
    ;

    /**
     * <code>CSS_SCHEDULED = 1;</code>
     *
     * <pre>
     **
     * NEW, LOCALIZING, SCHEDULED,
     * REINITIALIZING_AWAITING_KILL, RELAUNCHING,
     * </pre>
     */
    public static final int CSS_SCHEDULED_VALUE = 1;
    /**
     * <code>CSS_RUNNING = 2;</code>
     *
     * <pre>
     **
     * RUNNING, REINITIALIZING, PAUSING, KILLING
     * </pre>
     */
    public static final int CSS_RUNNING_VALUE = 2;
    /**
     * <code>CSS_PAUSED = 3;</code>
     *
     * <pre>
     **
     * PAUSED, RESUMING
     * </pre>
     */
    public static final int CSS_PAUSED_VALUE = 3;
    /**
     * <code>CSS_COMPLETING = 4;</code>
     *
     * <pre>
     **
     * LOCALIZATION_FAILED, EXITED_WITH_SUCCESS,
     * EXITED_WITH_FAILURE,
     * CONTAINER_CLEANEDUP_AFTER_KILL,
     * CONTAINER_RESOURCES_CLEANINGUP
     * </pre>
     */
    public static final int CSS_COMPLETING_VALUE = 4;
    /**
     * <code>CSS_DONE = 5;</code>
     *
     * <pre>
     **
     * DONE
     * </pre>
     */
    public static final int CSS_DONE_VALUE = 5;


    public final int getNumber() { return value; }

    public static ContainerSubStateProto valueOf(int value) {
      switch (value) {
        case 1: return CSS_SCHEDULED;
        case 2: return CSS_RUNNING;
        case 3: return CSS_PAUSED;
        case 4: return CSS_COMPLETING;
        case 5: return CSS_DONE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ContainerSubStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ContainerSubStateProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ContainerSubStateProto>() {
            public ContainerSubStateProto findValueByNumber(int number) {
              return ContainerSubStateProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(1);
    }

    private static final ContainerSubStateProto[] VALUES = values();

    public static ContainerSubStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ContainerSubStateProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ContainerSubStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.YarnApplicationStateProto}
   */
  public enum YarnApplicationStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>NEW = 1;</code>
     */
    NEW(0, 1),
    /**
     * <code>NEW_SAVING = 2;</code>
     */
    NEW_SAVING(1, 2),
    /**
     * <code>SUBMITTED = 3;</code>
     */
    SUBMITTED(2, 3),
    /**
     * <code>ACCEPTED = 4;</code>
     */
    ACCEPTED(3, 4),
    /**
     * <code>RUNNING = 5;</code>
     */
    RUNNING(4, 5),
    /**
     * <code>FINISHED = 6;</code>
     */
    FINISHED(5, 6),
    /**
     * <code>FAILED = 7;</code>
     */
    FAILED(6, 7),
    /**
     * <code>KILLED = 8;</code>
     */
    KILLED(7, 8),
    ;

    /**
     * <code>NEW = 1;</code>
     */
    public static final int NEW_VALUE = 1;
    /**
     * <code>NEW_SAVING = 2;</code>
     */
    public static final int NEW_SAVING_VALUE = 2;
    /**
     * <code>SUBMITTED = 3;</code>
     */
    public static final int SUBMITTED_VALUE = 3;
    /**
     * <code>ACCEPTED = 4;</code>
     */
    public static final int ACCEPTED_VALUE = 4;
    /**
     * <code>RUNNING = 5;</code>
     */
    public static final int RUNNING_VALUE = 5;
    /**
     * <code>FINISHED = 6;</code>
     */
    public static final int FINISHED_VALUE = 6;
    /**
     * <code>FAILED = 7;</code>
     */
    public static final int FAILED_VALUE = 7;
    /**
     * <code>KILLED = 8;</code>
     */
    public static final int KILLED_VALUE = 8;


    public final int getNumber() { return value; }

    public static YarnApplicationStateProto valueOf(int value) {
      switch (value) {
        case 1: return NEW;
        case 2: return NEW_SAVING;
        case 3: return SUBMITTED;
        case 4: return ACCEPTED;
        case 5: return RUNNING;
        case 6: return FINISHED;
        case 7: return FAILED;
        case 8: return KILLED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<YarnApplicationStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<YarnApplicationStateProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<YarnApplicationStateProto>() {
            public YarnApplicationStateProto findValueByNumber(int number) {
              return YarnApplicationStateProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(2);
    }

    private static final YarnApplicationStateProto[] VALUES = values();

    public static YarnApplicationStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private YarnApplicationStateProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.YarnApplicationStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.YarnApplicationAttemptStateProto}
   */
  public enum YarnApplicationAttemptStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>APP_ATTEMPT_NEW = 1;</code>
     */
    APP_ATTEMPT_NEW(0, 1),
    /**
     * <code>APP_ATTEMPT_SUBMITTED = 2;</code>
     */
    APP_ATTEMPT_SUBMITTED(1, 2),
    /**
     * <code>APP_ATTEMPT_SCHEDULED = 3;</code>
     */
    APP_ATTEMPT_SCHEDULED(2, 3),
    /**
     * <code>APP_ATTEMPT_ALLOCATED_SAVING = 4;</code>
     */
    APP_ATTEMPT_ALLOCATED_SAVING(3, 4),
    /**
     * <code>APP_ATTEMPT_ALLOCATED = 5;</code>
     */
    APP_ATTEMPT_ALLOCATED(4, 5),
    /**
     * <code>APP_ATTEMPT_LAUNCHED = 6;</code>
     */
    APP_ATTEMPT_LAUNCHED(5, 6),
    /**
     * <code>APP_ATTEMPT_FAILED = 7;</code>
     */
    APP_ATTEMPT_FAILED(6, 7),
    /**
     * <code>APP_ATTEMPT_RUNNING = 8;</code>
     */
    APP_ATTEMPT_RUNNING(7, 8),
    /**
     * <code>APP_ATTEMPT_FINISHING = 9;</code>
     */
    APP_ATTEMPT_FINISHING(8, 9),
    /**
     * <code>APP_ATTEMPT_FINISHED = 10;</code>
     */
    APP_ATTEMPT_FINISHED(9, 10),
    /**
     * <code>APP_ATTEMPT_KILLED = 11;</code>
     */
    APP_ATTEMPT_KILLED(10, 11),
    ;

    /**
     * <code>APP_ATTEMPT_NEW = 1;</code>
     */
    public static final int APP_ATTEMPT_NEW_VALUE = 1;
    /**
     * <code>APP_ATTEMPT_SUBMITTED = 2;</code>
     */
    public static final int APP_ATTEMPT_SUBMITTED_VALUE = 2;
    /**
     * <code>APP_ATTEMPT_SCHEDULED = 3;</code>
     */
    public static final int APP_ATTEMPT_SCHEDULED_VALUE = 3;
    /**
     * <code>APP_ATTEMPT_ALLOCATED_SAVING = 4;</code>
     */
    public static final int APP_ATTEMPT_ALLOCATED_SAVING_VALUE = 4;
    /**
     * <code>APP_ATTEMPT_ALLOCATED = 5;</code>
     */
    public static final int APP_ATTEMPT_ALLOCATED_VALUE = 5;
    /**
     * <code>APP_ATTEMPT_LAUNCHED = 6;</code>
     */
    public static final int APP_ATTEMPT_LAUNCHED_VALUE = 6;
    /**
     * <code>APP_ATTEMPT_FAILED = 7;</code>
     */
    public static final int APP_ATTEMPT_FAILED_VALUE = 7;
    /**
     * <code>APP_ATTEMPT_RUNNING = 8;</code>
     */
    public static final int APP_ATTEMPT_RUNNING_VALUE = 8;
    /**
     * <code>APP_ATTEMPT_FINISHING = 9;</code>
     */
    public static final int APP_ATTEMPT_FINISHING_VALUE = 9;
    /**
     * <code>APP_ATTEMPT_FINISHED = 10;</code>
     */
    public static final int APP_ATTEMPT_FINISHED_VALUE = 10;
    /**
     * <code>APP_ATTEMPT_KILLED = 11;</code>
     */
    public static final int APP_ATTEMPT_KILLED_VALUE = 11;


    public final int getNumber() { return value; }

    public static YarnApplicationAttemptStateProto valueOf(int value) {
      switch (value) {
        case 1: return APP_ATTEMPT_NEW;
        case 2: return APP_ATTEMPT_SUBMITTED;
        case 3: return APP_ATTEMPT_SCHEDULED;
        case 4: return APP_ATTEMPT_ALLOCATED_SAVING;
        case 5: return APP_ATTEMPT_ALLOCATED;
        case 6: return APP_ATTEMPT_LAUNCHED;
        case 7: return APP_ATTEMPT_FAILED;
        case 8: return APP_ATTEMPT_RUNNING;
        case 9: return APP_ATTEMPT_FINISHING;
        case 10: return APP_ATTEMPT_FINISHED;
        case 11: return APP_ATTEMPT_KILLED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<YarnApplicationAttemptStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<YarnApplicationAttemptStateProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<YarnApplicationAttemptStateProto>() {
            public YarnApplicationAttemptStateProto findValueByNumber(int number) {
              return YarnApplicationAttemptStateProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(3);
    }

    private static final YarnApplicationAttemptStateProto[] VALUES = values();

    public static YarnApplicationAttemptStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private YarnApplicationAttemptStateProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.YarnApplicationAttemptStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.FinalApplicationStatusProto}
   */
  public enum FinalApplicationStatusProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>APP_UNDEFINED = 0;</code>
     */
    APP_UNDEFINED(0, 0),
    /**
     * <code>APP_SUCCEEDED = 1;</code>
     */
    APP_SUCCEEDED(1, 1),
    /**
     * <code>APP_FAILED = 2;</code>
     */
    APP_FAILED(2, 2),
    /**
     * <code>APP_KILLED = 3;</code>
     */
    APP_KILLED(3, 3),
    /**
     * <code>APP_ENDED = 4;</code>
     */
    APP_ENDED(4, 4),
    ;

    /**
     * <code>APP_UNDEFINED = 0;</code>
     */
    public static final int APP_UNDEFINED_VALUE = 0;
    /**
     * <code>APP_SUCCEEDED = 1;</code>
     */
    public static final int APP_SUCCEEDED_VALUE = 1;
    /**
     * <code>APP_FAILED = 2;</code>
     */
    public static final int APP_FAILED_VALUE = 2;
    /**
     * <code>APP_KILLED = 3;</code>
     */
    public static final int APP_KILLED_VALUE = 3;
    /**
     * <code>APP_ENDED = 4;</code>
     */
    public static final int APP_ENDED_VALUE = 4;


    public final int getNumber() { return value; }

    public static FinalApplicationStatusProto valueOf(int value) {
      switch (value) {
        case 0: return APP_UNDEFINED;
        case 1: return APP_SUCCEEDED;
        case 2: return APP_FAILED;
        case 3: return APP_KILLED;
        case 4: return APP_ENDED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<FinalApplicationStatusProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<FinalApplicationStatusProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<FinalApplicationStatusProto>() {
            public FinalApplicationStatusProto findValueByNumber(int number) {
              return FinalApplicationStatusProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(4);
    }

    private static final FinalApplicationStatusProto[] VALUES = values();

    public static FinalApplicationStatusProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private FinalApplicationStatusProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.FinalApplicationStatusProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.LocalResourceVisibilityProto}
   */
  public enum LocalResourceVisibilityProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>PUBLIC = 1;</code>
     */
    PUBLIC(0, 1),
    /**
     * <code>PRIVATE = 2;</code>
     */
    PRIVATE(1, 2),
    /**
     * <code>APPLICATION = 3;</code>
     */
    APPLICATION(2, 3),
    ;

    /**
     * <code>PUBLIC = 1;</code>
     */
    public static final int PUBLIC_VALUE = 1;
    /**
     * <code>PRIVATE = 2;</code>
     */
    public static final int PRIVATE_VALUE = 2;
    /**
     * <code>APPLICATION = 3;</code>
     */
    public static final int APPLICATION_VALUE = 3;


    public final int getNumber() { return value; }

    public static LocalResourceVisibilityProto valueOf(int value) {
      switch (value) {
        case 1: return PUBLIC;
        case 2: return PRIVATE;
        case 3: return APPLICATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<LocalResourceVisibilityProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<LocalResourceVisibilityProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<LocalResourceVisibilityProto>() {
            public LocalResourceVisibilityProto findValueByNumber(int number) {
              return LocalResourceVisibilityProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(5);
    }

    private static final LocalResourceVisibilityProto[] VALUES = values();

    public static LocalResourceVisibilityProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private LocalResourceVisibilityProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.LocalResourceVisibilityProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.LocalResourceTypeProto}
   */
  public enum LocalResourceTypeProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ARCHIVE = 1;</code>
     */
    ARCHIVE(0, 1),
    /**
     * <code>FILE = 2;</code>
     */
    FILE(1, 2),
    /**
     * <code>PATTERN = 3;</code>
     */
    PATTERN(2, 3),
    ;

    /**
     * <code>ARCHIVE = 1;</code>
     */
    public static final int ARCHIVE_VALUE = 1;
    /**
     * <code>FILE = 2;</code>
     */
    public static final int FILE_VALUE = 2;
    /**
     * <code>PATTERN = 3;</code>
     */
    public static final int PATTERN_VALUE = 3;


    public final int getNumber() { return value; }

    public static LocalResourceTypeProto valueOf(int value) {
      switch (value) {
        case 1: return ARCHIVE;
        case 2: return FILE;
        case 3: return PATTERN;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<LocalResourceTypeProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<LocalResourceTypeProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<LocalResourceTypeProto>() {
            public LocalResourceTypeProto findValueByNumber(int number) {
              return LocalResourceTypeProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(6);
    }

    private static final LocalResourceTypeProto[] VALUES = values();

    public static LocalResourceTypeProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private LocalResourceTypeProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.LocalResourceTypeProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.LogAggregationStatusProto}
   */
  public enum LogAggregationStatusProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>LOG_DISABLED = 1;</code>
     */
    LOG_DISABLED(0, 1),
    /**
     * <code>LOG_NOT_START = 2;</code>
     */
    LOG_NOT_START(1, 2),
    /**
     * <code>LOG_RUNNING = 3;</code>
     */
    LOG_RUNNING(2, 3),
    /**
     * <code>LOG_SUCCEEDED = 4;</code>
     */
    LOG_SUCCEEDED(3, 4),
    /**
     * <code>LOG_FAILED = 5;</code>
     */
    LOG_FAILED(4, 5),
    /**
     * <code>LOG_TIME_OUT = 6;</code>
     */
    LOG_TIME_OUT(5, 6),
    /**
     * <code>LOG_RUNNING_WITH_FAILURE = 7;</code>
     */
    LOG_RUNNING_WITH_FAILURE(6, 7),
    ;

    /**
     * <code>LOG_DISABLED = 1;</code>
     */
    public static final int LOG_DISABLED_VALUE = 1;
    /**
     * <code>LOG_NOT_START = 2;</code>
     */
    public static final int LOG_NOT_START_VALUE = 2;
    /**
     * <code>LOG_RUNNING = 3;</code>
     */
    public static final int LOG_RUNNING_VALUE = 3;
    /**
     * <code>LOG_SUCCEEDED = 4;</code>
     */
    public static final int LOG_SUCCEEDED_VALUE = 4;
    /**
     * <code>LOG_FAILED = 5;</code>
     */
    public static final int LOG_FAILED_VALUE = 5;
    /**
     * <code>LOG_TIME_OUT = 6;</code>
     */
    public static final int LOG_TIME_OUT_VALUE = 6;
    /**
     * <code>LOG_RUNNING_WITH_FAILURE = 7;</code>
     */
    public static final int LOG_RUNNING_WITH_FAILURE_VALUE = 7;


    public final int getNumber() { return value; }

    public static LogAggregationStatusProto valueOf(int value) {
      switch (value) {
        case 1: return LOG_DISABLED;
        case 2: return LOG_NOT_START;
        case 3: return LOG_RUNNING;
        case 4: return LOG_SUCCEEDED;
        case 5: return LOG_FAILED;
        case 6: return LOG_TIME_OUT;
        case 7: return LOG_RUNNING_WITH_FAILURE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<LogAggregationStatusProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<LogAggregationStatusProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<LogAggregationStatusProto>() {
            public LogAggregationStatusProto findValueByNumber(int number) {
              return LogAggregationStatusProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(7);
    }

    private static final LogAggregationStatusProto[] VALUES = values();

    public static LogAggregationStatusProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private LogAggregationStatusProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.LogAggregationStatusProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.NodeStateProto}
   */
  public enum NodeStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>NS_NEW = 1;</code>
     */
    NS_NEW(0, 1),
    /**
     * <code>NS_RUNNING = 2;</code>
     */
    NS_RUNNING(1, 2),
    /**
     * <code>NS_UNHEALTHY = 3;</code>
     */
    NS_UNHEALTHY(2, 3),
    /**
     * <code>NS_DECOMMISSIONED = 4;</code>
     */
    NS_DECOMMISSIONED(3, 4),
    /**
     * <code>NS_LOST = 5;</code>
     */
    NS_LOST(4, 5),
    /**
     * <code>NS_REBOOTED = 6;</code>
     */
    NS_REBOOTED(5, 6),
    /**
     * <code>NS_DECOMMISSIONING = 7;</code>
     */
    NS_DECOMMISSIONING(6, 7),
    /**
     * <code>NS_SHUTDOWN = 8;</code>
     */
    NS_SHUTDOWN(7, 8),
    ;

    /**
     * <code>NS_NEW = 1;</code>
     */
    public static final int NS_NEW_VALUE = 1;
    /**
     * <code>NS_RUNNING = 2;</code>
     */
    public static final int NS_RUNNING_VALUE = 2;
    /**
     * <code>NS_UNHEALTHY = 3;</code>
     */
    public static final int NS_UNHEALTHY_VALUE = 3;
    /**
     * <code>NS_DECOMMISSIONED = 4;</code>
     */
    public static final int NS_DECOMMISSIONED_VALUE = 4;
    /**
     * <code>NS_LOST = 5;</code>
     */
    public static final int NS_LOST_VALUE = 5;
    /**
     * <code>NS_REBOOTED = 6;</code>
     */
    public static final int NS_REBOOTED_VALUE = 6;
    /**
     * <code>NS_DECOMMISSIONING = 7;</code>
     */
    public static final int NS_DECOMMISSIONING_VALUE = 7;
    /**
     * <code>NS_SHUTDOWN = 8;</code>
     */
    public static final int NS_SHUTDOWN_VALUE = 8;


    public final int getNumber() { return value; }

    public static NodeStateProto valueOf(int value) {
      switch (value) {
        case 1: return NS_NEW;
        case 2: return NS_RUNNING;
        case 3: return NS_UNHEALTHY;
        case 4: return NS_DECOMMISSIONED;
        case 5: return NS_LOST;
        case 6: return NS_REBOOTED;
        case 7: return NS_DECOMMISSIONING;
        case 8: return NS_SHUTDOWN;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<NodeStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<NodeStateProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<NodeStateProto>() {
            public NodeStateProto findValueByNumber(int number) {
              return NodeStateProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(8);
    }

    private static final NodeStateProto[] VALUES = values();

    public static NodeStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private NodeStateProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.NodeStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ContainerTypeProto}
   */
  public enum ContainerTypeProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>APPLICATION_MASTER = 1;</code>
     */
    APPLICATION_MASTER(0, 1),
    /**
     * <code>TASK = 2;</code>
     */
    TASK(1, 2),
    ;

    /**
     * <code>APPLICATION_MASTER = 1;</code>
     */
    public static final int APPLICATION_MASTER_VALUE = 1;
    /**
     * <code>TASK = 2;</code>
     */
    public static final int TASK_VALUE = 2;


    public final int getNumber() { return value; }

    public static ContainerTypeProto valueOf(int value) {
      switch (value) {
        case 1: return APPLICATION_MASTER;
        case 2: return TASK;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ContainerTypeProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ContainerTypeProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ContainerTypeProto>() {
            public ContainerTypeProto findValueByNumber(int number) {
              return ContainerTypeProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(9);
    }

    private static final ContainerTypeProto[] VALUES = values();

    public static ContainerTypeProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ContainerTypeProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ContainerTypeProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ExecutionTypeProto}
   */
  public enum ExecutionTypeProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>GUARANTEED = 1;</code>
     */
    GUARANTEED(0, 1),
    /**
     * <code>OPPORTUNISTIC = 2;</code>
     */
    OPPORTUNISTIC(1, 2),
    ;

    /**
     * <code>GUARANTEED = 1;</code>
     */
    public static final int GUARANTEED_VALUE = 1;
    /**
     * <code>OPPORTUNISTIC = 2;</code>
     */
    public static final int OPPORTUNISTIC_VALUE = 2;


    public final int getNumber() { return value; }

    public static ExecutionTypeProto valueOf(int value) {
      switch (value) {
        case 1: return GUARANTEED;
        case 2: return OPPORTUNISTIC;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ExecutionTypeProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ExecutionTypeProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ExecutionTypeProto>() {
            public ExecutionTypeProto findValueByNumber(int number) {
              return ExecutionTypeProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(10);
    }

    private static final ExecutionTypeProto[] VALUES = values();

    public static ExecutionTypeProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ExecutionTypeProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ExecutionTypeProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.AMCommandProto}
   */
  public enum AMCommandProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>AM_RESYNC = 1;</code>
     */
    AM_RESYNC(0, 1),
    /**
     * <code>AM_SHUTDOWN = 2;</code>
     */
    AM_SHUTDOWN(1, 2),
    ;

    /**
     * <code>AM_RESYNC = 1;</code>
     */
    public static final int AM_RESYNC_VALUE = 1;
    /**
     * <code>AM_SHUTDOWN = 2;</code>
     */
    public static final int AM_SHUTDOWN_VALUE = 2;


    public final int getNumber() { return value; }

    public static AMCommandProto valueOf(int value) {
      switch (value) {
        case 1: return AM_RESYNC;
        case 2: return AM_SHUTDOWN;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<AMCommandProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<AMCommandProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<AMCommandProto>() {
            public AMCommandProto findValueByNumber(int number) {
              return AMCommandProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(11);
    }

    private static final AMCommandProto[] VALUES = values();

    public static AMCommandProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private AMCommandProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.AMCommandProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ApplicationTimeoutTypeProto}
   */
  public enum ApplicationTimeoutTypeProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>APP_TIMEOUT_LIFETIME = 1;</code>
     */
    APP_TIMEOUT_LIFETIME(0, 1),
    ;

    /**
     * <code>APP_TIMEOUT_LIFETIME = 1;</code>
     */
    public static final int APP_TIMEOUT_LIFETIME_VALUE = 1;


    public final int getNumber() { return value; }

    public static ApplicationTimeoutTypeProto valueOf(int value) {
      switch (value) {
        case 1: return APP_TIMEOUT_LIFETIME;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ApplicationTimeoutTypeProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ApplicationTimeoutTypeProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ApplicationTimeoutTypeProto>() {
            public ApplicationTimeoutTypeProto findValueByNumber(int number) {
              return ApplicationTimeoutTypeProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(12);
    }

    private static final ApplicationTimeoutTypeProto[] VALUES = values();

    public static ApplicationTimeoutTypeProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ApplicationTimeoutTypeProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ApplicationTimeoutTypeProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ApplicationAccessTypeProto}
   */
  public enum ApplicationAccessTypeProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>APPACCESS_VIEW_APP = 1;</code>
     */
    APPACCESS_VIEW_APP(0, 1),
    /**
     * <code>APPACCESS_MODIFY_APP = 2;</code>
     */
    APPACCESS_MODIFY_APP(1, 2),
    ;

    /**
     * <code>APPACCESS_VIEW_APP = 1;</code>
     */
    public static final int APPACCESS_VIEW_APP_VALUE = 1;
    /**
     * <code>APPACCESS_MODIFY_APP = 2;</code>
     */
    public static final int APPACCESS_MODIFY_APP_VALUE = 2;


    public final int getNumber() { return value; }

    public static ApplicationAccessTypeProto valueOf(int value) {
      switch (value) {
        case 1: return APPACCESS_VIEW_APP;
        case 2: return APPACCESS_MODIFY_APP;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ApplicationAccessTypeProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ApplicationAccessTypeProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ApplicationAccessTypeProto>() {
            public ApplicationAccessTypeProto findValueByNumber(int number) {
              return ApplicationAccessTypeProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(13);
    }

    private static final ApplicationAccessTypeProto[] VALUES = values();

    public static ApplicationAccessTypeProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ApplicationAccessTypeProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ApplicationAccessTypeProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.QueueStateProto}
   */
  public enum QueueStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>Q_STOPPED = 1;</code>
     */
    Q_STOPPED(0, 1),
    /**
     * <code>Q_RUNNING = 2;</code>
     */
    Q_RUNNING(1, 2),
    /**
     * <code>Q_DRAINING = 3;</code>
     */
    Q_DRAINING(2, 3),
    ;

    /**
     * <code>Q_STOPPED = 1;</code>
     */
    public static final int Q_STOPPED_VALUE = 1;
    /**
     * <code>Q_RUNNING = 2;</code>
     */
    public static final int Q_RUNNING_VALUE = 2;
    /**
     * <code>Q_DRAINING = 3;</code>
     */
    public static final int Q_DRAINING_VALUE = 3;


    public final int getNumber() { return value; }

    public static QueueStateProto valueOf(int value) {
      switch (value) {
        case 1: return Q_STOPPED;
        case 2: return Q_RUNNING;
        case 3: return Q_DRAINING;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<QueueStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<QueueStateProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<QueueStateProto>() {
            public QueueStateProto findValueByNumber(int number) {
              return QueueStateProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(14);
    }

    private static final QueueStateProto[] VALUES = values();

    public static QueueStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private QueueStateProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.QueueStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.QueueACLProto}
   */
  public enum QueueACLProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>QACL_SUBMIT_APPLICATIONS = 1;</code>
     */
    QACL_SUBMIT_APPLICATIONS(0, 1),
    /**
     * <code>QACL_ADMINISTER_QUEUE = 2;</code>
     */
    QACL_ADMINISTER_QUEUE(1, 2),
    ;

    /**
     * <code>QACL_SUBMIT_APPLICATIONS = 1;</code>
     */
    public static final int QACL_SUBMIT_APPLICATIONS_VALUE = 1;
    /**
     * <code>QACL_ADMINISTER_QUEUE = 2;</code>
     */
    public static final int QACL_ADMINISTER_QUEUE_VALUE = 2;


    public final int getNumber() { return value; }

    public static QueueACLProto valueOf(int value) {
      switch (value) {
        case 1: return QACL_SUBMIT_APPLICATIONS;
        case 2: return QACL_ADMINISTER_QUEUE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<QueueACLProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<QueueACLProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<QueueACLProto>() {
            public QueueACLProto findValueByNumber(int number) {
              return QueueACLProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(15);
    }

    private static final QueueACLProto[] VALUES = values();

    public static QueueACLProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private QueueACLProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.QueueACLProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.SignalContainerCommandProto}
   */
  public enum SignalContainerCommandProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>OUTPUT_THREAD_DUMP = 1;</code>
     */
    OUTPUT_THREAD_DUMP(0, 1),
    /**
     * <code>GRACEFUL_SHUTDOWN = 2;</code>
     */
    GRACEFUL_SHUTDOWN(1, 2),
    /**
     * <code>FORCEFUL_SHUTDOWN = 3;</code>
     */
    FORCEFUL_SHUTDOWN(2, 3),
    ;

    /**
     * <code>OUTPUT_THREAD_DUMP = 1;</code>
     */
    public static final int OUTPUT_THREAD_DUMP_VALUE = 1;
    /**
     * <code>GRACEFUL_SHUTDOWN = 2;</code>
     */
    public static final int GRACEFUL_SHUTDOWN_VALUE = 2;
    /**
     * <code>FORCEFUL_SHUTDOWN = 3;</code>
     */
    public static final int FORCEFUL_SHUTDOWN_VALUE = 3;


    public final int getNumber() { return value; }

    public static SignalContainerCommandProto valueOf(int value) {
      switch (value) {
        case 1: return OUTPUT_THREAD_DUMP;
        case 2: return GRACEFUL_SHUTDOWN;
        case 3: return FORCEFUL_SHUTDOWN;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<SignalContainerCommandProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<SignalContainerCommandProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<SignalContainerCommandProto>() {
            public SignalContainerCommandProto findValueByNumber(int number) {
              return SignalContainerCommandProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(16);
    }

    private static final SignalContainerCommandProto[] VALUES = values();

    public static SignalContainerCommandProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private SignalContainerCommandProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.SignalContainerCommandProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ReservationRequestInterpreterProto}
   */
  public enum ReservationRequestInterpreterProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>R_ANY = 0;</code>
     */
    R_ANY(0, 0),
    /**
     * <code>R_ALL = 1;</code>
     */
    R_ALL(1, 1),
    /**
     * <code>R_ORDER = 2;</code>
     */
    R_ORDER(2, 2),
    /**
     * <code>R_ORDER_NO_GAP = 3;</code>
     */
    R_ORDER_NO_GAP(3, 3),
    ;

    /**
     * <code>R_ANY = 0;</code>
     */
    public static final int R_ANY_VALUE = 0;
    /**
     * <code>R_ALL = 1;</code>
     */
    public static final int R_ALL_VALUE = 1;
    /**
     * <code>R_ORDER = 2;</code>
     */
    public static final int R_ORDER_VALUE = 2;
    /**
     * <code>R_ORDER_NO_GAP = 3;</code>
     */
    public static final int R_ORDER_NO_GAP_VALUE = 3;


    public final int getNumber() { return value; }

    public static ReservationRequestInterpreterProto valueOf(int value) {
      switch (value) {
        case 0: return R_ANY;
        case 1: return R_ALL;
        case 2: return R_ORDER;
        case 3: return R_ORDER_NO_GAP;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ReservationRequestInterpreterProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ReservationRequestInterpreterProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ReservationRequestInterpreterProto>() {
            public ReservationRequestInterpreterProto findValueByNumber(int number) {
              return ReservationRequestInterpreterProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(17);
    }

    private static final ReservationRequestInterpreterProto[] VALUES = values();

    public static ReservationRequestInterpreterProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ReservationRequestInterpreterProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ReservationRequestInterpreterProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ContainerExitStatusProto}
   */
  public enum ContainerExitStatusProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>SUCCESS = 0;</code>
     */
    SUCCESS(0, 0),
    /**
     * <code>INVALID = -1000;</code>
     */
    INVALID(1, -1000),
    /**
     * <code>ABORTED = -100;</code>
     */
    ABORTED(2, -100),
    /**
     * <code>DISKS_FAILED = -101;</code>
     */
    DISKS_FAILED(3, -101),
    ;

    /**
     * <code>SUCCESS = 0;</code>
     */
    public static final int SUCCESS_VALUE = 0;
    /**
     * <code>INVALID = -1000;</code>
     */
    public static final int INVALID_VALUE = -1000;
    /**
     * <code>ABORTED = -100;</code>
     */
    public static final int ABORTED_VALUE = -100;
    /**
     * <code>DISKS_FAILED = -101;</code>
     */
    public static final int DISKS_FAILED_VALUE = -101;


    public final int getNumber() { return value; }

    public static ContainerExitStatusProto valueOf(int value) {
      switch (value) {
        case 0: return SUCCESS;
        case -1000: return INVALID;
        case -100: return ABORTED;
        case -101: return DISKS_FAILED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ContainerExitStatusProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ContainerExitStatusProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ContainerExitStatusProto>() {
            public ContainerExitStatusProto findValueByNumber(int number) {
              return ContainerExitStatusProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(18);
    }

    private static final ContainerExitStatusProto[] VALUES = values();

    public static ContainerExitStatusProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ContainerExitStatusProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ContainerExitStatusProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ContainerRetryPolicyProto}
   */
  public enum ContainerRetryPolicyProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>NEVER_RETRY = 0;</code>
     */
    NEVER_RETRY(0, 0),
    /**
     * <code>RETRY_ON_ALL_ERRORS = 1;</code>
     */
    RETRY_ON_ALL_ERRORS(1, 1),
    /**
     * <code>RETRY_ON_SPECIFIC_ERROR_CODES = 2;</code>
     */
    RETRY_ON_SPECIFIC_ERROR_CODES(2, 2),
    ;

    /**
     * <code>NEVER_RETRY = 0;</code>
     */
    public static final int NEVER_RETRY_VALUE = 0;
    /**
     * <code>RETRY_ON_ALL_ERRORS = 1;</code>
     */
    public static final int RETRY_ON_ALL_ERRORS_VALUE = 1;
    /**
     * <code>RETRY_ON_SPECIFIC_ERROR_CODES = 2;</code>
     */
    public static final int RETRY_ON_SPECIFIC_ERROR_CODES_VALUE = 2;


    public final int getNumber() { return value; }

    public static ContainerRetryPolicyProto valueOf(int value) {
      switch (value) {
        case 0: return NEVER_RETRY;
        case 1: return RETRY_ON_ALL_ERRORS;
        case 2: return RETRY_ON_SPECIFIC_ERROR_CODES;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ContainerRetryPolicyProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ContainerRetryPolicyProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ContainerRetryPolicyProto>() {
            public ContainerRetryPolicyProto findValueByNumber(int number) {
              return ContainerRetryPolicyProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(19);
    }

    private static final ContainerRetryPolicyProto[] VALUES = values();

    public static ContainerRetryPolicyProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ContainerRetryPolicyProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ContainerRetryPolicyProto)
  }

  public interface SerializedExceptionProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string message = 1;
    /**
     * <code>optional string message = 1;</code>
     */
    boolean hasMessage();
    /**
     * <code>optional string message = 1;</code>
     */
    java.lang.String getMessage();
    /**
     * <code>optional string message = 1;</code>
     */
    com.google.protobuf.ByteString
        getMessageBytes();

    // optional string trace = 2;
    /**
     * <code>optional string trace = 2;</code>
     */
    boolean hasTrace();
    /**
     * <code>optional string trace = 2;</code>
     */
    java.lang.String getTrace();
    /**
     * <code>optional string trace = 2;</code>
     */
    com.google.protobuf.ByteString
        getTraceBytes();

    // optional string class_name = 3;
    /**
     * <code>optional string class_name = 3;</code>
     */
    boolean hasClassName();
    /**
     * <code>optional string class_name = 3;</code>
     */
    java.lang.String getClassName();
    /**
     * <code>optional string class_name = 3;</code>
     */
    com.google.protobuf.ByteString
        getClassNameBytes();

    // optional .hadoop.yarn.SerializedExceptionProto cause = 4;
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    boolean hasCause();
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getCause();
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getCauseOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.SerializedExceptionProto}
   */
  public static final class SerializedExceptionProto extends
      com.google.protobuf.GeneratedMessage
      implements SerializedExceptionProtoOrBuilder {
    // Use SerializedExceptionProto.newBuilder() to construct.
    private SerializedExceptionProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SerializedExceptionProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SerializedExceptionProto defaultInstance;
    public static SerializedExceptionProto getDefaultInstance() {
      return defaultInstance;
    }

    public SerializedExceptionProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SerializedExceptionProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              message_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              trace_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              className_ = input.readBytes();
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = cause_.toBuilder();
              }
              cause_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(cause_);
                cause_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder.class);
    }

    public static com.google.protobuf.Parser<SerializedExceptionProto> PARSER =
        new com.google.protobuf.AbstractParser<SerializedExceptionProto>() {
      public SerializedExceptionProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SerializedExceptionProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SerializedExceptionProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string message = 1;
    public static final int MESSAGE_FIELD_NUMBER = 1;
    private java.lang.Object message_;
    /**
     * <code>optional string message = 1;</code>
     */
    public boolean hasMessage() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string message = 1;</code>
     */
    public java.lang.String getMessage() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          message_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string message = 1;</code>
     */
    public com.google.protobuf.ByteString
        getMessageBytes() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        message_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string trace = 2;
    public static final int TRACE_FIELD_NUMBER = 2;
    private java.lang.Object trace_;
    /**
     * <code>optional string trace = 2;</code>
     */
    public boolean hasTrace() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string trace = 2;</code>
     */
    public java.lang.String getTrace() {
      java.lang.Object ref = trace_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          trace_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string trace = 2;</code>
     */
    public com.google.protobuf.ByteString
        getTraceBytes() {
      java.lang.Object ref = trace_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        trace_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string class_name = 3;
    public static final int CLASS_NAME_FIELD_NUMBER = 3;
    private java.lang.Object className_;
    /**
     * <code>optional string class_name = 3;</code>
     */
    public boolean hasClassName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string class_name = 3;</code>
     */
    public java.lang.String getClassName() {
      java.lang.Object ref = className_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          className_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string class_name = 3;</code>
     */
    public com.google.protobuf.ByteString
        getClassNameBytes() {
      java.lang.Object ref = className_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        className_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.SerializedExceptionProto cause = 4;
    public static final int CAUSE_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto cause_;
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    public boolean hasCause() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getCause() {
      return cause_;
    }
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getCauseOrBuilder() {
      return cause_;
    }

    private void initFields() {
      message_ = "";
      trace_ = "";
      className_ = "";
      cause_ = org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getMessageBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getTraceBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getClassNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, cause_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getMessageBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getTraceBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getClassNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, cause_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto other = (org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto) obj;

      boolean result = true;
      result = result && (hasMessage() == other.hasMessage());
      if (hasMessage()) {
        result = result && getMessage()
            .equals(other.getMessage());
      }
      result = result && (hasTrace() == other.hasTrace());
      if (hasTrace()) {
        result = result && getTrace()
            .equals(other.getTrace());
      }
      result = result && (hasClassName() == other.hasClassName());
      if (hasClassName()) {
        result = result && getClassName()
            .equals(other.getClassName());
      }
      result = result && (hasCause() == other.hasCause());
      if (hasCause()) {
        result = result && getCause()
            .equals(other.getCause());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasMessage()) {
        hash = (37 * hash) + MESSAGE_FIELD_NUMBER;
        hash = (53 * hash) + getMessage().hashCode();
      }
      if (hasTrace()) {
        hash = (37 * hash) + TRACE_FIELD_NUMBER;
        hash = (53 * hash) + getTrace().hashCode();
      }
      if (hasClassName()) {
        hash = (37 * hash) + CLASS_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getClassName().hashCode();
      }
      if (hasCause()) {
        hash = (37 * hash) + CAUSE_FIELD_NUMBER;
        hash = (53 * hash) + getCause().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SerializedExceptionProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getCauseFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        message_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        trace_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        className_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (causeBuilder_ == null) {
          cause_ = org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance();
        } else {
          causeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto result = new org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.message_ = message_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.trace_ = trace_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.className_ = className_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (causeBuilder_ == null) {
          result.cause_ = cause_;
        } else {
          result.cause_ = causeBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance()) return this;
        if (other.hasMessage()) {
          bitField0_ |= 0x00000001;
          message_ = other.message_;
          onChanged();
        }
        if (other.hasTrace()) {
          bitField0_ |= 0x00000002;
          trace_ = other.trace_;
          onChanged();
        }
        if (other.hasClassName()) {
          bitField0_ |= 0x00000004;
          className_ = other.className_;
          onChanged();
        }
        if (other.hasCause()) {
          mergeCause(other.getCause());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string message = 1;
      private java.lang.Object message_ = "";
      /**
       * <code>optional string message = 1;</code>
       */
      public boolean hasMessage() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public java.lang.String getMessage() {
        java.lang.Object ref = message_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          message_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public com.google.protobuf.ByteString
          getMessageBytes() {
        java.lang.Object ref = message_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          message_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public Builder setMessage(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        message_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public Builder clearMessage() {
        bitField0_ = (bitField0_ & ~0x00000001);
        message_ = getDefaultInstance().getMessage();
        onChanged();
        return this;
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public Builder setMessageBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        message_ = value;
        onChanged();
        return this;
      }

      // optional string trace = 2;
      private java.lang.Object trace_ = "";
      /**
       * <code>optional string trace = 2;</code>
       */
      public boolean hasTrace() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public java.lang.String getTrace() {
        java.lang.Object ref = trace_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          trace_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public com.google.protobuf.ByteString
          getTraceBytes() {
        java.lang.Object ref = trace_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          trace_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public Builder setTrace(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        trace_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public Builder clearTrace() {
        bitField0_ = (bitField0_ & ~0x00000002);
        trace_ = getDefaultInstance().getTrace();
        onChanged();
        return this;
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public Builder setTraceBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        trace_ = value;
        onChanged();
        return this;
      }

      // optional string class_name = 3;
      private java.lang.Object className_ = "";
      /**
       * <code>optional string class_name = 3;</code>
       */
      public boolean hasClassName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public java.lang.String getClassName() {
        java.lang.Object ref = className_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          className_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public com.google.protobuf.ByteString
          getClassNameBytes() {
        java.lang.Object ref = className_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          className_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public Builder setClassName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        className_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public Builder clearClassName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        className_ = getDefaultInstance().getClassName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public Builder setClassNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        className_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.SerializedExceptionProto cause = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto cause_ = org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder> causeBuilder_;
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public boolean hasCause() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getCause() {
        if (causeBuilder_ == null) {
          return cause_;
        } else {
          return causeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder setCause(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto value) {
        if (causeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          cause_ = value;
          onChanged();
        } else {
          causeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder setCause(
          org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder builderForValue) {
        if (causeBuilder_ == null) {
          cause_ = builderForValue.build();
          onChanged();
        } else {
          causeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder mergeCause(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto value) {
        if (causeBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              cause_ != org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance()) {
            cause_ =
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.newBuilder(cause_).mergeFrom(value).buildPartial();
          } else {
            cause_ = value;
          }
          onChanged();
        } else {
          causeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder clearCause() {
        if (causeBuilder_ == null) {
          cause_ = org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance();
          onChanged();
        } else {
          causeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder getCauseBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getCauseFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getCauseOrBuilder() {
        if (causeBuilder_ != null) {
          return causeBuilder_.getMessageOrBuilder();
        } else {
          return cause_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder> 
          getCauseFieldBuilder() {
        if (causeBuilder_ == null) {
          causeBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder>(
                  cause_,
                  getParentForChildren(),
                  isClean());
          cause_ = null;
        }
        return causeBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SerializedExceptionProto)
    }

    static {
      defaultInstance = new SerializedExceptionProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SerializedExceptionProto)
  }

  public interface ApplicationIdProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 id = 1;
    /**
     * <code>optional int32 id = 1;</code>
     */
    boolean hasId();
    /**
     * <code>optional int32 id = 1;</code>
     */
    int getId();

    // optional int64 cluster_timestamp = 2;
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    boolean hasClusterTimestamp();
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    long getClusterTimestamp();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationIdProto}
   */
  public static final class ApplicationIdProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationIdProtoOrBuilder {
    // Use ApplicationIdProto.newBuilder() to construct.
    private ApplicationIdProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationIdProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationIdProto defaultInstance;
    public static ApplicationIdProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationIdProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              id_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              clusterTimestamp_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationIdProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationIdProto>() {
      public ApplicationIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationIdProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationIdProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 id = 1;
    public static final int ID_FIELD_NUMBER = 1;
    private int id_;
    /**
     * <code>optional int32 id = 1;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 id = 1;</code>
     */
    public int getId() {
      return id_;
    }

    // optional int64 cluster_timestamp = 2;
    public static final int CLUSTER_TIMESTAMP_FIELD_NUMBER = 2;
    private long clusterTimestamp_;
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    public boolean hasClusterTimestamp() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    public long getClusterTimestamp() {
      return clusterTimestamp_;
    }

    private void initFields() {
      id_ = 0;
      clusterTimestamp_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, clusterTimestamp_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, clusterTimestamp_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto) obj;

      boolean result = true;
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && (getId()
            == other.getId());
      }
      result = result && (hasClusterTimestamp() == other.hasClusterTimestamp());
      if (hasClusterTimestamp()) {
        result = result && (getClusterTimestamp()
            == other.getClusterTimestamp());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + getId();
      }
      if (hasClusterTimestamp()) {
        hash = (37 * hash) + CLUSTER_TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getClusterTimestamp());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        id_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        clusterTimestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.id_ = id_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.clusterTimestamp_ = clusterTimestamp_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) return this;
        if (other.hasId()) {
          setId(other.getId());
        }
        if (other.hasClusterTimestamp()) {
          setClusterTimestamp(other.getClusterTimestamp());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 id = 1;
      private int id_ ;
      /**
       * <code>optional int32 id = 1;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 id = 1;</code>
       */
      public int getId() {
        return id_;
      }
      /**
       * <code>optional int32 id = 1;</code>
       */
      public Builder setId(int value) {
        bitField0_ |= 0x00000001;
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 id = 1;</code>
       */
      public Builder clearId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        id_ = 0;
        onChanged();
        return this;
      }

      // optional int64 cluster_timestamp = 2;
      private long clusterTimestamp_ ;
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public boolean hasClusterTimestamp() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public long getClusterTimestamp() {
        return clusterTimestamp_;
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public Builder setClusterTimestamp(long value) {
        bitField0_ |= 0x00000002;
        clusterTimestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public Builder clearClusterTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000002);
        clusterTimestamp_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationIdProto)
    }

    static {
      defaultInstance = new ApplicationIdProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationIdProto)
  }

  public interface ApplicationAttemptIdProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    // optional int32 attemptId = 2;
    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    boolean hasAttemptId();
    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    int getAttemptId();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationAttemptIdProto}
   */
  public static final class ApplicationAttemptIdProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationAttemptIdProtoOrBuilder {
    // Use ApplicationAttemptIdProto.newBuilder() to construct.
    private ApplicationAttemptIdProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationAttemptIdProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationAttemptIdProto defaultInstance;
    public static ApplicationAttemptIdProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationAttemptIdProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationAttemptIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              attemptId_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationAttemptIdProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationAttemptIdProto>() {
      public ApplicationAttemptIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationAttemptIdProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationAttemptIdProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_;
    }

    // optional int32 attemptId = 2;
    public static final int ATTEMPTID_FIELD_NUMBER = 2;
    private int attemptId_;
    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    public boolean hasAttemptId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    public int getAttemptId() {
      return attemptId_;
    }

    private void initFields() {
      applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      attemptId_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, attemptId_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, attemptId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasAttemptId() == other.hasAttemptId());
      if (hasAttemptId()) {
        result = result && (getAttemptId()
            == other.getAttemptId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasAttemptId()) {
        hash = (37 * hash) + ATTEMPTID_FIELD_NUMBER;
        hash = (53 * hash) + getAttemptId();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationAttemptIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        attemptId_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.attemptId_ = attemptId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasAttemptId()) {
          setAttemptId(other.getAttemptId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  applicationId_,
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      // optional int32 attemptId = 2;
      private int attemptId_ ;
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public boolean hasAttemptId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public int getAttemptId() {
        return attemptId_;
      }
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public Builder setAttemptId(int value) {
        bitField0_ |= 0x00000002;
        attemptId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public Builder clearAttemptId() {
        bitField0_ = (bitField0_ & ~0x00000002);
        attemptId_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationAttemptIdProto)
    }

    static {
      defaultInstance = new ApplicationAttemptIdProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationAttemptIdProto)
  }

  public interface ContainerIdProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto app_id = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    boolean hasAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder();

    // optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    boolean hasAppAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getAppAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getAppAttemptIdOrBuilder();

    // optional int64 id = 3;
    /**
     * <code>optional int64 id = 3;</code>
     */
    boolean hasId();
    /**
     * <code>optional int64 id = 3;</code>
     */
    long getId();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerIdProto}
   */
  public static final class ContainerIdProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerIdProtoOrBuilder {
    // Use ContainerIdProto.newBuilder() to construct.
    private ContainerIdProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerIdProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerIdProto defaultInstance;
    public static ContainerIdProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerIdProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = appId_.toBuilder();
              }
              appId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appId_);
                appId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = appAttemptId_.toBuilder();
              }
              appAttemptId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appAttemptId_);
                appAttemptId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              id_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerIdProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerIdProto>() {
      public ContainerIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerIdProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerIdProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto app_id = 1;
    public static final int APP_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    public boolean hasAppId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
      return appId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
      return appId_;
    }

    // optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;
    public static final int APP_ATTEMPT_ID_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto appAttemptId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    public boolean hasAppAttemptId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getAppAttemptId() {
      return appAttemptId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getAppAttemptIdOrBuilder() {
      return appAttemptId_;
    }

    // optional int64 id = 3;
    public static final int ID_FIELD_NUMBER = 3;
    private long id_;
    /**
     * <code>optional int64 id = 3;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 id = 3;</code>
     */
    public long getId() {
      return id_;
    }

    private void initFields() {
      appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      appAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      id_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, appId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, appAttemptId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, id_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, appId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, appAttemptId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, id_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto) obj;

      boolean result = true;
      result = result && (hasAppId() == other.hasAppId());
      if (hasAppId()) {
        result = result && getAppId()
            .equals(other.getAppId());
      }
      result = result && (hasAppAttemptId() == other.hasAppAttemptId());
      if (hasAppAttemptId()) {
        result = result && getAppAttemptId()
            .equals(other.getAppAttemptId());
      }
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && (getId()
            == other.getId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAppId()) {
        hash = (37 * hash) + APP_ID_FIELD_NUMBER;
        hash = (53 * hash) + getAppId().hashCode();
      }
      if (hasAppAttemptId()) {
        hash = (37 * hash) + APP_ATTEMPT_ID_FIELD_NUMBER;
        hash = (53 * hash) + getAppAttemptId().hashCode();
      }
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getId());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getAppIdFieldBuilder();
          getAppAttemptIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (appIdBuilder_ == null) {
          appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (appAttemptIdBuilder_ == null) {
          appAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
        } else {
          appAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        id_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (appIdBuilder_ == null) {
          result.appId_ = appId_;
        } else {
          result.appId_ = appIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (appAttemptIdBuilder_ == null) {
          result.appAttemptId_ = appAttemptId_;
        } else {
          result.appAttemptId_ = appAttemptIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.id_ = id_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) return this;
        if (other.hasAppId()) {
          mergeAppId(other.getAppId());
        }
        if (other.hasAppAttemptId()) {
          mergeAppAttemptId(other.getAppAttemptId());
        }
        if (other.hasId()) {
          setId(other.getId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto app_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> appIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public boolean hasAppId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
        if (appIdBuilder_ == null) {
          return appId_;
        } else {
          return appIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder setAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appId_ = value;
          onChanged();
        } else {
          appIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder setAppId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (appIdBuilder_ == null) {
          appId_ = builderForValue.build();
          onChanged();
        } else {
          appIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder mergeAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              appId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            appId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(appId_).mergeFrom(value).buildPartial();
          } else {
            appId_ = value;
          }
          onChanged();
        } else {
          appIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder clearAppId() {
        if (appIdBuilder_ == null) {
          appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getAppIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAppIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
        if (appIdBuilder_ != null) {
          return appIdBuilder_.getMessageOrBuilder();
        } else {
          return appId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getAppIdFieldBuilder() {
        if (appIdBuilder_ == null) {
          appIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  appId_,
                  getParentForChildren(),
                  isClean());
          appId_ = null;
        }
        return appIdBuilder_;
      }

      // optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto appAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> appAttemptIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public boolean hasAppAttemptId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getAppAttemptId() {
        if (appAttemptIdBuilder_ == null) {
          return appAttemptId_;
        } else {
          return appAttemptIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder setAppAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (appAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appAttemptId_ = value;
          onChanged();
        } else {
          appAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder setAppAttemptId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (appAttemptIdBuilder_ == null) {
          appAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          appAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder mergeAppAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (appAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              appAttemptId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            appAttemptId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(appAttemptId_).mergeFrom(value).buildPartial();
          } else {
            appAttemptId_ = value;
          }
          onChanged();
        } else {
          appAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder clearAppAttemptId() {
        if (appAttemptIdBuilder_ == null) {
          appAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
          onChanged();
        } else {
          appAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getAppAttemptIdBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getAppAttemptIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getAppAttemptIdOrBuilder() {
        if (appAttemptIdBuilder_ != null) {
          return appAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return appAttemptId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getAppAttemptIdFieldBuilder() {
        if (appAttemptIdBuilder_ == null) {
          appAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  appAttemptId_,
                  getParentForChildren(),
                  isClean());
          appAttemptId_ = null;
        }
        return appAttemptIdBuilder_;
      }

      // optional int64 id = 3;
      private long id_ ;
      /**
       * <code>optional int64 id = 3;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 id = 3;</code>
       */
      public long getId() {
        return id_;
      }
      /**
       * <code>optional int64 id = 3;</code>
       */
      public Builder setId(long value) {
        bitField0_ |= 0x00000004;
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 id = 3;</code>
       */
      public Builder clearId() {
        bitField0_ = (bitField0_ & ~0x00000004);
        id_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerIdProto)
    }

    static {
      defaultInstance = new ContainerIdProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerIdProto)
  }

  public interface ResourceProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int64 memory = 1;
    /**
     * <code>optional int64 memory = 1;</code>
     */
    boolean hasMemory();
    /**
     * <code>optional int64 memory = 1;</code>
     */
    long getMemory();

    // optional int32 virtual_cores = 2;
    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    boolean hasVirtualCores();
    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    int getVirtualCores();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceProto}
   */
  public static final class ResourceProto extends
      com.google.protobuf.GeneratedMessage
      implements ResourceProtoOrBuilder {
    // Use ResourceProto.newBuilder() to construct.
    private ResourceProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ResourceProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ResourceProto defaultInstance;
    public static ResourceProto getDefaultInstance() {
      return defaultInstance;
    }

    public ResourceProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              memory_ = input.readInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              virtualCores_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ResourceProto> PARSER =
        new com.google.protobuf.AbstractParser<ResourceProto>() {
      public ResourceProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ResourceProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int64 memory = 1;
    public static final int MEMORY_FIELD_NUMBER = 1;
    private long memory_;
    /**
     * <code>optional int64 memory = 1;</code>
     */
    public boolean hasMemory() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int64 memory = 1;</code>
     */
    public long getMemory() {
      return memory_;
    }

    // optional int32 virtual_cores = 2;
    public static final int VIRTUAL_CORES_FIELD_NUMBER = 2;
    private int virtualCores_;
    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    public boolean hasVirtualCores() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    public int getVirtualCores() {
      return virtualCores_;
    }

    private void initFields() {
      memory_ = 0L;
      virtualCores_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt64(1, memory_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, virtualCores_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, memory_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, virtualCores_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto) obj;

      boolean result = true;
      result = result && (hasMemory() == other.hasMemory());
      if (hasMemory()) {
        result = result && (getMemory()
            == other.getMemory());
      }
      result = result && (hasVirtualCores() == other.hasVirtualCores());
      if (hasVirtualCores()) {
        result = result && (getVirtualCores()
            == other.getVirtualCores());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasMemory()) {
        hash = (37 * hash) + MEMORY_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getMemory());
      }
      if (hasVirtualCores()) {
        hash = (37 * hash) + VIRTUAL_CORES_FIELD_NUMBER;
        hash = (53 * hash) + getVirtualCores();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        memory_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        virtualCores_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.memory_ = memory_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.virtualCores_ = virtualCores_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) return this;
        if (other.hasMemory()) {
          setMemory(other.getMemory());
        }
        if (other.hasVirtualCores()) {
          setVirtualCores(other.getVirtualCores());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int64 memory = 1;
      private long memory_ ;
      /**
       * <code>optional int64 memory = 1;</code>
       */
      public boolean hasMemory() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int64 memory = 1;</code>
       */
      public long getMemory() {
        return memory_;
      }
      /**
       * <code>optional int64 memory = 1;</code>
       */
      public Builder setMemory(long value) {
        bitField0_ |= 0x00000001;
        memory_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 memory = 1;</code>
       */
      public Builder clearMemory() {
        bitField0_ = (bitField0_ & ~0x00000001);
        memory_ = 0L;
        onChanged();
        return this;
      }

      // optional int32 virtual_cores = 2;
      private int virtualCores_ ;
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public boolean hasVirtualCores() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public int getVirtualCores() {
        return virtualCores_;
      }
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public Builder setVirtualCores(int value) {
        bitField0_ |= 0x00000002;
        virtualCores_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public Builder clearVirtualCores() {
        bitField0_ = (bitField0_ & ~0x00000002);
        virtualCores_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceProto)
    }

    static {
      defaultInstance = new ResourceProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceProto)
  }

  public interface ResourceUtilizationProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 pmem = 1;
    /**
     * <code>optional int32 pmem = 1;</code>
     */
    boolean hasPmem();
    /**
     * <code>optional int32 pmem = 1;</code>
     */
    int getPmem();

    // optional int32 vmem = 2;
    /**
     * <code>optional int32 vmem = 2;</code>
     */
    boolean hasVmem();
    /**
     * <code>optional int32 vmem = 2;</code>
     */
    int getVmem();

    // optional float cpu = 3;
    /**
     * <code>optional float cpu = 3;</code>
     */
    boolean hasCpu();
    /**
     * <code>optional float cpu = 3;</code>
     */
    float getCpu();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceUtilizationProto}
   */
  public static final class ResourceUtilizationProto extends
      com.google.protobuf.GeneratedMessage
      implements ResourceUtilizationProtoOrBuilder {
    // Use ResourceUtilizationProto.newBuilder() to construct.
    private ResourceUtilizationProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ResourceUtilizationProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ResourceUtilizationProto defaultInstance;
    public static ResourceUtilizationProto getDefaultInstance() {
      return defaultInstance;
    }

    public ResourceUtilizationProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceUtilizationProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              pmem_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              vmem_ = input.readInt32();
              break;
            }
            case 29: {
              bitField0_ |= 0x00000004;
              cpu_ = input.readFloat();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceUtilizationProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceUtilizationProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ResourceUtilizationProto> PARSER =
        new com.google.protobuf.AbstractParser<ResourceUtilizationProto>() {
      public ResourceUtilizationProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ResourceUtilizationProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceUtilizationProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 pmem = 1;
    public static final int PMEM_FIELD_NUMBER = 1;
    private int pmem_;
    /**
     * <code>optional int32 pmem = 1;</code>
     */
    public boolean hasPmem() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 pmem = 1;</code>
     */
    public int getPmem() {
      return pmem_;
    }

    // optional int32 vmem = 2;
    public static final int VMEM_FIELD_NUMBER = 2;
    private int vmem_;
    /**
     * <code>optional int32 vmem = 2;</code>
     */
    public boolean hasVmem() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 vmem = 2;</code>
     */
    public int getVmem() {
      return vmem_;
    }

    // optional float cpu = 3;
    public static final int CPU_FIELD_NUMBER = 3;
    private float cpu_;
    /**
     * <code>optional float cpu = 3;</code>
     */
    public boolean hasCpu() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional float cpu = 3;</code>
     */
    public float getCpu() {
      return cpu_;
    }

    private void initFields() {
      pmem_ = 0;
      vmem_ = 0;
      cpu_ = 0F;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, pmem_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, vmem_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeFloat(3, cpu_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, pmem_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, vmem_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(3, cpu_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto) obj;

      boolean result = true;
      result = result && (hasPmem() == other.hasPmem());
      if (hasPmem()) {
        result = result && (getPmem()
            == other.getPmem());
      }
      result = result && (hasVmem() == other.hasVmem());
      if (hasVmem()) {
        result = result && (getVmem()
            == other.getVmem());
      }
      result = result && (hasCpu() == other.hasCpu());
      if (hasCpu()) {
        result = result && (Float.floatToIntBits(getCpu())    == Float.floatToIntBits(other.getCpu()));
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasPmem()) {
        hash = (37 * hash) + PMEM_FIELD_NUMBER;
        hash = (53 * hash) + getPmem();
      }
      if (hasVmem()) {
        hash = (37 * hash) + VMEM_FIELD_NUMBER;
        hash = (53 * hash) + getVmem();
      }
      if (hasCpu()) {
        hash = (37 * hash) + CPU_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getCpu());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceUtilizationProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceUtilizationProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceUtilizationProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        pmem_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        vmem_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        cpu_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceUtilizationProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.pmem_ = pmem_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.vmem_ = vmem_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.cpu_ = cpu_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance()) return this;
        if (other.hasPmem()) {
          setPmem(other.getPmem());
        }
        if (other.hasVmem()) {
          setVmem(other.getVmem());
        }
        if (other.hasCpu()) {
          setCpu(other.getCpu());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 pmem = 1;
      private int pmem_ ;
      /**
       * <code>optional int32 pmem = 1;</code>
       */
      public boolean hasPmem() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 pmem = 1;</code>
       */
      public int getPmem() {
        return pmem_;
      }
      /**
       * <code>optional int32 pmem = 1;</code>
       */
      public Builder setPmem(int value) {
        bitField0_ |= 0x00000001;
        pmem_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 pmem = 1;</code>
       */
      public Builder clearPmem() {
        bitField0_ = (bitField0_ & ~0x00000001);
        pmem_ = 0;
        onChanged();
        return this;
      }

      // optional int32 vmem = 2;
      private int vmem_ ;
      /**
       * <code>optional int32 vmem = 2;</code>
       */
      public boolean hasVmem() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 vmem = 2;</code>
       */
      public int getVmem() {
        return vmem_;
      }
      /**
       * <code>optional int32 vmem = 2;</code>
       */
      public Builder setVmem(int value) {
        bitField0_ |= 0x00000002;
        vmem_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 vmem = 2;</code>
       */
      public Builder clearVmem() {
        bitField0_ = (bitField0_ & ~0x00000002);
        vmem_ = 0;
        onChanged();
        return this;
      }

      // optional float cpu = 3;
      private float cpu_ ;
      /**
       * <code>optional float cpu = 3;</code>
       */
      public boolean hasCpu() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional float cpu = 3;</code>
       */
      public float getCpu() {
        return cpu_;
      }
      /**
       * <code>optional float cpu = 3;</code>
       */
      public Builder setCpu(float value) {
        bitField0_ |= 0x00000004;
        cpu_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float cpu = 3;</code>
       */
      public Builder clearCpu() {
        bitField0_ = (bitField0_ & ~0x00000004);
        cpu_ = 0F;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceUtilizationProto)
    }

    static {
      defaultInstance = new ResourceUtilizationProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceUtilizationProto)
  }

  public interface ResourceOptionProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ResourceProto resource = 1;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    // optional int32 over_commit_timeout = 2;
    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    boolean hasOverCommitTimeout();
    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    int getOverCommitTimeout();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceOptionProto}
   */
  public static final class ResourceOptionProto extends
      com.google.protobuf.GeneratedMessage
      implements ResourceOptionProtoOrBuilder {
    // Use ResourceOptionProto.newBuilder() to construct.
    private ResourceOptionProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ResourceOptionProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ResourceOptionProto defaultInstance;
    public static ResourceOptionProto getDefaultInstance() {
      return defaultInstance;
    }

    public ResourceOptionProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceOptionProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              overCommitTimeout_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ResourceOptionProto> PARSER =
        new com.google.protobuf.AbstractParser<ResourceOptionProto>() {
      public ResourceOptionProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ResourceOptionProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceOptionProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ResourceProto resource = 1;
    public static final int RESOURCE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional int32 over_commit_timeout = 2;
    public static final int OVER_COMMIT_TIMEOUT_FIELD_NUMBER = 2;
    private int overCommitTimeout_;
    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    public boolean hasOverCommitTimeout() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    public int getOverCommitTimeout() {
      return overCommitTimeout_;
    }

    private void initFields() {
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      overCommitTimeout_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, resource_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, overCommitTimeout_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, resource_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, overCommitTimeout_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto) obj;

      boolean result = true;
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasOverCommitTimeout() == other.hasOverCommitTimeout());
      if (hasOverCommitTimeout()) {
        result = result && (getOverCommitTimeout()
            == other.getOverCommitTimeout());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasOverCommitTimeout()) {
        hash = (37 * hash) + OVER_COMMIT_TIMEOUT_FIELD_NUMBER;
        hash = (53 * hash) + getOverCommitTimeout();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceOptionProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        overCommitTimeout_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.overCommitTimeout_ = overCommitTimeout_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance()) return this;
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasOverCommitTimeout()) {
          setOverCommitTimeout(other.getOverCommitTimeout());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ResourceProto resource = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional int32 over_commit_timeout = 2;
      private int overCommitTimeout_ ;
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public boolean hasOverCommitTimeout() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public int getOverCommitTimeout() {
        return overCommitTimeout_;
      }
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public Builder setOverCommitTimeout(int value) {
        bitField0_ |= 0x00000002;
        overCommitTimeout_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public Builder clearOverCommitTimeout() {
        bitField0_ = (bitField0_ & ~0x00000002);
        overCommitTimeout_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceOptionProto)
    }

    static {
      defaultInstance = new ResourceOptionProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceOptionProto)
  }

  public interface NodeResourceMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.NodeIdProto node_id = 1;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    // optional .hadoop.yarn.ResourceOptionProto resource_option = 2;
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    boolean hasResourceOption();
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getResourceOption();
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder getResourceOptionOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeResourceMapProto}
   */
  public static final class NodeResourceMapProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeResourceMapProtoOrBuilder {
    // Use NodeResourceMapProto.newBuilder() to construct.
    private NodeResourceMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeResourceMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeResourceMapProto defaultInstance;
    public static NodeResourceMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeResourceMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeResourceMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = resourceOption_.toBuilder();
              }
              resourceOption_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resourceOption_);
                resourceOption_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeResourceMapProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeResourceMapProto>() {
      public NodeResourceMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeResourceMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeResourceMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.NodeIdProto node_id = 1;
    public static final int NODE_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_;
    }

    // optional .hadoop.yarn.ResourceOptionProto resource_option = 2;
    public static final int RESOURCE_OPTION_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto resourceOption_;
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    public boolean hasResourceOption() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getResourceOption() {
      return resourceOption_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder getResourceOptionOrBuilder() {
      return resourceOption_;
    }

    private void initFields() {
      nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      resourceOption_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, resourceOption_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, resourceOption_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasResourceOption() == other.hasResourceOption());
      if (hasResourceOption()) {
        result = result && getResourceOption()
            .equals(other.getResourceOption());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasResourceOption()) {
        hash = (37 * hash) + RESOURCE_OPTION_FIELD_NUMBER;
        hash = (53 * hash) + getResourceOption().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeResourceMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
          getResourceOptionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (resourceOptionBuilder_ == null) {
          resourceOption_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance();
        } else {
          resourceOptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (resourceOptionBuilder_ == null) {
          result.resourceOption_ = resourceOption_;
        } else {
          result.resourceOption_ = resourceOptionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasResourceOption()) {
          mergeResourceOption(other.getResourceOption());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.NodeIdProto node_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // optional .hadoop.yarn.ResourceOptionProto resource_option = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto resourceOption_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder> resourceOptionBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public boolean hasResourceOption() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getResourceOption() {
        if (resourceOptionBuilder_ == null) {
          return resourceOption_;
        } else {
          return resourceOptionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder setResourceOption(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto value) {
        if (resourceOptionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resourceOption_ = value;
          onChanged();
        } else {
          resourceOptionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder setResourceOption(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder builderForValue) {
        if (resourceOptionBuilder_ == null) {
          resourceOption_ = builderForValue.build();
          onChanged();
        } else {
          resourceOptionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder mergeResourceOption(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto value) {
        if (resourceOptionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              resourceOption_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance()) {
            resourceOption_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.newBuilder(resourceOption_).mergeFrom(value).buildPartial();
          } else {
            resourceOption_ = value;
          }
          onChanged();
        } else {
          resourceOptionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder clearResourceOption() {
        if (resourceOptionBuilder_ == null) {
          resourceOption_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance();
          onChanged();
        } else {
          resourceOptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder getResourceOptionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getResourceOptionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder getResourceOptionOrBuilder() {
        if (resourceOptionBuilder_ != null) {
          return resourceOptionBuilder_.getMessageOrBuilder();
        } else {
          return resourceOption_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder> 
          getResourceOptionFieldBuilder() {
        if (resourceOptionBuilder_ == null) {
          resourceOptionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder>(
                  resourceOption_,
                  getParentForChildren(),
                  isClean());
          resourceOption_ = null;
        }
        return resourceOptionBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeResourceMapProto)
    }

    static {
      defaultInstance = new NodeResourceMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeResourceMapProto)
  }

  public interface PriorityProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 priority = 1;
    /**
     * <code>optional int32 priority = 1;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional int32 priority = 1;</code>
     */
    int getPriority();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PriorityProto}
   */
  public static final class PriorityProto extends
      com.google.protobuf.GeneratedMessage
      implements PriorityProtoOrBuilder {
    // Use PriorityProto.newBuilder() to construct.
    private PriorityProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private PriorityProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final PriorityProto defaultInstance;
    public static PriorityProto getDefaultInstance() {
      return defaultInstance;
    }

    public PriorityProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private PriorityProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              priority_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder.class);
    }

    public static com.google.protobuf.Parser<PriorityProto> PARSER =
        new com.google.protobuf.AbstractParser<PriorityProto>() {
      public PriorityProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PriorityProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<PriorityProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 priority = 1;
    public static final int PRIORITY_FIELD_NUMBER = 1;
    private int priority_;
    /**
     * <code>optional int32 priority = 1;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 priority = 1;</code>
     */
    public int getPriority() {
      return priority_;
    }

    private void initFields() {
      priority_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, priority_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, priority_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto) obj;

      boolean result = true;
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && (getPriority()
            == other.getPriority());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PriorityProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        priority_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.priority_ = priority_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) return this;
        if (other.hasPriority()) {
          setPriority(other.getPriority());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 priority = 1;
      private int priority_ ;
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public int getPriority() {
        return priority_;
      }
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public Builder setPriority(int value) {
        bitField0_ |= 0x00000001;
        priority_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public Builder clearPriority() {
        bitField0_ = (bitField0_ & ~0x00000001);
        priority_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PriorityProto)
    }

    static {
      defaultInstance = new PriorityProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PriorityProto)
  }

  public interface ContainerProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    boolean hasId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder();

    // optional .hadoop.yarn.NodeIdProto nodeId = 2;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    // optional string node_http_address = 3;
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    boolean hasNodeHttpAddress();
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    java.lang.String getNodeHttpAddress();
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    com.google.protobuf.ByteString
        getNodeHttpAddressBytes();

    // optional .hadoop.yarn.ResourceProto resource = 4;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    // optional .hadoop.yarn.PriorityProto priority = 5;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    // optional .hadoop.common.TokenProto container_token = 6;
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    boolean hasContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder();

    // optional .hadoop.yarn.ExecutionTypeProto execution_type = 7 [default = GUARANTEED];
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 7 [default = GUARANTEED];</code>
     */
    boolean hasExecutionType();
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 7 [default = GUARANTEED];</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType();

    // optional int64 allocation_request_id = 8 [default = -1];
    /**
     * <code>optional int64 allocation_request_id = 8 [default = -1];</code>
     */
    boolean hasAllocationRequestId();
    /**
     * <code>optional int64 allocation_request_id = 8 [default = -1];</code>
     */
    long getAllocationRequestId();

    // optional int32 version = 9 [default = 0];
    /**
     * <code>optional int32 version = 9 [default = 0];</code>
     */
    boolean hasVersion();
    /**
     * <code>optional int32 version = 9 [default = 0];</code>
     */
    int getVersion();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerProto}
   */
  public static final class ContainerProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerProtoOrBuilder {
    // Use ContainerProto.newBuilder() to construct.
    private ContainerProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerProto defaultInstance;
    public static ContainerProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = id_.toBuilder();
              }
              id_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(id_);
                id_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              nodeHttpAddress_ = input.readBytes();
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 50: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000020) == 0x00000020)) {
                subBuilder = containerToken_.toBuilder();
              }
              containerToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerToken_);
                containerToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000020;
              break;
            }
            case 56: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(7, rawValue);
              } else {
                bitField0_ |= 0x00000040;
                executionType_ = value;
              }
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              allocationRequestId_ = input.readInt64();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              version_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerProto>() {
      public ContainerProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto id = 1;
    public static final int ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
      return id_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
      return id_;
    }

    // optional .hadoop.yarn.NodeIdProto nodeId = 2;
    public static final int NODEID_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_;
    }

    // optional string node_http_address = 3;
    public static final int NODE_HTTP_ADDRESS_FIELD_NUMBER = 3;
    private java.lang.Object nodeHttpAddress_;
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    public boolean hasNodeHttpAddress() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    public java.lang.String getNodeHttpAddress() {
      java.lang.Object ref = nodeHttpAddress_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          nodeHttpAddress_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    public com.google.protobuf.ByteString
        getNodeHttpAddressBytes() {
      java.lang.Object ref = nodeHttpAddress_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nodeHttpAddress_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.ResourceProto resource = 4;
    public static final int RESOURCE_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional .hadoop.yarn.PriorityProto priority = 5;
    public static final int PRIORITY_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_;
    }

    // optional .hadoop.common.TokenProto container_token = 6;
    public static final int CONTAINER_TOKEN_FIELD_NUMBER = 6;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_;
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    public boolean hasContainerToken() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
      return containerToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
      return containerToken_;
    }

    // optional .hadoop.yarn.ExecutionTypeProto execution_type = 7 [default = GUARANTEED];
    public static final int EXECUTION_TYPE_FIELD_NUMBER = 7;
    private org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto executionType_;
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 7 [default = GUARANTEED];</code>
     */
    public boolean hasExecutionType() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 7 [default = GUARANTEED];</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType() {
      return executionType_;
    }

    // optional int64 allocation_request_id = 8 [default = -1];
    public static final int ALLOCATION_REQUEST_ID_FIELD_NUMBER = 8;
    private long allocationRequestId_;
    /**
     * <code>optional int64 allocation_request_id = 8 [default = -1];</code>
     */
    public boolean hasAllocationRequestId() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional int64 allocation_request_id = 8 [default = -1];</code>
     */
    public long getAllocationRequestId() {
      return allocationRequestId_;
    }

    // optional int32 version = 9 [default = 0];
    public static final int VERSION_FIELD_NUMBER = 9;
    private int version_;
    /**
     * <code>optional int32 version = 9 [default = 0];</code>
     */
    public boolean hasVersion() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional int32 version = 9 [default = 0];</code>
     */
    public int getVersion() {
      return version_;
    }

    private void initFields() {
      id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      nodeHttpAddress_ = "";
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
      allocationRequestId_ = -1L;
      version_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasContainerToken()) {
        if (!getContainerToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, nodeId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getNodeHttpAddressBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, resource_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, priority_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeMessage(6, containerToken_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeEnum(7, executionType_.getNumber());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeInt64(8, allocationRequestId_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeInt32(9, version_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, nodeId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getNodeHttpAddressBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, resource_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, priority_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, containerToken_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(7, executionType_.getNumber());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(8, allocationRequestId_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(9, version_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto) obj;

      boolean result = true;
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && getId()
            .equals(other.getId());
      }
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasNodeHttpAddress() == other.hasNodeHttpAddress());
      if (hasNodeHttpAddress()) {
        result = result && getNodeHttpAddress()
            .equals(other.getNodeHttpAddress());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasContainerToken() == other.hasContainerToken());
      if (hasContainerToken()) {
        result = result && getContainerToken()
            .equals(other.getContainerToken());
      }
      result = result && (hasExecutionType() == other.hasExecutionType());
      if (hasExecutionType()) {
        result = result &&
            (getExecutionType() == other.getExecutionType());
      }
      result = result && (hasAllocationRequestId() == other.hasAllocationRequestId());
      if (hasAllocationRequestId()) {
        result = result && (getAllocationRequestId()
            == other.getAllocationRequestId());
      }
      result = result && (hasVersion() == other.hasVersion());
      if (hasVersion()) {
        result = result && (getVersion()
            == other.getVersion());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + getId().hashCode();
      }
      if (hasNodeId()) {
        hash = (37 * hash) + NODEID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasNodeHttpAddress()) {
        hash = (37 * hash) + NODE_HTTP_ADDRESS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeHttpAddress().hashCode();
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasContainerToken()) {
        hash = (37 * hash) + CONTAINER_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getContainerToken().hashCode();
      }
      if (hasExecutionType()) {
        hash = (37 * hash) + EXECUTION_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getExecutionType());
      }
      if (hasAllocationRequestId()) {
        hash = (37 * hash) + ALLOCATION_REQUEST_ID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getAllocationRequestId());
      }
      if (hasVersion()) {
        hash = (37 * hash) + VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getVersion();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getIdFieldBuilder();
          getNodeIdFieldBuilder();
          getResourceFieldBuilder();
          getPriorityFieldBuilder();
          getContainerTokenFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (idBuilder_ == null) {
          id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        nodeHttpAddress_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        if (containerTokenBuilder_ == null) {
          containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
        bitField0_ = (bitField0_ & ~0x00000040);
        allocationRequestId_ = -1L;
        bitField0_ = (bitField0_ & ~0x00000080);
        version_ = 0;
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (idBuilder_ == null) {
          result.id_ = id_;
        } else {
          result.id_ = idBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.nodeHttpAddress_ = nodeHttpAddress_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        if (containerTokenBuilder_ == null) {
          result.containerToken_ = containerToken_;
        } else {
          result.containerToken_ = containerTokenBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.executionType_ = executionType_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.allocationRequestId_ = allocationRequestId_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.version_ = version_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance()) return this;
        if (other.hasId()) {
          mergeId(other.getId());
        }
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasNodeHttpAddress()) {
          bitField0_ |= 0x00000004;
          nodeHttpAddress_ = other.nodeHttpAddress_;
          onChanged();
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasContainerToken()) {
          mergeContainerToken(other.getContainerToken());
        }
        if (other.hasExecutionType()) {
          setExecutionType(other.getExecutionType());
        }
        if (other.hasAllocationRequestId()) {
          setAllocationRequestId(other.getAllocationRequestId());
        }
        if (other.hasVersion()) {
          setVersion(other.getVersion());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasContainerToken()) {
          if (!getContainerToken().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> idBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
        if (idBuilder_ == null) {
          return id_;
        } else {
          return idBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          id_ = value;
          onChanged();
        } else {
          idBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (idBuilder_ == null) {
          id_ = builderForValue.build();
          onChanged();
        } else {
          idBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder mergeId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              id_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            id_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(id_).mergeFrom(value).buildPartial();
          } else {
            id_ = value;
          }
          onChanged();
        } else {
          idBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder clearId() {
        if (idBuilder_ == null) {
          id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
        if (idBuilder_ != null) {
          return idBuilder_.getMessageOrBuilder();
        } else {
          return id_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getIdFieldBuilder() {
        if (idBuilder_ == null) {
          idBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  id_,
                  getParentForChildren(),
                  isClean());
          id_ = null;
        }
        return idBuilder_;
      }

      // optional .hadoop.yarn.NodeIdProto nodeId = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // optional string node_http_address = 3;
      private java.lang.Object nodeHttpAddress_ = "";
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public boolean hasNodeHttpAddress() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public java.lang.String getNodeHttpAddress() {
        java.lang.Object ref = nodeHttpAddress_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          nodeHttpAddress_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public com.google.protobuf.ByteString
          getNodeHttpAddressBytes() {
        java.lang.Object ref = nodeHttpAddress_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nodeHttpAddress_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public Builder setNodeHttpAddress(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        nodeHttpAddress_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public Builder clearNodeHttpAddress() {
        bitField0_ = (bitField0_ & ~0x00000004);
        nodeHttpAddress_ = getDefaultInstance().getNodeHttpAddress();
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public Builder setNodeHttpAddressBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        nodeHttpAddress_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto resource = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional .hadoop.yarn.PriorityProto priority = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  priority_,
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      // optional .hadoop.common.TokenProto container_token = 6;
      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> containerTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public boolean hasContainerToken() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
        if (containerTokenBuilder_ == null) {
          return containerToken_;
        } else {
          return containerTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder setContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerToken_ = value;
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder setContainerToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (containerTokenBuilder_ == null) {
          containerToken_ = builderForValue.build();
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder mergeContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020) &&
              containerToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            containerToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(containerToken_).mergeFrom(value).buildPartial();
          } else {
            containerToken_ = value;
          }
          onChanged();
        } else {
          containerTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder clearContainerToken() {
        if (containerTokenBuilder_ == null) {
          containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
          onChanged();
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getContainerTokenBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getContainerTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
        if (containerTokenBuilder_ != null) {
          return containerTokenBuilder_.getMessageOrBuilder();
        } else {
          return containerToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getContainerTokenFieldBuilder() {
        if (containerTokenBuilder_ == null) {
          containerTokenBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  containerToken_,
                  getParentForChildren(),
                  isClean());
          containerToken_ = null;
        }
        return containerTokenBuilder_;
      }

      // optional .hadoop.yarn.ExecutionTypeProto execution_type = 7 [default = GUARANTEED];
      private org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 7 [default = GUARANTEED];</code>
       */
      public boolean hasExecutionType() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 7 [default = GUARANTEED];</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType() {
        return executionType_;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 7 [default = GUARANTEED];</code>
       */
      public Builder setExecutionType(org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000040;
        executionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 7 [default = GUARANTEED];</code>
       */
      public Builder clearExecutionType() {
        bitField0_ = (bitField0_ & ~0x00000040);
        executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
        onChanged();
        return this;
      }

      // optional int64 allocation_request_id = 8 [default = -1];
      private long allocationRequestId_ = -1L;
      /**
       * <code>optional int64 allocation_request_id = 8 [default = -1];</code>
       */
      public boolean hasAllocationRequestId() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional int64 allocation_request_id = 8 [default = -1];</code>
       */
      public long getAllocationRequestId() {
        return allocationRequestId_;
      }
      /**
       * <code>optional int64 allocation_request_id = 8 [default = -1];</code>
       */
      public Builder setAllocationRequestId(long value) {
        bitField0_ |= 0x00000080;
        allocationRequestId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 allocation_request_id = 8 [default = -1];</code>
       */
      public Builder clearAllocationRequestId() {
        bitField0_ = (bitField0_ & ~0x00000080);
        allocationRequestId_ = -1L;
        onChanged();
        return this;
      }

      // optional int32 version = 9 [default = 0];
      private int version_ ;
      /**
       * <code>optional int32 version = 9 [default = 0];</code>
       */
      public boolean hasVersion() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional int32 version = 9 [default = 0];</code>
       */
      public int getVersion() {
        return version_;
      }
      /**
       * <code>optional int32 version = 9 [default = 0];</code>
       */
      public Builder setVersion(int value) {
        bitField0_ |= 0x00000100;
        version_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 version = 9 [default = 0];</code>
       */
      public Builder clearVersion() {
        bitField0_ = (bitField0_ & ~0x00000100);
        version_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerProto)
    }

    static {
      defaultInstance = new ContainerProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerProto)
  }

  public interface ContainerReportProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    // optional .hadoop.yarn.ResourceProto resource = 2;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    // optional .hadoop.yarn.NodeIdProto node_id = 3;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    // optional .hadoop.yarn.PriorityProto priority = 4;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    // optional int64 creation_time = 5;
    /**
     * <code>optional int64 creation_time = 5;</code>
     */
    boolean hasCreationTime();
    /**
     * <code>optional int64 creation_time = 5;</code>
     */
    long getCreationTime();

    // optional int64 finish_time = 6;
    /**
     * <code>optional int64 finish_time = 6;</code>
     */
    boolean hasFinishTime();
    /**
     * <code>optional int64 finish_time = 6;</code>
     */
    long getFinishTime();

    // optional string diagnostics_info = 7 [default = "N/A"];
    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    boolean hasDiagnosticsInfo();
    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    java.lang.String getDiagnosticsInfo();
    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsInfoBytes();

    // optional string log_url = 8;
    /**
     * <code>optional string log_url = 8;</code>
     */
    boolean hasLogUrl();
    /**
     * <code>optional string log_url = 8;</code>
     */
    java.lang.String getLogUrl();
    /**
     * <code>optional string log_url = 8;</code>
     */
    com.google.protobuf.ByteString
        getLogUrlBytes();

    // optional int32 container_exit_status = 9;
    /**
     * <code>optional int32 container_exit_status = 9;</code>
     */
    boolean hasContainerExitStatus();
    /**
     * <code>optional int32 container_exit_status = 9;</code>
     */
    int getContainerExitStatus();

    // optional .hadoop.yarn.ContainerStateProto container_state = 10;
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
     */
    boolean hasContainerState();
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getContainerState();

    // optional string node_http_address = 11;
    /**
     * <code>optional string node_http_address = 11;</code>
     */
    boolean hasNodeHttpAddress();
    /**
     * <code>optional string node_http_address = 11;</code>
     */
    java.lang.String getNodeHttpAddress();
    /**
     * <code>optional string node_http_address = 11;</code>
     */
    com.google.protobuf.ByteString
        getNodeHttpAddressBytes();

    // optional .hadoop.yarn.ExecutionTypeProto executionType = 12 [default = GUARANTEED];
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 12 [default = GUARANTEED];</code>
     */
    boolean hasExecutionType();
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 12 [default = GUARANTEED];</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerReportProto}
   */
  public static final class ContainerReportProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerReportProtoOrBuilder {
    // Use ContainerReportProto.newBuilder() to construct.
    private ContainerReportProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerReportProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerReportProto defaultInstance;
    public static ContainerReportProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerReportProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              creationTime_ = input.readInt64();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              finishTime_ = input.readInt64();
              break;
            }
            case 58: {
              bitField0_ |= 0x00000040;
              diagnosticsInfo_ = input.readBytes();
              break;
            }
            case 66: {
              bitField0_ |= 0x00000080;
              logUrl_ = input.readBytes();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              containerExitStatus_ = input.readInt32();
              break;
            }
            case 80: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(10, rawValue);
              } else {
                bitField0_ |= 0x00000200;
                containerState_ = value;
              }
              break;
            }
            case 90: {
              bitField0_ |= 0x00000400;
              nodeHttpAddress_ = input.readBytes();
              break;
            }
            case 96: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(12, rawValue);
              } else {
                bitField0_ |= 0x00000800;
                executionType_ = value;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerReportProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerReportProto>() {
      public ContainerReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerReportProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerReportProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }

    // optional .hadoop.yarn.ResourceProto resource = 2;
    public static final int RESOURCE_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional .hadoop.yarn.NodeIdProto node_id = 3;
    public static final int NODE_ID_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_;
    }

    // optional .hadoop.yarn.PriorityProto priority = 4;
    public static final int PRIORITY_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_;
    }

    // optional int64 creation_time = 5;
    public static final int CREATION_TIME_FIELD_NUMBER = 5;
    private long creationTime_;
    /**
     * <code>optional int64 creation_time = 5;</code>
     */
    public boolean hasCreationTime() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional int64 creation_time = 5;</code>
     */
    public long getCreationTime() {
      return creationTime_;
    }

    // optional int64 finish_time = 6;
    public static final int FINISH_TIME_FIELD_NUMBER = 6;
    private long finishTime_;
    /**
     * <code>optional int64 finish_time = 6;</code>
     */
    public boolean hasFinishTime() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int64 finish_time = 6;</code>
     */
    public long getFinishTime() {
      return finishTime_;
    }

    // optional string diagnostics_info = 7 [default = "N/A"];
    public static final int DIAGNOSTICS_INFO_FIELD_NUMBER = 7;
    private java.lang.Object diagnosticsInfo_;
    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    public boolean hasDiagnosticsInfo() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnosticsInfo() {
      java.lang.Object ref = diagnosticsInfo_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnosticsInfo_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsInfoBytes() {
      java.lang.Object ref = diagnosticsInfo_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnosticsInfo_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string log_url = 8;
    public static final int LOG_URL_FIELD_NUMBER = 8;
    private java.lang.Object logUrl_;
    /**
     * <code>optional string log_url = 8;</code>
     */
    public boolean hasLogUrl() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional string log_url = 8;</code>
     */
    public java.lang.String getLogUrl() {
      java.lang.Object ref = logUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          logUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string log_url = 8;</code>
     */
    public com.google.protobuf.ByteString
        getLogUrlBytes() {
      java.lang.Object ref = logUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        logUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int32 container_exit_status = 9;
    public static final int CONTAINER_EXIT_STATUS_FIELD_NUMBER = 9;
    private int containerExitStatus_;
    /**
     * <code>optional int32 container_exit_status = 9;</code>
     */
    public boolean hasContainerExitStatus() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional int32 container_exit_status = 9;</code>
     */
    public int getContainerExitStatus() {
      return containerExitStatus_;
    }

    // optional .hadoop.yarn.ContainerStateProto container_state = 10;
    public static final int CONTAINER_STATE_FIELD_NUMBER = 10;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto containerState_;
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
     */
    public boolean hasContainerState() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getContainerState() {
      return containerState_;
    }

    // optional string node_http_address = 11;
    public static final int NODE_HTTP_ADDRESS_FIELD_NUMBER = 11;
    private java.lang.Object nodeHttpAddress_;
    /**
     * <code>optional string node_http_address = 11;</code>
     */
    public boolean hasNodeHttpAddress() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    /**
     * <code>optional string node_http_address = 11;</code>
     */
    public java.lang.String getNodeHttpAddress() {
      java.lang.Object ref = nodeHttpAddress_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          nodeHttpAddress_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string node_http_address = 11;</code>
     */
    public com.google.protobuf.ByteString
        getNodeHttpAddressBytes() {
      java.lang.Object ref = nodeHttpAddress_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nodeHttpAddress_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.ExecutionTypeProto executionType = 12 [default = GUARANTEED];
    public static final int EXECUTIONTYPE_FIELD_NUMBER = 12;
    private org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto executionType_;
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 12 [default = GUARANTEED];</code>
     */
    public boolean hasExecutionType() {
      return ((bitField0_ & 0x00000800) == 0x00000800);
    }
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 12 [default = GUARANTEED];</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType() {
      return executionType_;
    }

    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      creationTime_ = 0L;
      finishTime_ = 0L;
      diagnosticsInfo_ = "N/A";
      logUrl_ = "";
      containerExitStatus_ = 0;
      containerState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
      nodeHttpAddress_ = "";
      executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, resource_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, nodeId_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, priority_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeInt64(5, creationTime_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt64(6, finishTime_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeBytes(7, getDiagnosticsInfoBytes());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeBytes(8, getLogUrlBytes());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeInt32(9, containerExitStatus_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeEnum(10, containerState_.getNumber());
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeBytes(11, getNodeHttpAddressBytes());
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        output.writeEnum(12, executionType_.getNumber());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, resource_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, nodeId_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, priority_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(5, creationTime_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(6, finishTime_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(7, getDiagnosticsInfoBytes());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(8, getLogUrlBytes());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(9, containerExitStatus_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(10, containerState_.getNumber());
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(11, getNodeHttpAddressBytes());
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(12, executionType_.getNumber());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasCreationTime() == other.hasCreationTime());
      if (hasCreationTime()) {
        result = result && (getCreationTime()
            == other.getCreationTime());
      }
      result = result && (hasFinishTime() == other.hasFinishTime());
      if (hasFinishTime()) {
        result = result && (getFinishTime()
            == other.getFinishTime());
      }
      result = result && (hasDiagnosticsInfo() == other.hasDiagnosticsInfo());
      if (hasDiagnosticsInfo()) {
        result = result && getDiagnosticsInfo()
            .equals(other.getDiagnosticsInfo());
      }
      result = result && (hasLogUrl() == other.hasLogUrl());
      if (hasLogUrl()) {
        result = result && getLogUrl()
            .equals(other.getLogUrl());
      }
      result = result && (hasContainerExitStatus() == other.hasContainerExitStatus());
      if (hasContainerExitStatus()) {
        result = result && (getContainerExitStatus()
            == other.getContainerExitStatus());
      }
      result = result && (hasContainerState() == other.hasContainerState());
      if (hasContainerState()) {
        result = result &&
            (getContainerState() == other.getContainerState());
      }
      result = result && (hasNodeHttpAddress() == other.hasNodeHttpAddress());
      if (hasNodeHttpAddress()) {
        result = result && getNodeHttpAddress()
            .equals(other.getNodeHttpAddress());
      }
      result = result && (hasExecutionType() == other.hasExecutionType());
      if (hasExecutionType()) {
        result = result &&
            (getExecutionType() == other.getExecutionType());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasNodeId()) {
        hash = (37 * hash) + NODE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasCreationTime()) {
        hash = (37 * hash) + CREATION_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getCreationTime());
      }
      if (hasFinishTime()) {
        hash = (37 * hash) + FINISH_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getFinishTime());
      }
      if (hasDiagnosticsInfo()) {
        hash = (37 * hash) + DIAGNOSTICS_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnosticsInfo().hashCode();
      }
      if (hasLogUrl()) {
        hash = (37 * hash) + LOG_URL_FIELD_NUMBER;
        hash = (53 * hash) + getLogUrl().hashCode();
      }
      if (hasContainerExitStatus()) {
        hash = (37 * hash) + CONTAINER_EXIT_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getContainerExitStatus();
      }
      if (hasContainerState()) {
        hash = (37 * hash) + CONTAINER_STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getContainerState());
      }
      if (hasNodeHttpAddress()) {
        hash = (37 * hash) + NODE_HTTP_ADDRESS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeHttpAddress().hashCode();
      }
      if (hasExecutionType()) {
        hash = (37 * hash) + EXECUTIONTYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getExecutionType());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getResourceFieldBuilder();
          getNodeIdFieldBuilder();
          getPriorityFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        creationTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000010);
        finishTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000020);
        diagnosticsInfo_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000040);
        logUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000080);
        containerExitStatus_ = 0;
        bitField0_ = (bitField0_ & ~0x00000100);
        containerState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
        bitField0_ = (bitField0_ & ~0x00000200);
        nodeHttpAddress_ = "";
        bitField0_ = (bitField0_ & ~0x00000400);
        executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
        bitField0_ = (bitField0_ & ~0x00000800);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.creationTime_ = creationTime_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.finishTime_ = finishTime_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.diagnosticsInfo_ = diagnosticsInfo_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.logUrl_ = logUrl_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.containerExitStatus_ = containerExitStatus_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.containerState_ = containerState_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000400;
        }
        result.nodeHttpAddress_ = nodeHttpAddress_;
        if (((from_bitField0_ & 0x00000800) == 0x00000800)) {
          to_bitField0_ |= 0x00000800;
        }
        result.executionType_ = executionType_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasCreationTime()) {
          setCreationTime(other.getCreationTime());
        }
        if (other.hasFinishTime()) {
          setFinishTime(other.getFinishTime());
        }
        if (other.hasDiagnosticsInfo()) {
          bitField0_ |= 0x00000040;
          diagnosticsInfo_ = other.diagnosticsInfo_;
          onChanged();
        }
        if (other.hasLogUrl()) {
          bitField0_ |= 0x00000080;
          logUrl_ = other.logUrl_;
          onChanged();
        }
        if (other.hasContainerExitStatus()) {
          setContainerExitStatus(other.getContainerExitStatus());
        }
        if (other.hasContainerState()) {
          setContainerState(other.getContainerState());
        }
        if (other.hasNodeHttpAddress()) {
          bitField0_ |= 0x00000400;
          nodeHttpAddress_ = other.nodeHttpAddress_;
          onChanged();
        }
        if (other.hasExecutionType()) {
          setExecutionType(other.getExecutionType());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto resource = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional .hadoop.yarn.NodeIdProto node_id = 3;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // optional .hadoop.yarn.PriorityProto priority = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  priority_,
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      // optional int64 creation_time = 5;
      private long creationTime_ ;
      /**
       * <code>optional int64 creation_time = 5;</code>
       */
      public boolean hasCreationTime() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional int64 creation_time = 5;</code>
       */
      public long getCreationTime() {
        return creationTime_;
      }
      /**
       * <code>optional int64 creation_time = 5;</code>
       */
      public Builder setCreationTime(long value) {
        bitField0_ |= 0x00000010;
        creationTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 creation_time = 5;</code>
       */
      public Builder clearCreationTime() {
        bitField0_ = (bitField0_ & ~0x00000010);
        creationTime_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 finish_time = 6;
      private long finishTime_ ;
      /**
       * <code>optional int64 finish_time = 6;</code>
       */
      public boolean hasFinishTime() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int64 finish_time = 6;</code>
       */
      public long getFinishTime() {
        return finishTime_;
      }
      /**
       * <code>optional int64 finish_time = 6;</code>
       */
      public Builder setFinishTime(long value) {
        bitField0_ |= 0x00000020;
        finishTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 finish_time = 6;</code>
       */
      public Builder clearFinishTime() {
        bitField0_ = (bitField0_ & ~0x00000020);
        finishTime_ = 0L;
        onChanged();
        return this;
      }

      // optional string diagnostics_info = 7 [default = "N/A"];
      private java.lang.Object diagnosticsInfo_ = "N/A";
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public boolean hasDiagnosticsInfo() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnosticsInfo() {
        java.lang.Object ref = diagnosticsInfo_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          diagnosticsInfo_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsInfoBytes() {
        java.lang.Object ref = diagnosticsInfo_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnosticsInfo_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsInfo(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000040;
        diagnosticsInfo_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public Builder clearDiagnosticsInfo() {
        bitField0_ = (bitField0_ & ~0x00000040);
        diagnosticsInfo_ = getDefaultInstance().getDiagnosticsInfo();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsInfoBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000040;
        diagnosticsInfo_ = value;
        onChanged();
        return this;
      }

      // optional string log_url = 8;
      private java.lang.Object logUrl_ = "";
      /**
       * <code>optional string log_url = 8;</code>
       */
      public boolean hasLogUrl() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional string log_url = 8;</code>
       */
      public java.lang.String getLogUrl() {
        java.lang.Object ref = logUrl_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          logUrl_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string log_url = 8;</code>
       */
      public com.google.protobuf.ByteString
          getLogUrlBytes() {
        java.lang.Object ref = logUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          logUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string log_url = 8;</code>
       */
      public Builder setLogUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        logUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string log_url = 8;</code>
       */
      public Builder clearLogUrl() {
        bitField0_ = (bitField0_ & ~0x00000080);
        logUrl_ = getDefaultInstance().getLogUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string log_url = 8;</code>
       */
      public Builder setLogUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        logUrl_ = value;
        onChanged();
        return this;
      }

      // optional int32 container_exit_status = 9;
      private int containerExitStatus_ ;
      /**
       * <code>optional int32 container_exit_status = 9;</code>
       */
      public boolean hasContainerExitStatus() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional int32 container_exit_status = 9;</code>
       */
      public int getContainerExitStatus() {
        return containerExitStatus_;
      }
      /**
       * <code>optional int32 container_exit_status = 9;</code>
       */
      public Builder setContainerExitStatus(int value) {
        bitField0_ |= 0x00000100;
        containerExitStatus_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 container_exit_status = 9;</code>
       */
      public Builder clearContainerExitStatus() {
        bitField0_ = (bitField0_ & ~0x00000100);
        containerExitStatus_ = 0;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ContainerStateProto container_state = 10;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto containerState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
       */
      public boolean hasContainerState() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getContainerState() {
        return containerState_;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
       */
      public Builder setContainerState(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000200;
        containerState_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
       */
      public Builder clearContainerState() {
        bitField0_ = (bitField0_ & ~0x00000200);
        containerState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
        onChanged();
        return this;
      }

      // optional string node_http_address = 11;
      private java.lang.Object nodeHttpAddress_ = "";
      /**
       * <code>optional string node_http_address = 11;</code>
       */
      public boolean hasNodeHttpAddress() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional string node_http_address = 11;</code>
       */
      public java.lang.String getNodeHttpAddress() {
        java.lang.Object ref = nodeHttpAddress_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          nodeHttpAddress_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string node_http_address = 11;</code>
       */
      public com.google.protobuf.ByteString
          getNodeHttpAddressBytes() {
        java.lang.Object ref = nodeHttpAddress_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nodeHttpAddress_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string node_http_address = 11;</code>
       */
      public Builder setNodeHttpAddress(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000400;
        nodeHttpAddress_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_http_address = 11;</code>
       */
      public Builder clearNodeHttpAddress() {
        bitField0_ = (bitField0_ & ~0x00000400);
        nodeHttpAddress_ = getDefaultInstance().getNodeHttpAddress();
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_http_address = 11;</code>
       */
      public Builder setNodeHttpAddressBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000400;
        nodeHttpAddress_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ExecutionTypeProto executionType = 12 [default = GUARANTEED];
      private org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 12 [default = GUARANTEED];</code>
       */
      public boolean hasExecutionType() {
        return ((bitField0_ & 0x00000800) == 0x00000800);
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 12 [default = GUARANTEED];</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType() {
        return executionType_;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 12 [default = GUARANTEED];</code>
       */
      public Builder setExecutionType(org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000800;
        executionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 12 [default = GUARANTEED];</code>
       */
      public Builder clearExecutionType() {
        bitField0_ = (bitField0_ & ~0x00000800);
        executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerReportProto)
    }

    static {
      defaultInstance = new ContainerReportProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerReportProto)
  }

  public interface URLProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string scheme = 1;
    /**
     * <code>optional string scheme = 1;</code>
     */
    boolean hasScheme();
    /**
     * <code>optional string scheme = 1;</code>
     */
    java.lang.String getScheme();
    /**
     * <code>optional string scheme = 1;</code>
     */
    com.google.protobuf.ByteString
        getSchemeBytes();

    // optional string host = 2;
    /**
     * <code>optional string host = 2;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 2;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 2;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    // optional int32 port = 3;
    /**
     * <code>optional int32 port = 3;</code>
     */
    boolean hasPort();
    /**
     * <code>optional int32 port = 3;</code>
     */
    int getPort();

    // optional string file = 4;
    /**
     * <code>optional string file = 4;</code>
     */
    boolean hasFile();
    /**
     * <code>optional string file = 4;</code>
     */
    java.lang.String getFile();
    /**
     * <code>optional string file = 4;</code>
     */
    com.google.protobuf.ByteString
        getFileBytes();

    // optional string userInfo = 5;
    /**
     * <code>optional string userInfo = 5;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>optional string userInfo = 5;</code>
     */
    java.lang.String getUserInfo();
    /**
     * <code>optional string userInfo = 5;</code>
     */
    com.google.protobuf.ByteString
        getUserInfoBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.URLProto}
   */
  public static final class URLProto extends
      com.google.protobuf.GeneratedMessage
      implements URLProtoOrBuilder {
    // Use URLProto.newBuilder() to construct.
    private URLProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private URLProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final URLProto defaultInstance;
    public static URLProto getDefaultInstance() {
      return defaultInstance;
    }

    public URLProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private URLProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              scheme_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              host_ = input.readBytes();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              port_ = input.readInt32();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              file_ = input.readBytes();
              break;
            }
            case 42: {
              bitField0_ |= 0x00000010;
              userInfo_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto.class, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder.class);
    }

    public static com.google.protobuf.Parser<URLProto> PARSER =
        new com.google.protobuf.AbstractParser<URLProto>() {
      public URLProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new URLProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<URLProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string scheme = 1;
    public static final int SCHEME_FIELD_NUMBER = 1;
    private java.lang.Object scheme_;
    /**
     * <code>optional string scheme = 1;</code>
     */
    public boolean hasScheme() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string scheme = 1;</code>
     */
    public java.lang.String getScheme() {
      java.lang.Object ref = scheme_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          scheme_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string scheme = 1;</code>
     */
    public com.google.protobuf.ByteString
        getSchemeBytes() {
      java.lang.Object ref = scheme_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        scheme_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string host = 2;
    public static final int HOST_FIELD_NUMBER = 2;
    private java.lang.Object host_;
    /**
     * <code>optional string host = 2;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string host = 2;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 2;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int32 port = 3;
    public static final int PORT_FIELD_NUMBER = 3;
    private int port_;
    /**
     * <code>optional int32 port = 3;</code>
     */
    public boolean hasPort() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int32 port = 3;</code>
     */
    public int getPort() {
      return port_;
    }

    // optional string file = 4;
    public static final int FILE_FIELD_NUMBER = 4;
    private java.lang.Object file_;
    /**
     * <code>optional string file = 4;</code>
     */
    public boolean hasFile() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string file = 4;</code>
     */
    public java.lang.String getFile() {
      java.lang.Object ref = file_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          file_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string file = 4;</code>
     */
    public com.google.protobuf.ByteString
        getFileBytes() {
      java.lang.Object ref = file_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        file_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string userInfo = 5;
    public static final int USERINFO_FIELD_NUMBER = 5;
    private java.lang.Object userInfo_;
    /**
     * <code>optional string userInfo = 5;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string userInfo = 5;</code>
     */
    public java.lang.String getUserInfo() {
      java.lang.Object ref = userInfo_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          userInfo_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string userInfo = 5;</code>
     */
    public com.google.protobuf.ByteString
        getUserInfoBytes() {
      java.lang.Object ref = userInfo_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        userInfo_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      scheme_ = "";
      host_ = "";
      port_ = 0;
      file_ = "";
      userInfo_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getSchemeBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getHostBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(3, port_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(4, getFileBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBytes(5, getUserInfoBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getSchemeBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getHostBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, port_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, getFileBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(5, getUserInfoBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.URLProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.URLProto other = (org.apache.hadoop.yarn.proto.YarnProtos.URLProto) obj;

      boolean result = true;
      result = result && (hasScheme() == other.hasScheme());
      if (hasScheme()) {
        result = result && getScheme()
            .equals(other.getScheme());
      }
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasPort() == other.hasPort());
      if (hasPort()) {
        result = result && (getPort()
            == other.getPort());
      }
      result = result && (hasFile() == other.hasFile());
      if (hasFile()) {
        result = result && getFile()
            .equals(other.getFile());
      }
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasScheme()) {
        hash = (37 * hash) + SCHEME_FIELD_NUMBER;
        hash = (53 * hash) + getScheme().hashCode();
      }
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasPort()) {
        hash = (37 * hash) + PORT_FIELD_NUMBER;
        hash = (53 * hash) + getPort();
      }
      if (hasFile()) {
        hash = (37 * hash) + FILE_FIELD_NUMBER;
        hash = (53 * hash) + getFile().hashCode();
      }
      if (hasUserInfo()) {
        hash = (37 * hash) + USERINFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.URLProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.URLProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.URLProto.class, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.URLProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        scheme_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        port_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        file_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        userInfo_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.URLProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.URLProto result = new org.apache.hadoop.yarn.proto.YarnProtos.URLProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.scheme_ = scheme_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.port_ = port_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.file_ = file_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.userInfo_ = userInfo_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.URLProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.URLProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.URLProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance()) return this;
        if (other.hasScheme()) {
          bitField0_ |= 0x00000001;
          scheme_ = other.scheme_;
          onChanged();
        }
        if (other.hasHost()) {
          bitField0_ |= 0x00000002;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasPort()) {
          setPort(other.getPort());
        }
        if (other.hasFile()) {
          bitField0_ |= 0x00000008;
          file_ = other.file_;
          onChanged();
        }
        if (other.hasUserInfo()) {
          bitField0_ |= 0x00000010;
          userInfo_ = other.userInfo_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.URLProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.URLProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string scheme = 1;
      private java.lang.Object scheme_ = "";
      /**
       * <code>optional string scheme = 1;</code>
       */
      public boolean hasScheme() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public java.lang.String getScheme() {
        java.lang.Object ref = scheme_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          scheme_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public com.google.protobuf.ByteString
          getSchemeBytes() {
        java.lang.Object ref = scheme_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          scheme_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public Builder setScheme(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        scheme_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public Builder clearScheme() {
        bitField0_ = (bitField0_ & ~0x00000001);
        scheme_ = getDefaultInstance().getScheme();
        onChanged();
        return this;
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public Builder setSchemeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        scheme_ = value;
        onChanged();
        return this;
      }

      // optional string host = 2;
      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 2;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          host_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000002);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
        return this;
      }

      // optional int32 port = 3;
      private int port_ ;
      /**
       * <code>optional int32 port = 3;</code>
       */
      public boolean hasPort() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int32 port = 3;</code>
       */
      public int getPort() {
        return port_;
      }
      /**
       * <code>optional int32 port = 3;</code>
       */
      public Builder setPort(int value) {
        bitField0_ |= 0x00000004;
        port_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 port = 3;</code>
       */
      public Builder clearPort() {
        bitField0_ = (bitField0_ & ~0x00000004);
        port_ = 0;
        onChanged();
        return this;
      }

      // optional string file = 4;
      private java.lang.Object file_ = "";
      /**
       * <code>optional string file = 4;</code>
       */
      public boolean hasFile() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public java.lang.String getFile() {
        java.lang.Object ref = file_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          file_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public com.google.protobuf.ByteString
          getFileBytes() {
        java.lang.Object ref = file_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          file_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public Builder setFile(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        file_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public Builder clearFile() {
        bitField0_ = (bitField0_ & ~0x00000008);
        file_ = getDefaultInstance().getFile();
        onChanged();
        return this;
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public Builder setFileBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        file_ = value;
        onChanged();
        return this;
      }

      // optional string userInfo = 5;
      private java.lang.Object userInfo_ = "";
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public java.lang.String getUserInfo() {
        java.lang.Object ref = userInfo_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          userInfo_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public com.google.protobuf.ByteString
          getUserInfoBytes() {
        java.lang.Object ref = userInfo_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          userInfo_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public Builder setUserInfo(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        userInfo_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000010);
        userInfo_ = getDefaultInstance().getUserInfo();
        onChanged();
        return this;
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public Builder setUserInfoBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        userInfo_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.URLProto)
    }

    static {
      defaultInstance = new URLProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.URLProto)
  }

  public interface LocalResourceProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.URLProto resource = 1;
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.URLProto getResource();
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder getResourceOrBuilder();

    // optional int64 size = 2;
    /**
     * <code>optional int64 size = 2;</code>
     */
    boolean hasSize();
    /**
     * <code>optional int64 size = 2;</code>
     */
    long getSize();

    // optional int64 timestamp = 3;
    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    boolean hasTimestamp();
    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    long getTimestamp();

    // optional .hadoop.yarn.LocalResourceTypeProto type = 4;
    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    boolean hasType();
    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto getType();

    // optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;
    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    boolean hasVisibility();
    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto getVisibility();

    // optional string pattern = 6;
    /**
     * <code>optional string pattern = 6;</code>
     */
    boolean hasPattern();
    /**
     * <code>optional string pattern = 6;</code>
     */
    java.lang.String getPattern();
    /**
     * <code>optional string pattern = 6;</code>
     */
    com.google.protobuf.ByteString
        getPatternBytes();

    // optional bool should_be_uploaded_to_shared_cache = 7;
    /**
     * <code>optional bool should_be_uploaded_to_shared_cache = 7;</code>
     */
    boolean hasShouldBeUploadedToSharedCache();
    /**
     * <code>optional bool should_be_uploaded_to_shared_cache = 7;</code>
     */
    boolean getShouldBeUploadedToSharedCache();
  }
  /**
   * Protobuf type {@code hadoop.yarn.LocalResourceProto}
   */
  public static final class LocalResourceProto extends
      com.google.protobuf.GeneratedMessage
      implements LocalResourceProtoOrBuilder {
    // Use LocalResourceProto.newBuilder() to construct.
    private LocalResourceProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private LocalResourceProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final LocalResourceProto defaultInstance;
    public static LocalResourceProto getDefaultInstance() {
      return defaultInstance;
    }

    public LocalResourceProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private LocalResourceProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.URLProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              size_ = input.readInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              timestamp_ = input.readInt64();
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                type_ = value;
              }
              break;
            }
            case 40: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto value = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(5, rawValue);
              } else {
                bitField0_ |= 0x00000010;
                visibility_ = value;
              }
              break;
            }
            case 50: {
              bitField0_ |= 0x00000020;
              pattern_ = input.readBytes();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              shouldBeUploadedToSharedCache_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder.class);
    }

    public static com.google.protobuf.Parser<LocalResourceProto> PARSER =
        new com.google.protobuf.AbstractParser<LocalResourceProto>() {
      public LocalResourceProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new LocalResourceProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<LocalResourceProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.URLProto resource = 1;
    public static final int RESOURCE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.URLProto resource_;
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.URLProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional int64 size = 2;
    public static final int SIZE_FIELD_NUMBER = 2;
    private long size_;
    /**
     * <code>optional int64 size = 2;</code>
     */
    public boolean hasSize() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 size = 2;</code>
     */
    public long getSize() {
      return size_;
    }

    // optional int64 timestamp = 3;
    public static final int TIMESTAMP_FIELD_NUMBER = 3;
    private long timestamp_;
    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    public boolean hasTimestamp() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    public long getTimestamp() {
      return timestamp_;
    }

    // optional .hadoop.yarn.LocalResourceTypeProto type = 4;
    public static final int TYPE_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto type_;
    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto getType() {
      return type_;
    }

    // optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;
    public static final int VISIBILITY_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto visibility_;
    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    public boolean hasVisibility() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto getVisibility() {
      return visibility_;
    }

    // optional string pattern = 6;
    public static final int PATTERN_FIELD_NUMBER = 6;
    private java.lang.Object pattern_;
    /**
     * <code>optional string pattern = 6;</code>
     */
    public boolean hasPattern() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional string pattern = 6;</code>
     */
    public java.lang.String getPattern() {
      java.lang.Object ref = pattern_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          pattern_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string pattern = 6;</code>
     */
    public com.google.protobuf.ByteString
        getPatternBytes() {
      java.lang.Object ref = pattern_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        pattern_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional bool should_be_uploaded_to_shared_cache = 7;
    public static final int SHOULD_BE_UPLOADED_TO_SHARED_CACHE_FIELD_NUMBER = 7;
    private boolean shouldBeUploadedToSharedCache_;
    /**
     * <code>optional bool should_be_uploaded_to_shared_cache = 7;</code>
     */
    public boolean hasShouldBeUploadedToSharedCache() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional bool should_be_uploaded_to_shared_cache = 7;</code>
     */
    public boolean getShouldBeUploadedToSharedCache() {
      return shouldBeUploadedToSharedCache_;
    }

    private void initFields() {
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance();
      size_ = 0L;
      timestamp_ = 0L;
      type_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.ARCHIVE;
      visibility_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.PUBLIC;
      pattern_ = "";
      shouldBeUploadedToSharedCache_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, resource_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, size_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, timestamp_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeEnum(4, type_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeEnum(5, visibility_.getNumber());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBytes(6, getPatternBytes());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeBool(7, shouldBeUploadedToSharedCache_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, resource_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, size_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, timestamp_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, type_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(5, visibility_.getNumber());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(6, getPatternBytes());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, shouldBeUploadedToSharedCache_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto other = (org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto) obj;

      boolean result = true;
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasSize() == other.hasSize());
      if (hasSize()) {
        result = result && (getSize()
            == other.getSize());
      }
      result = result && (hasTimestamp() == other.hasTimestamp());
      if (hasTimestamp()) {
        result = result && (getTimestamp()
            == other.getTimestamp());
      }
      result = result && (hasType() == other.hasType());
      if (hasType()) {
        result = result &&
            (getType() == other.getType());
      }
      result = result && (hasVisibility() == other.hasVisibility());
      if (hasVisibility()) {
        result = result &&
            (getVisibility() == other.getVisibility());
      }
      result = result && (hasPattern() == other.hasPattern());
      if (hasPattern()) {
        result = result && getPattern()
            .equals(other.getPattern());
      }
      result = result && (hasShouldBeUploadedToSharedCache() == other.hasShouldBeUploadedToSharedCache());
      if (hasShouldBeUploadedToSharedCache()) {
        result = result && (getShouldBeUploadedToSharedCache()
            == other.getShouldBeUploadedToSharedCache());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasSize()) {
        hash = (37 * hash) + SIZE_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getSize());
      }
      if (hasTimestamp()) {
        hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getTimestamp());
      }
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getType());
      }
      if (hasVisibility()) {
        hash = (37 * hash) + VISIBILITY_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getVisibility());
      }
      if (hasPattern()) {
        hash = (37 * hash) + PATTERN_FIELD_NUMBER;
        hash = (53 * hash) + getPattern().hashCode();
      }
      if (hasShouldBeUploadedToSharedCache()) {
        hash = (37 * hash) + SHOULD_BE_UPLOADED_TO_SHARED_CACHE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getShouldBeUploadedToSharedCache());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.LocalResourceProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        size_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        timestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        type_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.ARCHIVE;
        bitField0_ = (bitField0_ & ~0x00000008);
        visibility_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.PUBLIC;
        bitField0_ = (bitField0_ & ~0x00000010);
        pattern_ = "";
        bitField0_ = (bitField0_ & ~0x00000020);
        shouldBeUploadedToSharedCache_ = false;
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto result = new org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.size_ = size_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.timestamp_ = timestamp_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.visibility_ = visibility_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.pattern_ = pattern_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.shouldBeUploadedToSharedCache_ = shouldBeUploadedToSharedCache_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance()) return this;
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasSize()) {
          setSize(other.getSize());
        }
        if (other.hasTimestamp()) {
          setTimestamp(other.getTimestamp());
        }
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasVisibility()) {
          setVisibility(other.getVisibility());
        }
        if (other.hasPattern()) {
          bitField0_ |= 0x00000020;
          pattern_ = other.pattern_;
          onChanged();
        }
        if (other.hasShouldBeUploadedToSharedCache()) {
          setShouldBeUploadedToSharedCache(other.getShouldBeUploadedToSharedCache());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.URLProto resource = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.URLProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.URLProto, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.URLProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.URLProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.URLProto, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional int64 size = 2;
      private long size_ ;
      /**
       * <code>optional int64 size = 2;</code>
       */
      public boolean hasSize() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 size = 2;</code>
       */
      public long getSize() {
        return size_;
      }
      /**
       * <code>optional int64 size = 2;</code>
       */
      public Builder setSize(long value) {
        bitField0_ |= 0x00000002;
        size_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 size = 2;</code>
       */
      public Builder clearSize() {
        bitField0_ = (bitField0_ & ~0x00000002);
        size_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 timestamp = 3;
      private long timestamp_ ;
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public boolean hasTimestamp() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public long getTimestamp() {
        return timestamp_;
      }
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public Builder setTimestamp(long value) {
        bitField0_ |= 0x00000004;
        timestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public Builder clearTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000004);
        timestamp_ = 0L;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.LocalResourceTypeProto type = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto type_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.ARCHIVE;
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto getType() {
        return type_;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public Builder setType(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        type_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000008);
        type_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.ARCHIVE;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto visibility_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.PUBLIC;
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public boolean hasVisibility() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto getVisibility() {
        return visibility_;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public Builder setVisibility(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000010;
        visibility_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public Builder clearVisibility() {
        bitField0_ = (bitField0_ & ~0x00000010);
        visibility_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.PUBLIC;
        onChanged();
        return this;
      }

      // optional string pattern = 6;
      private java.lang.Object pattern_ = "";
      /**
       * <code>optional string pattern = 6;</code>
       */
      public boolean hasPattern() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public java.lang.String getPattern() {
        java.lang.Object ref = pattern_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          pattern_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public com.google.protobuf.ByteString
          getPatternBytes() {
        java.lang.Object ref = pattern_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          pattern_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public Builder setPattern(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        pattern_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public Builder clearPattern() {
        bitField0_ = (bitField0_ & ~0x00000020);
        pattern_ = getDefaultInstance().getPattern();
        onChanged();
        return this;
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public Builder setPatternBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        pattern_ = value;
        onChanged();
        return this;
      }

      // optional bool should_be_uploaded_to_shared_cache = 7;
      private boolean shouldBeUploadedToSharedCache_ ;
      /**
       * <code>optional bool should_be_uploaded_to_shared_cache = 7;</code>
       */
      public boolean hasShouldBeUploadedToSharedCache() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional bool should_be_uploaded_to_shared_cache = 7;</code>
       */
      public boolean getShouldBeUploadedToSharedCache() {
        return shouldBeUploadedToSharedCache_;
      }
      /**
       * <code>optional bool should_be_uploaded_to_shared_cache = 7;</code>
       */
      public Builder setShouldBeUploadedToSharedCache(boolean value) {
        bitField0_ |= 0x00000040;
        shouldBeUploadedToSharedCache_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool should_be_uploaded_to_shared_cache = 7;</code>
       */
      public Builder clearShouldBeUploadedToSharedCache() {
        bitField0_ = (bitField0_ & ~0x00000040);
        shouldBeUploadedToSharedCache_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.LocalResourceProto)
    }

    static {
      defaultInstance = new LocalResourceProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.LocalResourceProto)
  }

  public interface ApplicationResourceUsageReportProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 num_used_containers = 1;
    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    boolean hasNumUsedContainers();
    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    int getNumUsedContainers();

    // optional int32 num_reserved_containers = 2;
    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    boolean hasNumReservedContainers();
    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    int getNumReservedContainers();

    // optional .hadoop.yarn.ResourceProto used_resources = 3;
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    boolean hasUsedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedResourcesOrBuilder();

    // optional .hadoop.yarn.ResourceProto reserved_resources = 4;
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    boolean hasReservedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getReservedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getReservedResourcesOrBuilder();

    // optional .hadoop.yarn.ResourceProto needed_resources = 5;
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    boolean hasNeededResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getNeededResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getNeededResourcesOrBuilder();

    // optional int64 memory_seconds = 6;
    /**
     * <code>optional int64 memory_seconds = 6;</code>
     */
    boolean hasMemorySeconds();
    /**
     * <code>optional int64 memory_seconds = 6;</code>
     */
    long getMemorySeconds();

    // optional int64 vcore_seconds = 7;
    /**
     * <code>optional int64 vcore_seconds = 7;</code>
     */
    boolean hasVcoreSeconds();
    /**
     * <code>optional int64 vcore_seconds = 7;</code>
     */
    long getVcoreSeconds();

    // optional float queue_usage_percentage = 8;
    /**
     * <code>optional float queue_usage_percentage = 8;</code>
     */
    boolean hasQueueUsagePercentage();
    /**
     * <code>optional float queue_usage_percentage = 8;</code>
     */
    float getQueueUsagePercentage();

    // optional float cluster_usage_percentage = 9;
    /**
     * <code>optional float cluster_usage_percentage = 9;</code>
     */
    boolean hasClusterUsagePercentage();
    /**
     * <code>optional float cluster_usage_percentage = 9;</code>
     */
    float getClusterUsagePercentage();

    // optional int64 preempted_memory_seconds = 10;
    /**
     * <code>optional int64 preempted_memory_seconds = 10;</code>
     */
    boolean hasPreemptedMemorySeconds();
    /**
     * <code>optional int64 preempted_memory_seconds = 10;</code>
     */
    long getPreemptedMemorySeconds();

    // optional int64 preempted_vcore_seconds = 11;
    /**
     * <code>optional int64 preempted_vcore_seconds = 11;</code>
     */
    boolean hasPreemptedVcoreSeconds();
    /**
     * <code>optional int64 preempted_vcore_seconds = 11;</code>
     */
    long getPreemptedVcoreSeconds();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationResourceUsageReportProto}
   */
  public static final class ApplicationResourceUsageReportProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationResourceUsageReportProtoOrBuilder {
    // Use ApplicationResourceUsageReportProto.newBuilder() to construct.
    private ApplicationResourceUsageReportProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationResourceUsageReportProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationResourceUsageReportProto defaultInstance;
    public static ApplicationResourceUsageReportProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationResourceUsageReportProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationResourceUsageReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              numUsedContainers_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              numReservedContainers_ = input.readInt32();
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = usedResources_.toBuilder();
              }
              usedResources_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(usedResources_);
                usedResources_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = reservedResources_.toBuilder();
              }
              reservedResources_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservedResources_);
                reservedResources_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = neededResources_.toBuilder();
              }
              neededResources_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(neededResources_);
                neededResources_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              memorySeconds_ = input.readInt64();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              vcoreSeconds_ = input.readInt64();
              break;
            }
            case 69: {
              bitField0_ |= 0x00000080;
              queueUsagePercentage_ = input.readFloat();
              break;
            }
            case 77: {
              bitField0_ |= 0x00000100;
              clusterUsagePercentage_ = input.readFloat();
              break;
            }
            case 80: {
              bitField0_ |= 0x00000200;
              preemptedMemorySeconds_ = input.readInt64();
              break;
            }
            case 88: {
              bitField0_ |= 0x00000400;
              preemptedVcoreSeconds_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationResourceUsageReportProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationResourceUsageReportProto>() {
      public ApplicationResourceUsageReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationResourceUsageReportProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationResourceUsageReportProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 num_used_containers = 1;
    public static final int NUM_USED_CONTAINERS_FIELD_NUMBER = 1;
    private int numUsedContainers_;
    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    public boolean hasNumUsedContainers() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    public int getNumUsedContainers() {
      return numUsedContainers_;
    }

    // optional int32 num_reserved_containers = 2;
    public static final int NUM_RESERVED_CONTAINERS_FIELD_NUMBER = 2;
    private int numReservedContainers_;
    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    public boolean hasNumReservedContainers() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    public int getNumReservedContainers() {
      return numReservedContainers_;
    }

    // optional .hadoop.yarn.ResourceProto used_resources = 3;
    public static final int USED_RESOURCES_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto usedResources_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    public boolean hasUsedResources() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsedResources() {
      return usedResources_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedResourcesOrBuilder() {
      return usedResources_;
    }

    // optional .hadoop.yarn.ResourceProto reserved_resources = 4;
    public static final int RESERVED_RESOURCES_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto reservedResources_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    public boolean hasReservedResources() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getReservedResources() {
      return reservedResources_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getReservedResourcesOrBuilder() {
      return reservedResources_;
    }

    // optional .hadoop.yarn.ResourceProto needed_resources = 5;
    public static final int NEEDED_RESOURCES_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto neededResources_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    public boolean hasNeededResources() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getNeededResources() {
      return neededResources_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getNeededResourcesOrBuilder() {
      return neededResources_;
    }

    // optional int64 memory_seconds = 6;
    public static final int MEMORY_SECONDS_FIELD_NUMBER = 6;
    private long memorySeconds_;
    /**
     * <code>optional int64 memory_seconds = 6;</code>
     */
    public boolean hasMemorySeconds() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int64 memory_seconds = 6;</code>
     */
    public long getMemorySeconds() {
      return memorySeconds_;
    }

    // optional int64 vcore_seconds = 7;
    public static final int VCORE_SECONDS_FIELD_NUMBER = 7;
    private long vcoreSeconds_;
    /**
     * <code>optional int64 vcore_seconds = 7;</code>
     */
    public boolean hasVcoreSeconds() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional int64 vcore_seconds = 7;</code>
     */
    public long getVcoreSeconds() {
      return vcoreSeconds_;
    }

    // optional float queue_usage_percentage = 8;
    public static final int QUEUE_USAGE_PERCENTAGE_FIELD_NUMBER = 8;
    private float queueUsagePercentage_;
    /**
     * <code>optional float queue_usage_percentage = 8;</code>
     */
    public boolean hasQueueUsagePercentage() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional float queue_usage_percentage = 8;</code>
     */
    public float getQueueUsagePercentage() {
      return queueUsagePercentage_;
    }

    // optional float cluster_usage_percentage = 9;
    public static final int CLUSTER_USAGE_PERCENTAGE_FIELD_NUMBER = 9;
    private float clusterUsagePercentage_;
    /**
     * <code>optional float cluster_usage_percentage = 9;</code>
     */
    public boolean hasClusterUsagePercentage() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional float cluster_usage_percentage = 9;</code>
     */
    public float getClusterUsagePercentage() {
      return clusterUsagePercentage_;
    }

    // optional int64 preempted_memory_seconds = 10;
    public static final int PREEMPTED_MEMORY_SECONDS_FIELD_NUMBER = 10;
    private long preemptedMemorySeconds_;
    /**
     * <code>optional int64 preempted_memory_seconds = 10;</code>
     */
    public boolean hasPreemptedMemorySeconds() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional int64 preempted_memory_seconds = 10;</code>
     */
    public long getPreemptedMemorySeconds() {
      return preemptedMemorySeconds_;
    }

    // optional int64 preempted_vcore_seconds = 11;
    public static final int PREEMPTED_VCORE_SECONDS_FIELD_NUMBER = 11;
    private long preemptedVcoreSeconds_;
    /**
     * <code>optional int64 preempted_vcore_seconds = 11;</code>
     */
    public boolean hasPreemptedVcoreSeconds() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    /**
     * <code>optional int64 preempted_vcore_seconds = 11;</code>
     */
    public long getPreemptedVcoreSeconds() {
      return preemptedVcoreSeconds_;
    }

    private void initFields() {
      numUsedContainers_ = 0;
      numReservedContainers_ = 0;
      usedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      reservedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      neededResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      memorySeconds_ = 0L;
      vcoreSeconds_ = 0L;
      queueUsagePercentage_ = 0F;
      clusterUsagePercentage_ = 0F;
      preemptedMemorySeconds_ = 0L;
      preemptedVcoreSeconds_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, numUsedContainers_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, numReservedContainers_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, usedResources_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, reservedResources_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, neededResources_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt64(6, memorySeconds_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeInt64(7, vcoreSeconds_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeFloat(8, queueUsagePercentage_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeFloat(9, clusterUsagePercentage_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeInt64(10, preemptedMemorySeconds_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeInt64(11, preemptedVcoreSeconds_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, numUsedContainers_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, numReservedContainers_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, usedResources_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, reservedResources_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, neededResources_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(6, memorySeconds_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(7, vcoreSeconds_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(8, queueUsagePercentage_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(9, clusterUsagePercentage_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(10, preemptedMemorySeconds_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(11, preemptedVcoreSeconds_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto) obj;

      boolean result = true;
      result = result && (hasNumUsedContainers() == other.hasNumUsedContainers());
      if (hasNumUsedContainers()) {
        result = result && (getNumUsedContainers()
            == other.getNumUsedContainers());
      }
      result = result && (hasNumReservedContainers() == other.hasNumReservedContainers());
      if (hasNumReservedContainers()) {
        result = result && (getNumReservedContainers()
            == other.getNumReservedContainers());
      }
      result = result && (hasUsedResources() == other.hasUsedResources());
      if (hasUsedResources()) {
        result = result && getUsedResources()
            .equals(other.getUsedResources());
      }
      result = result && (hasReservedResources() == other.hasReservedResources());
      if (hasReservedResources()) {
        result = result && getReservedResources()
            .equals(other.getReservedResources());
      }
      result = result && (hasNeededResources() == other.hasNeededResources());
      if (hasNeededResources()) {
        result = result && getNeededResources()
            .equals(other.getNeededResources());
      }
      result = result && (hasMemorySeconds() == other.hasMemorySeconds());
      if (hasMemorySeconds()) {
        result = result && (getMemorySeconds()
            == other.getMemorySeconds());
      }
      result = result && (hasVcoreSeconds() == other.hasVcoreSeconds());
      if (hasVcoreSeconds()) {
        result = result && (getVcoreSeconds()
            == other.getVcoreSeconds());
      }
      result = result && (hasQueueUsagePercentage() == other.hasQueueUsagePercentage());
      if (hasQueueUsagePercentage()) {
        result = result && (Float.floatToIntBits(getQueueUsagePercentage())    == Float.floatToIntBits(other.getQueueUsagePercentage()));
      }
      result = result && (hasClusterUsagePercentage() == other.hasClusterUsagePercentage());
      if (hasClusterUsagePercentage()) {
        result = result && (Float.floatToIntBits(getClusterUsagePercentage())    == Float.floatToIntBits(other.getClusterUsagePercentage()));
      }
      result = result && (hasPreemptedMemorySeconds() == other.hasPreemptedMemorySeconds());
      if (hasPreemptedMemorySeconds()) {
        result = result && (getPreemptedMemorySeconds()
            == other.getPreemptedMemorySeconds());
      }
      result = result && (hasPreemptedVcoreSeconds() == other.hasPreemptedVcoreSeconds());
      if (hasPreemptedVcoreSeconds()) {
        result = result && (getPreemptedVcoreSeconds()
            == other.getPreemptedVcoreSeconds());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNumUsedContainers()) {
        hash = (37 * hash) + NUM_USED_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumUsedContainers();
      }
      if (hasNumReservedContainers()) {
        hash = (37 * hash) + NUM_RESERVED_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumReservedContainers();
      }
      if (hasUsedResources()) {
        hash = (37 * hash) + USED_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getUsedResources().hashCode();
      }
      if (hasReservedResources()) {
        hash = (37 * hash) + RESERVED_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getReservedResources().hashCode();
      }
      if (hasNeededResources()) {
        hash = (37 * hash) + NEEDED_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getNeededResources().hashCode();
      }
      if (hasMemorySeconds()) {
        hash = (37 * hash) + MEMORY_SECONDS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getMemorySeconds());
      }
      if (hasVcoreSeconds()) {
        hash = (37 * hash) + VCORE_SECONDS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getVcoreSeconds());
      }
      if (hasQueueUsagePercentage()) {
        hash = (37 * hash) + QUEUE_USAGE_PERCENTAGE_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getQueueUsagePercentage());
      }
      if (hasClusterUsagePercentage()) {
        hash = (37 * hash) + CLUSTER_USAGE_PERCENTAGE_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getClusterUsagePercentage());
      }
      if (hasPreemptedMemorySeconds()) {
        hash = (37 * hash) + PREEMPTED_MEMORY_SECONDS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getPreemptedMemorySeconds());
      }
      if (hasPreemptedVcoreSeconds()) {
        hash = (37 * hash) + PREEMPTED_VCORE_SECONDS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getPreemptedVcoreSeconds());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationResourceUsageReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUsedResourcesFieldBuilder();
          getReservedResourcesFieldBuilder();
          getNeededResourcesFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        numUsedContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        numReservedContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (usedResourcesBuilder_ == null) {
          usedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          usedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (reservedResourcesBuilder_ == null) {
          reservedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          reservedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (neededResourcesBuilder_ == null) {
          neededResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          neededResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        memorySeconds_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000020);
        vcoreSeconds_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000040);
        queueUsagePercentage_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000080);
        clusterUsagePercentage_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000100);
        preemptedMemorySeconds_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000200);
        preemptedVcoreSeconds_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000400);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.numUsedContainers_ = numUsedContainers_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.numReservedContainers_ = numReservedContainers_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (usedResourcesBuilder_ == null) {
          result.usedResources_ = usedResources_;
        } else {
          result.usedResources_ = usedResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (reservedResourcesBuilder_ == null) {
          result.reservedResources_ = reservedResources_;
        } else {
          result.reservedResources_ = reservedResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (neededResourcesBuilder_ == null) {
          result.neededResources_ = neededResources_;
        } else {
          result.neededResources_ = neededResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.memorySeconds_ = memorySeconds_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.vcoreSeconds_ = vcoreSeconds_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.queueUsagePercentage_ = queueUsagePercentage_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.clusterUsagePercentage_ = clusterUsagePercentage_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.preemptedMemorySeconds_ = preemptedMemorySeconds_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000400;
        }
        result.preemptedVcoreSeconds_ = preemptedVcoreSeconds_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance()) return this;
        if (other.hasNumUsedContainers()) {
          setNumUsedContainers(other.getNumUsedContainers());
        }
        if (other.hasNumReservedContainers()) {
          setNumReservedContainers(other.getNumReservedContainers());
        }
        if (other.hasUsedResources()) {
          mergeUsedResources(other.getUsedResources());
        }
        if (other.hasReservedResources()) {
          mergeReservedResources(other.getReservedResources());
        }
        if (other.hasNeededResources()) {
          mergeNeededResources(other.getNeededResources());
        }
        if (other.hasMemorySeconds()) {
          setMemorySeconds(other.getMemorySeconds());
        }
        if (other.hasVcoreSeconds()) {
          setVcoreSeconds(other.getVcoreSeconds());
        }
        if (other.hasQueueUsagePercentage()) {
          setQueueUsagePercentage(other.getQueueUsagePercentage());
        }
        if (other.hasClusterUsagePercentage()) {
          setClusterUsagePercentage(other.getClusterUsagePercentage());
        }
        if (other.hasPreemptedMemorySeconds()) {
          setPreemptedMemorySeconds(other.getPreemptedMemorySeconds());
        }
        if (other.hasPreemptedVcoreSeconds()) {
          setPreemptedVcoreSeconds(other.getPreemptedVcoreSeconds());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 num_used_containers = 1;
      private int numUsedContainers_ ;
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public boolean hasNumUsedContainers() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public int getNumUsedContainers() {
        return numUsedContainers_;
      }
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public Builder setNumUsedContainers(int value) {
        bitField0_ |= 0x00000001;
        numUsedContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public Builder clearNumUsedContainers() {
        bitField0_ = (bitField0_ & ~0x00000001);
        numUsedContainers_ = 0;
        onChanged();
        return this;
      }

      // optional int32 num_reserved_containers = 2;
      private int numReservedContainers_ ;
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public boolean hasNumReservedContainers() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public int getNumReservedContainers() {
        return numReservedContainers_;
      }
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public Builder setNumReservedContainers(int value) {
        bitField0_ |= 0x00000002;
        numReservedContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public Builder clearNumReservedContainers() {
        bitField0_ = (bitField0_ & ~0x00000002);
        numReservedContainers_ = 0;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto used_resources = 3;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto usedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> usedResourcesBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public boolean hasUsedResources() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsedResources() {
        if (usedResourcesBuilder_ == null) {
          return usedResources_;
        } else {
          return usedResourcesBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder setUsedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          usedResources_ = value;
          onChanged();
        } else {
          usedResourcesBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder setUsedResources(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (usedResourcesBuilder_ == null) {
          usedResources_ = builderForValue.build();
          onChanged();
        } else {
          usedResourcesBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder mergeUsedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              usedResources_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            usedResources_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(usedResources_).mergeFrom(value).buildPartial();
          } else {
            usedResources_ = value;
          }
          onChanged();
        } else {
          usedResourcesBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder clearUsedResources() {
        if (usedResourcesBuilder_ == null) {
          usedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          usedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getUsedResourcesBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getUsedResourcesFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedResourcesOrBuilder() {
        if (usedResourcesBuilder_ != null) {
          return usedResourcesBuilder_.getMessageOrBuilder();
        } else {
          return usedResources_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getUsedResourcesFieldBuilder() {
        if (usedResourcesBuilder_ == null) {
          usedResourcesBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  usedResources_,
                  getParentForChildren(),
                  isClean());
          usedResources_ = null;
        }
        return usedResourcesBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto reserved_resources = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto reservedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> reservedResourcesBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public boolean hasReservedResources() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getReservedResources() {
        if (reservedResourcesBuilder_ == null) {
          return reservedResources_;
        } else {
          return reservedResourcesBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder setReservedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (reservedResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservedResources_ = value;
          onChanged();
        } else {
          reservedResourcesBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder setReservedResources(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (reservedResourcesBuilder_ == null) {
          reservedResources_ = builderForValue.build();
          onChanged();
        } else {
          reservedResourcesBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder mergeReservedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (reservedResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              reservedResources_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            reservedResources_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(reservedResources_).mergeFrom(value).buildPartial();
          } else {
            reservedResources_ = value;
          }
          onChanged();
        } else {
          reservedResourcesBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder clearReservedResources() {
        if (reservedResourcesBuilder_ == null) {
          reservedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          reservedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getReservedResourcesBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getReservedResourcesFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getReservedResourcesOrBuilder() {
        if (reservedResourcesBuilder_ != null) {
          return reservedResourcesBuilder_.getMessageOrBuilder();
        } else {
          return reservedResources_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getReservedResourcesFieldBuilder() {
        if (reservedResourcesBuilder_ == null) {
          reservedResourcesBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  reservedResources_,
                  getParentForChildren(),
                  isClean());
          reservedResources_ = null;
        }
        return reservedResourcesBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto needed_resources = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto neededResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> neededResourcesBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public boolean hasNeededResources() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getNeededResources() {
        if (neededResourcesBuilder_ == null) {
          return neededResources_;
        } else {
          return neededResourcesBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder setNeededResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (neededResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          neededResources_ = value;
          onChanged();
        } else {
          neededResourcesBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder setNeededResources(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (neededResourcesBuilder_ == null) {
          neededResources_ = builderForValue.build();
          onChanged();
        } else {
          neededResourcesBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder mergeNeededResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (neededResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              neededResources_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            neededResources_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(neededResources_).mergeFrom(value).buildPartial();
          } else {
            neededResources_ = value;
          }
          onChanged();
        } else {
          neededResourcesBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder clearNeededResources() {
        if (neededResourcesBuilder_ == null) {
          neededResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          neededResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getNeededResourcesBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getNeededResourcesFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getNeededResourcesOrBuilder() {
        if (neededResourcesBuilder_ != null) {
          return neededResourcesBuilder_.getMessageOrBuilder();
        } else {
          return neededResources_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getNeededResourcesFieldBuilder() {
        if (neededResourcesBuilder_ == null) {
          neededResourcesBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  neededResources_,
                  getParentForChildren(),
                  isClean());
          neededResources_ = null;
        }
        return neededResourcesBuilder_;
      }

      // optional int64 memory_seconds = 6;
      private long memorySeconds_ ;
      /**
       * <code>optional int64 memory_seconds = 6;</code>
       */
      public boolean hasMemorySeconds() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int64 memory_seconds = 6;</code>
       */
      public long getMemorySeconds() {
        return memorySeconds_;
      }
      /**
       * <code>optional int64 memory_seconds = 6;</code>
       */
      public Builder setMemorySeconds(long value) {
        bitField0_ |= 0x00000020;
        memorySeconds_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 memory_seconds = 6;</code>
       */
      public Builder clearMemorySeconds() {
        bitField0_ = (bitField0_ & ~0x00000020);
        memorySeconds_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 vcore_seconds = 7;
      private long vcoreSeconds_ ;
      /**
       * <code>optional int64 vcore_seconds = 7;</code>
       */
      public boolean hasVcoreSeconds() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional int64 vcore_seconds = 7;</code>
       */
      public long getVcoreSeconds() {
        return vcoreSeconds_;
      }
      /**
       * <code>optional int64 vcore_seconds = 7;</code>
       */
      public Builder setVcoreSeconds(long value) {
        bitField0_ |= 0x00000040;
        vcoreSeconds_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 vcore_seconds = 7;</code>
       */
      public Builder clearVcoreSeconds() {
        bitField0_ = (bitField0_ & ~0x00000040);
        vcoreSeconds_ = 0L;
        onChanged();
        return this;
      }

      // optional float queue_usage_percentage = 8;
      private float queueUsagePercentage_ ;
      /**
       * <code>optional float queue_usage_percentage = 8;</code>
       */
      public boolean hasQueueUsagePercentage() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional float queue_usage_percentage = 8;</code>
       */
      public float getQueueUsagePercentage() {
        return queueUsagePercentage_;
      }
      /**
       * <code>optional float queue_usage_percentage = 8;</code>
       */
      public Builder setQueueUsagePercentage(float value) {
        bitField0_ |= 0x00000080;
        queueUsagePercentage_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float queue_usage_percentage = 8;</code>
       */
      public Builder clearQueueUsagePercentage() {
        bitField0_ = (bitField0_ & ~0x00000080);
        queueUsagePercentage_ = 0F;
        onChanged();
        return this;
      }

      // optional float cluster_usage_percentage = 9;
      private float clusterUsagePercentage_ ;
      /**
       * <code>optional float cluster_usage_percentage = 9;</code>
       */
      public boolean hasClusterUsagePercentage() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional float cluster_usage_percentage = 9;</code>
       */
      public float getClusterUsagePercentage() {
        return clusterUsagePercentage_;
      }
      /**
       * <code>optional float cluster_usage_percentage = 9;</code>
       */
      public Builder setClusterUsagePercentage(float value) {
        bitField0_ |= 0x00000100;
        clusterUsagePercentage_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float cluster_usage_percentage = 9;</code>
       */
      public Builder clearClusterUsagePercentage() {
        bitField0_ = (bitField0_ & ~0x00000100);
        clusterUsagePercentage_ = 0F;
        onChanged();
        return this;
      }

      // optional int64 preempted_memory_seconds = 10;
      private long preemptedMemorySeconds_ ;
      /**
       * <code>optional int64 preempted_memory_seconds = 10;</code>
       */
      public boolean hasPreemptedMemorySeconds() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional int64 preempted_memory_seconds = 10;</code>
       */
      public long getPreemptedMemorySeconds() {
        return preemptedMemorySeconds_;
      }
      /**
       * <code>optional int64 preempted_memory_seconds = 10;</code>
       */
      public Builder setPreemptedMemorySeconds(long value) {
        bitField0_ |= 0x00000200;
        preemptedMemorySeconds_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 preempted_memory_seconds = 10;</code>
       */
      public Builder clearPreemptedMemorySeconds() {
        bitField0_ = (bitField0_ & ~0x00000200);
        preemptedMemorySeconds_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 preempted_vcore_seconds = 11;
      private long preemptedVcoreSeconds_ ;
      /**
       * <code>optional int64 preempted_vcore_seconds = 11;</code>
       */
      public boolean hasPreemptedVcoreSeconds() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional int64 preempted_vcore_seconds = 11;</code>
       */
      public long getPreemptedVcoreSeconds() {
        return preemptedVcoreSeconds_;
      }
      /**
       * <code>optional int64 preempted_vcore_seconds = 11;</code>
       */
      public Builder setPreemptedVcoreSeconds(long value) {
        bitField0_ |= 0x00000400;
        preemptedVcoreSeconds_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 preempted_vcore_seconds = 11;</code>
       */
      public Builder clearPreemptedVcoreSeconds() {
        bitField0_ = (bitField0_ & ~0x00000400);
        preemptedVcoreSeconds_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationResourceUsageReportProto)
    }

    static {
      defaultInstance = new ApplicationResourceUsageReportProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationResourceUsageReportProto)
  }

  public interface ApplicationReportProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto applicationId = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    // optional string user = 2;
    /**
     * <code>optional string user = 2;</code>
     */
    boolean hasUser();
    /**
     * <code>optional string user = 2;</code>
     */
    java.lang.String getUser();
    /**
     * <code>optional string user = 2;</code>
     */
    com.google.protobuf.ByteString
        getUserBytes();

    // optional string queue = 3;
    /**
     * <code>optional string queue = 3;</code>
     */
    boolean hasQueue();
    /**
     * <code>optional string queue = 3;</code>
     */
    java.lang.String getQueue();
    /**
     * <code>optional string queue = 3;</code>
     */
    com.google.protobuf.ByteString
        getQueueBytes();

    // optional string name = 4;
    /**
     * <code>optional string name = 4;</code>
     */
    boolean hasName();
    /**
     * <code>optional string name = 4;</code>
     */
    java.lang.String getName();
    /**
     * <code>optional string name = 4;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    // optional string host = 5;
    /**
     * <code>optional string host = 5;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 5;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 5;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    // optional int32 rpc_port = 6;
    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    boolean hasRpcPort();
    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    int getRpcPort();

    // optional .hadoop.common.TokenProto client_to_am_token = 7;
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    boolean hasClientToAmToken();
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getClientToAmToken();
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getClientToAmTokenOrBuilder();

    // optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;
    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    boolean hasYarnApplicationState();
    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getYarnApplicationState();

    // optional string trackingUrl = 9;
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    boolean hasTrackingUrl();
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    java.lang.String getTrackingUrl();
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    com.google.protobuf.ByteString
        getTrackingUrlBytes();

    // optional string diagnostics = 10 [default = "N/A"];
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    boolean hasDiagnostics();
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    java.lang.String getDiagnostics();
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsBytes();

    // optional int64 startTime = 11;
    /**
     * <code>optional int64 startTime = 11;</code>
     */
    boolean hasStartTime();
    /**
     * <code>optional int64 startTime = 11;</code>
     */
    long getStartTime();

    // optional int64 finishTime = 12;
    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    boolean hasFinishTime();
    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    long getFinishTime();

    // optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    boolean hasFinalApplicationStatus();
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus();

    // optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    boolean hasAppResourceUsage();
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getAppResourceUsage();
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder getAppResourceUsageOrBuilder();

    // optional string originalTrackingUrl = 15;
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    boolean hasOriginalTrackingUrl();
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    java.lang.String getOriginalTrackingUrl();
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    com.google.protobuf.ByteString
        getOriginalTrackingUrlBytes();

    // optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    boolean hasCurrentApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getCurrentApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getCurrentApplicationAttemptIdOrBuilder();

    // optional float progress = 17;
    /**
     * <code>optional float progress = 17;</code>
     */
    boolean hasProgress();
    /**
     * <code>optional float progress = 17;</code>
     */
    float getProgress();

    // optional string applicationType = 18;
    /**
     * <code>optional string applicationType = 18;</code>
     */
    boolean hasApplicationType();
    /**
     * <code>optional string applicationType = 18;</code>
     */
    java.lang.String getApplicationType();
    /**
     * <code>optional string applicationType = 18;</code>
     */
    com.google.protobuf.ByteString
        getApplicationTypeBytes();

    // optional .hadoop.common.TokenProto am_rm_token = 19;
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    boolean hasAmRmToken();
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken();
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder();

    // repeated string applicationTags = 20;
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    java.util.List<java.lang.String>
    getApplicationTagsList();
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    int getApplicationTagsCount();
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    java.lang.String getApplicationTags(int index);
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    com.google.protobuf.ByteString
        getApplicationTagsBytes(int index);

    // optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 21;
    /**
     * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 21;</code>
     */
    boolean hasLogAggregationStatus();
    /**
     * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 21;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto getLogAggregationStatus();

    // optional bool unmanaged_application = 22 [default = false];
    /**
     * <code>optional bool unmanaged_application = 22 [default = false];</code>
     */
    boolean hasUnmanagedApplication();
    /**
     * <code>optional bool unmanaged_application = 22 [default = false];</code>
     */
    boolean getUnmanagedApplication();

    // optional .hadoop.yarn.PriorityProto priority = 23;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    // optional string appNodeLabelExpression = 24;
    /**
     * <code>optional string appNodeLabelExpression = 24;</code>
     */
    boolean hasAppNodeLabelExpression();
    /**
     * <code>optional string appNodeLabelExpression = 24;</code>
     */
    java.lang.String getAppNodeLabelExpression();
    /**
     * <code>optional string appNodeLabelExpression = 24;</code>
     */
    com.google.protobuf.ByteString
        getAppNodeLabelExpressionBytes();

    // optional string amNodeLabelExpression = 25;
    /**
     * <code>optional string amNodeLabelExpression = 25;</code>
     */
    boolean hasAmNodeLabelExpression();
    /**
     * <code>optional string amNodeLabelExpression = 25;</code>
     */
    java.lang.String getAmNodeLabelExpression();
    /**
     * <code>optional string amNodeLabelExpression = 25;</code>
     */
    com.google.protobuf.ByteString
        getAmNodeLabelExpressionBytes();

    // repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;
    /**
     * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto> 
        getAppTimeoutsList();
    /**
     * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto getAppTimeouts(int index);
    /**
     * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
     */
    int getAppTimeoutsCount();
    /**
     * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProtoOrBuilder> 
        getAppTimeoutsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProtoOrBuilder getAppTimeoutsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationReportProto}
   */
  public static final class ApplicationReportProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationReportProtoOrBuilder {
    // Use ApplicationReportProto.newBuilder() to construct.
    private ApplicationReportProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationReportProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationReportProto defaultInstance;
    public static ApplicationReportProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationReportProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              user_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              queue_ = input.readBytes();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              name_ = input.readBytes();
              break;
            }
            case 42: {
              bitField0_ |= 0x00000010;
              host_ = input.readBytes();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              rpcPort_ = input.readInt32();
              break;
            }
            case 58: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000040) == 0x00000040)) {
                subBuilder = clientToAmToken_.toBuilder();
              }
              clientToAmToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(clientToAmToken_);
                clientToAmToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000040;
              break;
            }
            case 64: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(8, rawValue);
              } else {
                bitField0_ |= 0x00000080;
                yarnApplicationState_ = value;
              }
              break;
            }
            case 74: {
              bitField0_ |= 0x00000100;
              trackingUrl_ = input.readBytes();
              break;
            }
            case 82: {
              bitField0_ |= 0x00000200;
              diagnostics_ = input.readBytes();
              break;
            }
            case 88: {
              bitField0_ |= 0x00000400;
              startTime_ = input.readInt64();
              break;
            }
            case 96: {
              bitField0_ |= 0x00000800;
              finishTime_ = input.readInt64();
              break;
            }
            case 104: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto value = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(13, rawValue);
              } else {
                bitField0_ |= 0x00001000;
                finalApplicationStatus_ = value;
              }
              break;
            }
            case 114: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00002000) == 0x00002000)) {
                subBuilder = appResourceUsage_.toBuilder();
              }
              appResourceUsage_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appResourceUsage_);
                appResourceUsage_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00002000;
              break;
            }
            case 122: {
              bitField0_ |= 0x00004000;
              originalTrackingUrl_ = input.readBytes();
              break;
            }
            case 130: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00008000) == 0x00008000)) {
                subBuilder = currentApplicationAttemptId_.toBuilder();
              }
              currentApplicationAttemptId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(currentApplicationAttemptId_);
                currentApplicationAttemptId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00008000;
              break;
            }
            case 141: {
              bitField0_ |= 0x00010000;
              progress_ = input.readFloat();
              break;
            }
            case 146: {
              bitField0_ |= 0x00020000;
              applicationType_ = input.readBytes();
              break;
            }
            case 154: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00040000) == 0x00040000)) {
                subBuilder = amRmToken_.toBuilder();
              }
              amRmToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(amRmToken_);
                amRmToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00040000;
              break;
            }
            case 162: {
              if (!((mutable_bitField0_ & 0x00080000) == 0x00080000)) {
                applicationTags_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00080000;
              }
              applicationTags_.add(input.readBytes());
              break;
            }
            case 168: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto value = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(21, rawValue);
              } else {
                bitField0_ |= 0x00080000;
                logAggregationStatus_ = value;
              }
              break;
            }
            case 176: {
              bitField0_ |= 0x00100000;
              unmanagedApplication_ = input.readBool();
              break;
            }
            case 186: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00200000) == 0x00200000)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00200000;
              break;
            }
            case 194: {
              bitField0_ |= 0x00400000;
              appNodeLabelExpression_ = input.readBytes();
              break;
            }
            case 202: {
              bitField0_ |= 0x00800000;
              amNodeLabelExpression_ = input.readBytes();
              break;
            }
            case 210: {
              if (!((mutable_bitField0_ & 0x02000000) == 0x02000000)) {
                appTimeouts_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto>();
                mutable_bitField0_ |= 0x02000000;
              }
              appTimeouts_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00080000) == 0x00080000)) {
          applicationTags_ = new com.google.protobuf.UnmodifiableLazyStringList(applicationTags_);
        }
        if (((mutable_bitField0_ & 0x02000000) == 0x02000000)) {
          appTimeouts_ = java.util.Collections.unmodifiableList(appTimeouts_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationReportProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationReportProto>() {
      public ApplicationReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationReportProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationReportProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto applicationId = 1;
    public static final int APPLICATIONID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_;
    }

    // optional string user = 2;
    public static final int USER_FIELD_NUMBER = 2;
    private java.lang.Object user_;
    /**
     * <code>optional string user = 2;</code>
     */
    public boolean hasUser() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string user = 2;</code>
     */
    public java.lang.String getUser() {
      java.lang.Object ref = user_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          user_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string user = 2;</code>
     */
    public com.google.protobuf.ByteString
        getUserBytes() {
      java.lang.Object ref = user_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        user_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string queue = 3;
    public static final int QUEUE_FIELD_NUMBER = 3;
    private java.lang.Object queue_;
    /**
     * <code>optional string queue = 3;</code>
     */
    public boolean hasQueue() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string queue = 3;</code>
     */
    public java.lang.String getQueue() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queue = 3;</code>
     */
    public com.google.protobuf.ByteString
        getQueueBytes() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queue_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string name = 4;
    public static final int NAME_FIELD_NUMBER = 4;
    private java.lang.Object name_;
    /**
     * <code>optional string name = 4;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string name = 4;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string name = 4;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string host = 5;
    public static final int HOST_FIELD_NUMBER = 5;
    private java.lang.Object host_;
    /**
     * <code>optional string host = 5;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string host = 5;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 5;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int32 rpc_port = 6;
    public static final int RPC_PORT_FIELD_NUMBER = 6;
    private int rpcPort_;
    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    public boolean hasRpcPort() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    public int getRpcPort() {
      return rpcPort_;
    }

    // optional .hadoop.common.TokenProto client_to_am_token = 7;
    public static final int CLIENT_TO_AM_TOKEN_FIELD_NUMBER = 7;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto clientToAmToken_;
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    public boolean hasClientToAmToken() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getClientToAmToken() {
      return clientToAmToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getClientToAmTokenOrBuilder() {
      return clientToAmToken_;
    }

    // optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;
    public static final int YARN_APPLICATION_STATE_FIELD_NUMBER = 8;
    private org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto yarnApplicationState_;
    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    public boolean hasYarnApplicationState() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getYarnApplicationState() {
      return yarnApplicationState_;
    }

    // optional string trackingUrl = 9;
    public static final int TRACKINGURL_FIELD_NUMBER = 9;
    private java.lang.Object trackingUrl_;
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    public boolean hasTrackingUrl() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    public java.lang.String getTrackingUrl() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          trackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    public com.google.protobuf.ByteString
        getTrackingUrlBytes() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        trackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string diagnostics = 10 [default = "N/A"];
    public static final int DIAGNOSTICS_FIELD_NUMBER = 10;
    private java.lang.Object diagnostics_;
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int64 startTime = 11;
    public static final int STARTTIME_FIELD_NUMBER = 11;
    private long startTime_;
    /**
     * <code>optional int64 startTime = 11;</code>
     */
    public boolean hasStartTime() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    /**
     * <code>optional int64 startTime = 11;</code>
     */
    public long getStartTime() {
      return startTime_;
    }

    // optional int64 finishTime = 12;
    public static final int FINISHTIME_FIELD_NUMBER = 12;
    private long finishTime_;
    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    public boolean hasFinishTime() {
      return ((bitField0_ & 0x00000800) == 0x00000800);
    }
    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    public long getFinishTime() {
      return finishTime_;
    }

    // optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;
    public static final int FINAL_APPLICATION_STATUS_FIELD_NUMBER = 13;
    private org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto finalApplicationStatus_;
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    public boolean hasFinalApplicationStatus() {
      return ((bitField0_ & 0x00001000) == 0x00001000);
    }
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus() {
      return finalApplicationStatus_;
    }

    // optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;
    public static final int APP_RESOURCE_USAGE_FIELD_NUMBER = 14;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto appResourceUsage_;
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    public boolean hasAppResourceUsage() {
      return ((bitField0_ & 0x00002000) == 0x00002000);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getAppResourceUsage() {
      return appResourceUsage_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder getAppResourceUsageOrBuilder() {
      return appResourceUsage_;
    }

    // optional string originalTrackingUrl = 15;
    public static final int ORIGINALTRACKINGURL_FIELD_NUMBER = 15;
    private java.lang.Object originalTrackingUrl_;
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    public boolean hasOriginalTrackingUrl() {
      return ((bitField0_ & 0x00004000) == 0x00004000);
    }
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    public java.lang.String getOriginalTrackingUrl() {
      java.lang.Object ref = originalTrackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          originalTrackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    public com.google.protobuf.ByteString
        getOriginalTrackingUrlBytes() {
      java.lang.Object ref = originalTrackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        originalTrackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;
    public static final int CURRENTAPPLICATIONATTEMPTID_FIELD_NUMBER = 16;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto currentApplicationAttemptId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    public boolean hasCurrentApplicationAttemptId() {
      return ((bitField0_ & 0x00008000) == 0x00008000);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getCurrentApplicationAttemptId() {
      return currentApplicationAttemptId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getCurrentApplicationAttemptIdOrBuilder() {
      return currentApplicationAttemptId_;
    }

    // optional float progress = 17;
    public static final int PROGRESS_FIELD_NUMBER = 17;
    private float progress_;
    /**
     * <code>optional float progress = 17;</code>
     */
    public boolean hasProgress() {
      return ((bitField0_ & 0x00010000) == 0x00010000);
    }
    /**
     * <code>optional float progress = 17;</code>
     */
    public float getProgress() {
      return progress_;
    }

    // optional string applicationType = 18;
    public static final int APPLICATIONTYPE_FIELD_NUMBER = 18;
    private java.lang.Object applicationType_;
    /**
     * <code>optional string applicationType = 18;</code>
     */
    public boolean hasApplicationType() {
      return ((bitField0_ & 0x00020000) == 0x00020000);
    }
    /**
     * <code>optional string applicationType = 18;</code>
     */
    public java.lang.String getApplicationType() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          applicationType_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string applicationType = 18;</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTypeBytes() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        applicationType_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.common.TokenProto am_rm_token = 19;
    public static final int AM_RM_TOKEN_FIELD_NUMBER = 19;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto amRmToken_;
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    public boolean hasAmRmToken() {
      return ((bitField0_ & 0x00040000) == 0x00040000);
    }
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken() {
      return amRmToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder() {
      return amRmToken_;
    }

    // repeated string applicationTags = 20;
    public static final int APPLICATIONTAGS_FIELD_NUMBER = 20;
    private com.google.protobuf.LazyStringList applicationTags_;
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    public java.util.List<java.lang.String>
        getApplicationTagsList() {
      return applicationTags_;
    }
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    public int getApplicationTagsCount() {
      return applicationTags_.size();
    }
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    public java.lang.String getApplicationTags(int index) {
      return applicationTags_.get(index);
    }
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTagsBytes(int index) {
      return applicationTags_.getByteString(index);
    }

    // optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 21;
    public static final int LOG_AGGREGATION_STATUS_FIELD_NUMBER = 21;
    private org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto logAggregationStatus_;
    /**
     * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 21;</code>
     */
    public boolean hasLogAggregationStatus() {
      return ((bitField0_ & 0x00080000) == 0x00080000);
    }
    /**
     * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 21;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto getLogAggregationStatus() {
      return logAggregationStatus_;
    }

    // optional bool unmanaged_application = 22 [default = false];
    public static final int UNMANAGED_APPLICATION_FIELD_NUMBER = 22;
    private boolean unmanagedApplication_;
    /**
     * <code>optional bool unmanaged_application = 22 [default = false];</code>
     */
    public boolean hasUnmanagedApplication() {
      return ((bitField0_ & 0x00100000) == 0x00100000);
    }
    /**
     * <code>optional bool unmanaged_application = 22 [default = false];</code>
     */
    public boolean getUnmanagedApplication() {
      return unmanagedApplication_;
    }

    // optional .hadoop.yarn.PriorityProto priority = 23;
    public static final int PRIORITY_FIELD_NUMBER = 23;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00200000) == 0x00200000);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_;
    }

    // optional string appNodeLabelExpression = 24;
    public static final int APPNODELABELEXPRESSION_FIELD_NUMBER = 24;
    private java.lang.Object appNodeLabelExpression_;
    /**
     * <code>optional string appNodeLabelExpression = 24;</code>
     */
    public boolean hasAppNodeLabelExpression() {
      return ((bitField0_ & 0x00400000) == 0x00400000);
    }
    /**
     * <code>optional string appNodeLabelExpression = 24;</code>
     */
    public java.lang.String getAppNodeLabelExpression() {
      java.lang.Object ref = appNodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          appNodeLabelExpression_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string appNodeLabelExpression = 24;</code>
     */
    public com.google.protobuf.ByteString
        getAppNodeLabelExpressionBytes() {
      java.lang.Object ref = appNodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        appNodeLabelExpression_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string amNodeLabelExpression = 25;
    public static final int AMNODELABELEXPRESSION_FIELD_NUMBER = 25;
    private java.lang.Object amNodeLabelExpression_;
    /**
     * <code>optional string amNodeLabelExpression = 25;</code>
     */
    public boolean hasAmNodeLabelExpression() {
      return ((bitField0_ & 0x00800000) == 0x00800000);
    }
    /**
     * <code>optional string amNodeLabelExpression = 25;</code>
     */
    public java.lang.String getAmNodeLabelExpression() {
      java.lang.Object ref = amNodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          amNodeLabelExpression_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string amNodeLabelExpression = 25;</code>
     */
    public com.google.protobuf.ByteString
        getAmNodeLabelExpressionBytes() {
      java.lang.Object ref = amNodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        amNodeLabelExpression_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;
    public static final int APPTIMEOUTS_FIELD_NUMBER = 26;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto> appTimeouts_;
    /**
     * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto> getAppTimeoutsList() {
      return appTimeouts_;
    }
    /**
     * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProtoOrBuilder> 
        getAppTimeoutsOrBuilderList() {
      return appTimeouts_;
    }
    /**
     * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
     */
    public int getAppTimeoutsCount() {
      return appTimeouts_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto getAppTimeouts(int index) {
      return appTimeouts_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProtoOrBuilder getAppTimeoutsOrBuilder(
        int index) {
      return appTimeouts_.get(index);
    }

    private void initFields() {
      applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      user_ = "";
      queue_ = "";
      name_ = "";
      host_ = "";
      rpcPort_ = 0;
      clientToAmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      yarnApplicationState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.NEW;
      trackingUrl_ = "";
      diagnostics_ = "N/A";
      startTime_ = 0L;
      finishTime_ = 0L;
      finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
      appResourceUsage_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance();
      originalTrackingUrl_ = "";
      currentApplicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      progress_ = 0F;
      applicationType_ = "";
      amRmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      logAggregationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto.LOG_DISABLED;
      unmanagedApplication_ = false;
      priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      appNodeLabelExpression_ = "";
      amNodeLabelExpression_ = "";
      appTimeouts_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasClientToAmToken()) {
        if (!getClientToAmToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasAmRmToken()) {
        if (!getAmRmToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getAppTimeoutsCount(); i++) {
        if (!getAppTimeouts(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getUserBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getQueueBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(4, getNameBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBytes(5, getHostBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt32(6, rpcPort_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeMessage(7, clientToAmToken_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeEnum(8, yarnApplicationState_.getNumber());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeBytes(9, getTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeBytes(10, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeInt64(11, startTime_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        output.writeInt64(12, finishTime_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        output.writeEnum(13, finalApplicationStatus_.getNumber());
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        output.writeMessage(14, appResourceUsage_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        output.writeBytes(15, getOriginalTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00008000) == 0x00008000)) {
        output.writeMessage(16, currentApplicationAttemptId_);
      }
      if (((bitField0_ & 0x00010000) == 0x00010000)) {
        output.writeFloat(17, progress_);
      }
      if (((bitField0_ & 0x00020000) == 0x00020000)) {
        output.writeBytes(18, getApplicationTypeBytes());
      }
      if (((bitField0_ & 0x00040000) == 0x00040000)) {
        output.writeMessage(19, amRmToken_);
      }
      for (int i = 0; i < applicationTags_.size(); i++) {
        output.writeBytes(20, applicationTags_.getByteString(i));
      }
      if (((bitField0_ & 0x00080000) == 0x00080000)) {
        output.writeEnum(21, logAggregationStatus_.getNumber());
      }
      if (((bitField0_ & 0x00100000) == 0x00100000)) {
        output.writeBool(22, unmanagedApplication_);
      }
      if (((bitField0_ & 0x00200000) == 0x00200000)) {
        output.writeMessage(23, priority_);
      }
      if (((bitField0_ & 0x00400000) == 0x00400000)) {
        output.writeBytes(24, getAppNodeLabelExpressionBytes());
      }
      if (((bitField0_ & 0x00800000) == 0x00800000)) {
        output.writeBytes(25, getAmNodeLabelExpressionBytes());
      }
      for (int i = 0; i < appTimeouts_.size(); i++) {
        output.writeMessage(26, appTimeouts_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getUserBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getQueueBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, getNameBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(5, getHostBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(6, rpcPort_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, clientToAmToken_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(8, yarnApplicationState_.getNumber());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(9, getTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(10, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(11, startTime_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(12, finishTime_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(13, finalApplicationStatus_.getNumber());
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, appResourceUsage_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(15, getOriginalTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00008000) == 0x00008000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(16, currentApplicationAttemptId_);
      }
      if (((bitField0_ & 0x00010000) == 0x00010000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(17, progress_);
      }
      if (((bitField0_ & 0x00020000) == 0x00020000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(18, getApplicationTypeBytes());
      }
      if (((bitField0_ & 0x00040000) == 0x00040000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(19, amRmToken_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < applicationTags_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(applicationTags_.getByteString(i));
        }
        size += dataSize;
        size += 2 * getApplicationTagsList().size();
      }
      if (((bitField0_ & 0x00080000) == 0x00080000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(21, logAggregationStatus_.getNumber());
      }
      if (((bitField0_ & 0x00100000) == 0x00100000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(22, unmanagedApplication_);
      }
      if (((bitField0_ & 0x00200000) == 0x00200000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(23, priority_);
      }
      if (((bitField0_ & 0x00400000) == 0x00400000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(24, getAppNodeLabelExpressionBytes());
      }
      if (((bitField0_ & 0x00800000) == 0x00800000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(25, getAmNodeLabelExpressionBytes());
      }
      for (int i = 0; i < appTimeouts_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(26, appTimeouts_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasUser() == other.hasUser());
      if (hasUser()) {
        result = result && getUser()
            .equals(other.getUser());
      }
      result = result && (hasQueue() == other.hasQueue());
      if (hasQueue()) {
        result = result && getQueue()
            .equals(other.getQueue());
      }
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasRpcPort() == other.hasRpcPort());
      if (hasRpcPort()) {
        result = result && (getRpcPort()
            == other.getRpcPort());
      }
      result = result && (hasClientToAmToken() == other.hasClientToAmToken());
      if (hasClientToAmToken()) {
        result = result && getClientToAmToken()
            .equals(other.getClientToAmToken());
      }
      result = result && (hasYarnApplicationState() == other.hasYarnApplicationState());
      if (hasYarnApplicationState()) {
        result = result &&
            (getYarnApplicationState() == other.getYarnApplicationState());
      }
      result = result && (hasTrackingUrl() == other.hasTrackingUrl());
      if (hasTrackingUrl()) {
        result = result && getTrackingUrl()
            .equals(other.getTrackingUrl());
      }
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result && (hasStartTime() == other.hasStartTime());
      if (hasStartTime()) {
        result = result && (getStartTime()
            == other.getStartTime());
      }
      result = result && (hasFinishTime() == other.hasFinishTime());
      if (hasFinishTime()) {
        result = result && (getFinishTime()
            == other.getFinishTime());
      }
      result = result && (hasFinalApplicationStatus() == other.hasFinalApplicationStatus());
      if (hasFinalApplicationStatus()) {
        result = result &&
            (getFinalApplicationStatus() == other.getFinalApplicationStatus());
      }
      result = result && (hasAppResourceUsage() == other.hasAppResourceUsage());
      if (hasAppResourceUsage()) {
        result = result && getAppResourceUsage()
            .equals(other.getAppResourceUsage());
      }
      result = result && (hasOriginalTrackingUrl() == other.hasOriginalTrackingUrl());
      if (hasOriginalTrackingUrl()) {
        result = result && getOriginalTrackingUrl()
            .equals(other.getOriginalTrackingUrl());
      }
      result = result && (hasCurrentApplicationAttemptId() == other.hasCurrentApplicationAttemptId());
      if (hasCurrentApplicationAttemptId()) {
        result = result && getCurrentApplicationAttemptId()
            .equals(other.getCurrentApplicationAttemptId());
      }
      result = result && (hasProgress() == other.hasProgress());
      if (hasProgress()) {
        result = result && (Float.floatToIntBits(getProgress())    == Float.floatToIntBits(other.getProgress()));
      }
      result = result && (hasApplicationType() == other.hasApplicationType());
      if (hasApplicationType()) {
        result = result && getApplicationType()
            .equals(other.getApplicationType());
      }
      result = result && (hasAmRmToken() == other.hasAmRmToken());
      if (hasAmRmToken()) {
        result = result && getAmRmToken()
            .equals(other.getAmRmToken());
      }
      result = result && getApplicationTagsList()
          .equals(other.getApplicationTagsList());
      result = result && (hasLogAggregationStatus() == other.hasLogAggregationStatus());
      if (hasLogAggregationStatus()) {
        result = result &&
            (getLogAggregationStatus() == other.getLogAggregationStatus());
      }
      result = result && (hasUnmanagedApplication() == other.hasUnmanagedApplication());
      if (hasUnmanagedApplication()) {
        result = result && (getUnmanagedApplication()
            == other.getUnmanagedApplication());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasAppNodeLabelExpression() == other.hasAppNodeLabelExpression());
      if (hasAppNodeLabelExpression()) {
        result = result && getAppNodeLabelExpression()
            .equals(other.getAppNodeLabelExpression());
      }
      result = result && (hasAmNodeLabelExpression() == other.hasAmNodeLabelExpression());
      if (hasAmNodeLabelExpression()) {
        result = result && getAmNodeLabelExpression()
            .equals(other.getAmNodeLabelExpression());
      }
      result = result && getAppTimeoutsList()
          .equals(other.getAppTimeoutsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATIONID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasUser()) {
        hash = (37 * hash) + USER_FIELD_NUMBER;
        hash = (53 * hash) + getUser().hashCode();
      }
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasRpcPort()) {
        hash = (37 * hash) + RPC_PORT_FIELD_NUMBER;
        hash = (53 * hash) + getRpcPort();
      }
      if (hasClientToAmToken()) {
        hash = (37 * hash) + CLIENT_TO_AM_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getClientToAmToken().hashCode();
      }
      if (hasYarnApplicationState()) {
        hash = (37 * hash) + YARN_APPLICATION_STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getYarnApplicationState());
      }
      if (hasTrackingUrl()) {
        hash = (37 * hash) + TRACKINGURL_FIELD_NUMBER;
        hash = (53 * hash) + getTrackingUrl().hashCode();
      }
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      if (hasStartTime()) {
        hash = (37 * hash) + STARTTIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getStartTime());
      }
      if (hasFinishTime()) {
        hash = (37 * hash) + FINISHTIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getFinishTime());
      }
      if (hasFinalApplicationStatus()) {
        hash = (37 * hash) + FINAL_APPLICATION_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getFinalApplicationStatus());
      }
      if (hasAppResourceUsage()) {
        hash = (37 * hash) + APP_RESOURCE_USAGE_FIELD_NUMBER;
        hash = (53 * hash) + getAppResourceUsage().hashCode();
      }
      if (hasOriginalTrackingUrl()) {
        hash = (37 * hash) + ORIGINALTRACKINGURL_FIELD_NUMBER;
        hash = (53 * hash) + getOriginalTrackingUrl().hashCode();
      }
      if (hasCurrentApplicationAttemptId()) {
        hash = (37 * hash) + CURRENTAPPLICATIONATTEMPTID_FIELD_NUMBER;
        hash = (53 * hash) + getCurrentApplicationAttemptId().hashCode();
      }
      if (hasProgress()) {
        hash = (37 * hash) + PROGRESS_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getProgress());
      }
      if (hasApplicationType()) {
        hash = (37 * hash) + APPLICATIONTYPE_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationType().hashCode();
      }
      if (hasAmRmToken()) {
        hash = (37 * hash) + AM_RM_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getAmRmToken().hashCode();
      }
      if (getApplicationTagsCount() > 0) {
        hash = (37 * hash) + APPLICATIONTAGS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationTagsList().hashCode();
      }
      if (hasLogAggregationStatus()) {
        hash = (37 * hash) + LOG_AGGREGATION_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getLogAggregationStatus());
      }
      if (hasUnmanagedApplication()) {
        hash = (37 * hash) + UNMANAGED_APPLICATION_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getUnmanagedApplication());
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasAppNodeLabelExpression()) {
        hash = (37 * hash) + APPNODELABELEXPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + getAppNodeLabelExpression().hashCode();
      }
      if (hasAmNodeLabelExpression()) {
        hash = (37 * hash) + AMNODELABELEXPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + getAmNodeLabelExpression().hashCode();
      }
      if (getAppTimeoutsCount() > 0) {
        hash = (37 * hash) + APPTIMEOUTS_FIELD_NUMBER;
        hash = (53 * hash) + getAppTimeoutsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
          getClientToAmTokenFieldBuilder();
          getAppResourceUsageFieldBuilder();
          getCurrentApplicationAttemptIdFieldBuilder();
          getAmRmTokenFieldBuilder();
          getPriorityFieldBuilder();
          getAppTimeoutsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        user_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        queue_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        rpcPort_ = 0;
        bitField0_ = (bitField0_ & ~0x00000020);
        if (clientToAmTokenBuilder_ == null) {
          clientToAmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
        } else {
          clientToAmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        yarnApplicationState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.NEW;
        bitField0_ = (bitField0_ & ~0x00000080);
        trackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000100);
        diagnostics_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000200);
        startTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000400);
        finishTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000800);
        finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
        bitField0_ = (bitField0_ & ~0x00001000);
        if (appResourceUsageBuilder_ == null) {
          appResourceUsage_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance();
        } else {
          appResourceUsageBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        originalTrackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00004000);
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
        } else {
          currentApplicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00008000);
        progress_ = 0F;
        bitField0_ = (bitField0_ & ~0x00010000);
        applicationType_ = "";
        bitField0_ = (bitField0_ & ~0x00020000);
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
        } else {
          amRmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00040000);
        applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00080000);
        logAggregationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto.LOG_DISABLED;
        bitField0_ = (bitField0_ & ~0x00100000);
        unmanagedApplication_ = false;
        bitField0_ = (bitField0_ & ~0x00200000);
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00400000);
        appNodeLabelExpression_ = "";
        bitField0_ = (bitField0_ & ~0x00800000);
        amNodeLabelExpression_ = "";
        bitField0_ = (bitField0_ & ~0x01000000);
        if (appTimeoutsBuilder_ == null) {
          appTimeouts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x02000000);
        } else {
          appTimeoutsBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.user_ = user_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.queue_ = queue_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.name_ = name_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.rpcPort_ = rpcPort_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        if (clientToAmTokenBuilder_ == null) {
          result.clientToAmToken_ = clientToAmToken_;
        } else {
          result.clientToAmToken_ = clientToAmTokenBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.yarnApplicationState_ = yarnApplicationState_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.trackingUrl_ = trackingUrl_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.diagnostics_ = diagnostics_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000400;
        }
        result.startTime_ = startTime_;
        if (((from_bitField0_ & 0x00000800) == 0x00000800)) {
          to_bitField0_ |= 0x00000800;
        }
        result.finishTime_ = finishTime_;
        if (((from_bitField0_ & 0x00001000) == 0x00001000)) {
          to_bitField0_ |= 0x00001000;
        }
        result.finalApplicationStatus_ = finalApplicationStatus_;
        if (((from_bitField0_ & 0x00002000) == 0x00002000)) {
          to_bitField0_ |= 0x00002000;
        }
        if (appResourceUsageBuilder_ == null) {
          result.appResourceUsage_ = appResourceUsage_;
        } else {
          result.appResourceUsage_ = appResourceUsageBuilder_.build();
        }
        if (((from_bitField0_ & 0x00004000) == 0x00004000)) {
          to_bitField0_ |= 0x00004000;
        }
        result.originalTrackingUrl_ = originalTrackingUrl_;
        if (((from_bitField0_ & 0x00008000) == 0x00008000)) {
          to_bitField0_ |= 0x00008000;
        }
        if (currentApplicationAttemptIdBuilder_ == null) {
          result.currentApplicationAttemptId_ = currentApplicationAttemptId_;
        } else {
          result.currentApplicationAttemptId_ = currentApplicationAttemptIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00010000) == 0x00010000)) {
          to_bitField0_ |= 0x00010000;
        }
        result.progress_ = progress_;
        if (((from_bitField0_ & 0x00020000) == 0x00020000)) {
          to_bitField0_ |= 0x00020000;
        }
        result.applicationType_ = applicationType_;
        if (((from_bitField0_ & 0x00040000) == 0x00040000)) {
          to_bitField0_ |= 0x00040000;
        }
        if (amRmTokenBuilder_ == null) {
          result.amRmToken_ = amRmToken_;
        } else {
          result.amRmToken_ = amRmTokenBuilder_.build();
        }
        if (((bitField0_ & 0x00080000) == 0x00080000)) {
          applicationTags_ = new com.google.protobuf.UnmodifiableLazyStringList(
              applicationTags_);
          bitField0_ = (bitField0_ & ~0x00080000);
        }
        result.applicationTags_ = applicationTags_;
        if (((from_bitField0_ & 0x00100000) == 0x00100000)) {
          to_bitField0_ |= 0x00080000;
        }
        result.logAggregationStatus_ = logAggregationStatus_;
        if (((from_bitField0_ & 0x00200000) == 0x00200000)) {
          to_bitField0_ |= 0x00100000;
        }
        result.unmanagedApplication_ = unmanagedApplication_;
        if (((from_bitField0_ & 0x00400000) == 0x00400000)) {
          to_bitField0_ |= 0x00200000;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00800000) == 0x00800000)) {
          to_bitField0_ |= 0x00400000;
        }
        result.appNodeLabelExpression_ = appNodeLabelExpression_;
        if (((from_bitField0_ & 0x01000000) == 0x01000000)) {
          to_bitField0_ |= 0x00800000;
        }
        result.amNodeLabelExpression_ = amNodeLabelExpression_;
        if (appTimeoutsBuilder_ == null) {
          if (((bitField0_ & 0x02000000) == 0x02000000)) {
            appTimeouts_ = java.util.Collections.unmodifiableList(appTimeouts_);
            bitField0_ = (bitField0_ & ~0x02000000);
          }
          result.appTimeouts_ = appTimeouts_;
        } else {
          result.appTimeouts_ = appTimeoutsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasUser()) {
          bitField0_ |= 0x00000002;
          user_ = other.user_;
          onChanged();
        }
        if (other.hasQueue()) {
          bitField0_ |= 0x00000004;
          queue_ = other.queue_;
          onChanged();
        }
        if (other.hasName()) {
          bitField0_ |= 0x00000008;
          name_ = other.name_;
          onChanged();
        }
        if (other.hasHost()) {
          bitField0_ |= 0x00000010;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasRpcPort()) {
          setRpcPort(other.getRpcPort());
        }
        if (other.hasClientToAmToken()) {
          mergeClientToAmToken(other.getClientToAmToken());
        }
        if (other.hasYarnApplicationState()) {
          setYarnApplicationState(other.getYarnApplicationState());
        }
        if (other.hasTrackingUrl()) {
          bitField0_ |= 0x00000100;
          trackingUrl_ = other.trackingUrl_;
          onChanged();
        }
        if (other.hasDiagnostics()) {
          bitField0_ |= 0x00000200;
          diagnostics_ = other.diagnostics_;
          onChanged();
        }
        if (other.hasStartTime()) {
          setStartTime(other.getStartTime());
        }
        if (other.hasFinishTime()) {
          setFinishTime(other.getFinishTime());
        }
        if (other.hasFinalApplicationStatus()) {
          setFinalApplicationStatus(other.getFinalApplicationStatus());
        }
        if (other.hasAppResourceUsage()) {
          mergeAppResourceUsage(other.getAppResourceUsage());
        }
        if (other.hasOriginalTrackingUrl()) {
          bitField0_ |= 0x00004000;
          originalTrackingUrl_ = other.originalTrackingUrl_;
          onChanged();
        }
        if (other.hasCurrentApplicationAttemptId()) {
          mergeCurrentApplicationAttemptId(other.getCurrentApplicationAttemptId());
        }
        if (other.hasProgress()) {
          setProgress(other.getProgress());
        }
        if (other.hasApplicationType()) {
          bitField0_ |= 0x00020000;
          applicationType_ = other.applicationType_;
          onChanged();
        }
        if (other.hasAmRmToken()) {
          mergeAmRmToken(other.getAmRmToken());
        }
        if (!other.applicationTags_.isEmpty()) {
          if (applicationTags_.isEmpty()) {
            applicationTags_ = other.applicationTags_;
            bitField0_ = (bitField0_ & ~0x00080000);
          } else {
            ensureApplicationTagsIsMutable();
            applicationTags_.addAll(other.applicationTags_);
          }
          onChanged();
        }
        if (other.hasLogAggregationStatus()) {
          setLogAggregationStatus(other.getLogAggregationStatus());
        }
        if (other.hasUnmanagedApplication()) {
          setUnmanagedApplication(other.getUnmanagedApplication());
        }
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasAppNodeLabelExpression()) {
          bitField0_ |= 0x00800000;
          appNodeLabelExpression_ = other.appNodeLabelExpression_;
          onChanged();
        }
        if (other.hasAmNodeLabelExpression()) {
          bitField0_ |= 0x01000000;
          amNodeLabelExpression_ = other.amNodeLabelExpression_;
          onChanged();
        }
        if (appTimeoutsBuilder_ == null) {
          if (!other.appTimeouts_.isEmpty()) {
            if (appTimeouts_.isEmpty()) {
              appTimeouts_ = other.appTimeouts_;
              bitField0_ = (bitField0_ & ~0x02000000);
            } else {
              ensureAppTimeoutsIsMutable();
              appTimeouts_.addAll(other.appTimeouts_);
            }
            onChanged();
          }
        } else {
          if (!other.appTimeouts_.isEmpty()) {
            if (appTimeoutsBuilder_.isEmpty()) {
              appTimeoutsBuilder_.dispose();
              appTimeoutsBuilder_ = null;
              appTimeouts_ = other.appTimeouts_;
              bitField0_ = (bitField0_ & ~0x02000000);
              appTimeoutsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAppTimeoutsFieldBuilder() : null;
            } else {
              appTimeoutsBuilder_.addAllMessages(other.appTimeouts_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasClientToAmToken()) {
          if (!getClientToAmToken().isInitialized()) {
            
            return false;
          }
        }
        if (hasAmRmToken()) {
          if (!getAmRmToken().isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getAppTimeoutsCount(); i++) {
          if (!getAppTimeouts(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto applicationId = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  applicationId_,
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      // optional string user = 2;
      private java.lang.Object user_ = "";
      /**
       * <code>optional string user = 2;</code>
       */
      public boolean hasUser() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public java.lang.String getUser() {
        java.lang.Object ref = user_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          user_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public com.google.protobuf.ByteString
          getUserBytes() {
        java.lang.Object ref = user_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          user_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public Builder setUser(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        user_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public Builder clearUser() {
        bitField0_ = (bitField0_ & ~0x00000002);
        user_ = getDefaultInstance().getUser();
        onChanged();
        return this;
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public Builder setUserBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        user_ = value;
        onChanged();
        return this;
      }

      // optional string queue = 3;
      private java.lang.Object queue_ = "";
      /**
       * <code>optional string queue = 3;</code>
       */
      public boolean hasQueue() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public java.lang.String getQueue() {
        java.lang.Object ref = queue_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          queue_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public com.google.protobuf.ByteString
          getQueueBytes() {
        java.lang.Object ref = queue_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queue_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public Builder setQueue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public Builder clearQueue() {
        bitField0_ = (bitField0_ & ~0x00000004);
        queue_ = getDefaultInstance().getQueue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public Builder setQueueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }

      // optional string name = 4;
      private java.lang.Object name_ = "";
      /**
       * <code>optional string name = 4;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000008);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        name_ = value;
        onChanged();
        return this;
      }

      // optional string host = 5;
      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 5;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          host_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000010);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        host_ = value;
        onChanged();
        return this;
      }

      // optional int32 rpc_port = 6;
      private int rpcPort_ ;
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public boolean hasRpcPort() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public int getRpcPort() {
        return rpcPort_;
      }
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public Builder setRpcPort(int value) {
        bitField0_ |= 0x00000020;
        rpcPort_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public Builder clearRpcPort() {
        bitField0_ = (bitField0_ & ~0x00000020);
        rpcPort_ = 0;
        onChanged();
        return this;
      }

      // optional .hadoop.common.TokenProto client_to_am_token = 7;
      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto clientToAmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> clientToAmTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public boolean hasClientToAmToken() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getClientToAmToken() {
        if (clientToAmTokenBuilder_ == null) {
          return clientToAmToken_;
        } else {
          return clientToAmTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder setClientToAmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (clientToAmTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          clientToAmToken_ = value;
          onChanged();
        } else {
          clientToAmTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder setClientToAmToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (clientToAmTokenBuilder_ == null) {
          clientToAmToken_ = builderForValue.build();
          onChanged();
        } else {
          clientToAmTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder mergeClientToAmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (clientToAmTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040) &&
              clientToAmToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            clientToAmToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(clientToAmToken_).mergeFrom(value).buildPartial();
          } else {
            clientToAmToken_ = value;
          }
          onChanged();
        } else {
          clientToAmTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder clearClientToAmToken() {
        if (clientToAmTokenBuilder_ == null) {
          clientToAmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
          onChanged();
        } else {
          clientToAmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getClientToAmTokenBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getClientToAmTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getClientToAmTokenOrBuilder() {
        if (clientToAmTokenBuilder_ != null) {
          return clientToAmTokenBuilder_.getMessageOrBuilder();
        } else {
          return clientToAmToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getClientToAmTokenFieldBuilder() {
        if (clientToAmTokenBuilder_ == null) {
          clientToAmTokenBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  clientToAmToken_,
                  getParentForChildren(),
                  isClean());
          clientToAmToken_ = null;
        }
        return clientToAmTokenBuilder_;
      }

      // optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;
      private org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto yarnApplicationState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.NEW;
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public boolean hasYarnApplicationState() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getYarnApplicationState() {
        return yarnApplicationState_;
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public Builder setYarnApplicationState(org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000080;
        yarnApplicationState_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public Builder clearYarnApplicationState() {
        bitField0_ = (bitField0_ & ~0x00000080);
        yarnApplicationState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.NEW;
        onChanged();
        return this;
      }

      // optional string trackingUrl = 9;
      private java.lang.Object trackingUrl_ = "";
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public boolean hasTrackingUrl() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public java.lang.String getTrackingUrl() {
        java.lang.Object ref = trackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          trackingUrl_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public com.google.protobuf.ByteString
          getTrackingUrlBytes() {
        java.lang.Object ref = trackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          trackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public Builder setTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000100;
        trackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public Builder clearTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00000100);
        trackingUrl_ = getDefaultInstance().getTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public Builder setTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000100;
        trackingUrl_ = value;
        onChanged();
        return this;
      }

      // optional string diagnostics = 10 [default = "N/A"];
      private java.lang.Object diagnostics_ = "N/A";
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          diagnostics_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsBytes() {
        java.lang.Object ref = diagnostics_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnostics_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public Builder setDiagnostics(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000200);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        diagnostics_ = value;
        onChanged();
        return this;
      }

      // optional int64 startTime = 11;
      private long startTime_ ;
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public boolean hasStartTime() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public long getStartTime() {
        return startTime_;
      }
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public Builder setStartTime(long value) {
        bitField0_ |= 0x00000400;
        startTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public Builder clearStartTime() {
        bitField0_ = (bitField0_ & ~0x00000400);
        startTime_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 finishTime = 12;
      private long finishTime_ ;
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public boolean hasFinishTime() {
        return ((bitField0_ & 0x00000800) == 0x00000800);
      }
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public long getFinishTime() {
        return finishTime_;
      }
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public Builder setFinishTime(long value) {
        bitField0_ |= 0x00000800;
        finishTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public Builder clearFinishTime() {
        bitField0_ = (bitField0_ & ~0x00000800);
        finishTime_ = 0L;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;
      private org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public boolean hasFinalApplicationStatus() {
        return ((bitField0_ & 0x00001000) == 0x00001000);
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus() {
        return finalApplicationStatus_;
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public Builder setFinalApplicationStatus(org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00001000;
        finalApplicationStatus_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public Builder clearFinalApplicationStatus() {
        bitField0_ = (bitField0_ & ~0x00001000);
        finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto appResourceUsage_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder> appResourceUsageBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public boolean hasAppResourceUsage() {
        return ((bitField0_ & 0x00002000) == 0x00002000);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getAppResourceUsage() {
        if (appResourceUsageBuilder_ == null) {
          return appResourceUsage_;
        } else {
          return appResourceUsageBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder setAppResourceUsage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto value) {
        if (appResourceUsageBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appResourceUsage_ = value;
          onChanged();
        } else {
          appResourceUsageBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder setAppResourceUsage(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder builderForValue) {
        if (appResourceUsageBuilder_ == null) {
          appResourceUsage_ = builderForValue.build();
          onChanged();
        } else {
          appResourceUsageBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder mergeAppResourceUsage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto value) {
        if (appResourceUsageBuilder_ == null) {
          if (((bitField0_ & 0x00002000) == 0x00002000) &&
              appResourceUsage_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance()) {
            appResourceUsage_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.newBuilder(appResourceUsage_).mergeFrom(value).buildPartial();
          } else {
            appResourceUsage_ = value;
          }
          onChanged();
        } else {
          appResourceUsageBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder clearAppResourceUsage() {
        if (appResourceUsageBuilder_ == null) {
          appResourceUsage_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance();
          onChanged();
        } else {
          appResourceUsageBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder getAppResourceUsageBuilder() {
        bitField0_ |= 0x00002000;
        onChanged();
        return getAppResourceUsageFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder getAppResourceUsageOrBuilder() {
        if (appResourceUsageBuilder_ != null) {
          return appResourceUsageBuilder_.getMessageOrBuilder();
        } else {
          return appResourceUsage_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder> 
          getAppResourceUsageFieldBuilder() {
        if (appResourceUsageBuilder_ == null) {
          appResourceUsageBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder>(
                  appResourceUsage_,
                  getParentForChildren(),
                  isClean());
          appResourceUsage_ = null;
        }
        return appResourceUsageBuilder_;
      }

      // optional string originalTrackingUrl = 15;
      private java.lang.Object originalTrackingUrl_ = "";
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public boolean hasOriginalTrackingUrl() {
        return ((bitField0_ & 0x00004000) == 0x00004000);
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public java.lang.String getOriginalTrackingUrl() {
        java.lang.Object ref = originalTrackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          originalTrackingUrl_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public com.google.protobuf.ByteString
          getOriginalTrackingUrlBytes() {
        java.lang.Object ref = originalTrackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          originalTrackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public Builder setOriginalTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00004000;
        originalTrackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public Builder clearOriginalTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00004000);
        originalTrackingUrl_ = getDefaultInstance().getOriginalTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public Builder setOriginalTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00004000;
        originalTrackingUrl_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto currentApplicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> currentApplicationAttemptIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public boolean hasCurrentApplicationAttemptId() {
        return ((bitField0_ & 0x00008000) == 0x00008000);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getCurrentApplicationAttemptId() {
        if (currentApplicationAttemptIdBuilder_ == null) {
          return currentApplicationAttemptId_;
        } else {
          return currentApplicationAttemptIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder setCurrentApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (currentApplicationAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          currentApplicationAttemptId_ = value;
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00008000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder setCurrentApplicationAttemptId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00008000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder mergeCurrentApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (currentApplicationAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00008000) == 0x00008000) &&
              currentApplicationAttemptId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            currentApplicationAttemptId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(currentApplicationAttemptId_).mergeFrom(value).buildPartial();
          } else {
            currentApplicationAttemptId_ = value;
          }
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00008000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder clearCurrentApplicationAttemptId() {
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00008000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getCurrentApplicationAttemptIdBuilder() {
        bitField0_ |= 0x00008000;
        onChanged();
        return getCurrentApplicationAttemptIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getCurrentApplicationAttemptIdOrBuilder() {
        if (currentApplicationAttemptIdBuilder_ != null) {
          return currentApplicationAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return currentApplicationAttemptId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getCurrentApplicationAttemptIdFieldBuilder() {
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  currentApplicationAttemptId_,
                  getParentForChildren(),
                  isClean());
          currentApplicationAttemptId_ = null;
        }
        return currentApplicationAttemptIdBuilder_;
      }

      // optional float progress = 17;
      private float progress_ ;
      /**
       * <code>optional float progress = 17;</code>
       */
      public boolean hasProgress() {
        return ((bitField0_ & 0x00010000) == 0x00010000);
      }
      /**
       * <code>optional float progress = 17;</code>
       */
      public float getProgress() {
        return progress_;
      }
      /**
       * <code>optional float progress = 17;</code>
       */
      public Builder setProgress(float value) {
        bitField0_ |= 0x00010000;
        progress_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float progress = 17;</code>
       */
      public Builder clearProgress() {
        bitField0_ = (bitField0_ & ~0x00010000);
        progress_ = 0F;
        onChanged();
        return this;
      }

      // optional string applicationType = 18;
      private java.lang.Object applicationType_ = "";
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public boolean hasApplicationType() {
        return ((bitField0_ & 0x00020000) == 0x00020000);
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public java.lang.String getApplicationType() {
        java.lang.Object ref = applicationType_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          applicationType_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTypeBytes() {
        java.lang.Object ref = applicationType_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          applicationType_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public Builder setApplicationType(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00020000;
        applicationType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public Builder clearApplicationType() {
        bitField0_ = (bitField0_ & ~0x00020000);
        applicationType_ = getDefaultInstance().getApplicationType();
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public Builder setApplicationTypeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00020000;
        applicationType_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.common.TokenProto am_rm_token = 19;
      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto amRmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> amRmTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public boolean hasAmRmToken() {
        return ((bitField0_ & 0x00040000) == 0x00040000);
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken() {
        if (amRmTokenBuilder_ == null) {
          return amRmToken_;
        } else {
          return amRmTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder setAmRmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (amRmTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          amRmToken_ = value;
          onChanged();
        } else {
          amRmTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00040000;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder setAmRmToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = builderForValue.build();
          onChanged();
        } else {
          amRmTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00040000;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder mergeAmRmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (amRmTokenBuilder_ == null) {
          if (((bitField0_ & 0x00040000) == 0x00040000) &&
              amRmToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            amRmToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(amRmToken_).mergeFrom(value).buildPartial();
          } else {
            amRmToken_ = value;
          }
          onChanged();
        } else {
          amRmTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00040000;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder clearAmRmToken() {
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
          onChanged();
        } else {
          amRmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00040000);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getAmRmTokenBuilder() {
        bitField0_ |= 0x00040000;
        onChanged();
        return getAmRmTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder() {
        if (amRmTokenBuilder_ != null) {
          return amRmTokenBuilder_.getMessageOrBuilder();
        } else {
          return amRmToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getAmRmTokenFieldBuilder() {
        if (amRmTokenBuilder_ == null) {
          amRmTokenBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  amRmToken_,
                  getParentForChildren(),
                  isClean());
          amRmToken_ = null;
        }
        return amRmTokenBuilder_;
      }

      // repeated string applicationTags = 20;
      private com.google.protobuf.LazyStringList applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureApplicationTagsIsMutable() {
        if (!((bitField0_ & 0x00080000) == 0x00080000)) {
          applicationTags_ = new com.google.protobuf.LazyStringArrayList(applicationTags_);
          bitField0_ |= 0x00080000;
         }
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public java.util.List<java.lang.String>
          getApplicationTagsList() {
        return java.util.Collections.unmodifiableList(applicationTags_);
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public int getApplicationTagsCount() {
        return applicationTags_.size();
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public java.lang.String getApplicationTags(int index) {
        return applicationTags_.get(index);
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTagsBytes(int index) {
        return applicationTags_.getByteString(index);
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public Builder setApplicationTags(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public Builder addApplicationTags(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public Builder addAllApplicationTags(
          java.lang.Iterable<java.lang.String> values) {
        ensureApplicationTagsIsMutable();
        super.addAll(values, applicationTags_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public Builder clearApplicationTags() {
        applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00080000);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public Builder addApplicationTagsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.add(value);
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 21;
      private org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto logAggregationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto.LOG_DISABLED;
      /**
       * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 21;</code>
       */
      public boolean hasLogAggregationStatus() {
        return ((bitField0_ & 0x00100000) == 0x00100000);
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 21;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto getLogAggregationStatus() {
        return logAggregationStatus_;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 21;</code>
       */
      public Builder setLogAggregationStatus(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00100000;
        logAggregationStatus_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 21;</code>
       */
      public Builder clearLogAggregationStatus() {
        bitField0_ = (bitField0_ & ~0x00100000);
        logAggregationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto.LOG_DISABLED;
        onChanged();
        return this;
      }

      // optional bool unmanaged_application = 22 [default = false];
      private boolean unmanagedApplication_ ;
      /**
       * <code>optional bool unmanaged_application = 22 [default = false];</code>
       */
      public boolean hasUnmanagedApplication() {
        return ((bitField0_ & 0x00200000) == 0x00200000);
      }
      /**
       * <code>optional bool unmanaged_application = 22 [default = false];</code>
       */
      public boolean getUnmanagedApplication() {
        return unmanagedApplication_;
      }
      /**
       * <code>optional bool unmanaged_application = 22 [default = false];</code>
       */
      public Builder setUnmanagedApplication(boolean value) {
        bitField0_ |= 0x00200000;
        unmanagedApplication_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool unmanaged_application = 22 [default = false];</code>
       */
      public Builder clearUnmanagedApplication() {
        bitField0_ = (bitField0_ & ~0x00200000);
        unmanagedApplication_ = false;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.PriorityProto priority = 23;
      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00400000) == 0x00400000);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00400000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00400000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00400000) == 0x00400000) &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00400000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00400000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00400000;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 23;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  priority_,
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      // optional string appNodeLabelExpression = 24;
      private java.lang.Object appNodeLabelExpression_ = "";
      /**
       * <code>optional string appNodeLabelExpression = 24;</code>
       */
      public boolean hasAppNodeLabelExpression() {
        return ((bitField0_ & 0x00800000) == 0x00800000);
      }
      /**
       * <code>optional string appNodeLabelExpression = 24;</code>
       */
      public java.lang.String getAppNodeLabelExpression() {
        java.lang.Object ref = appNodeLabelExpression_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          appNodeLabelExpression_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string appNodeLabelExpression = 24;</code>
       */
      public com.google.protobuf.ByteString
          getAppNodeLabelExpressionBytes() {
        java.lang.Object ref = appNodeLabelExpression_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          appNodeLabelExpression_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string appNodeLabelExpression = 24;</code>
       */
      public Builder setAppNodeLabelExpression(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00800000;
        appNodeLabelExpression_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string appNodeLabelExpression = 24;</code>
       */
      public Builder clearAppNodeLabelExpression() {
        bitField0_ = (bitField0_ & ~0x00800000);
        appNodeLabelExpression_ = getDefaultInstance().getAppNodeLabelExpression();
        onChanged();
        return this;
      }
      /**
       * <code>optional string appNodeLabelExpression = 24;</code>
       */
      public Builder setAppNodeLabelExpressionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00800000;
        appNodeLabelExpression_ = value;
        onChanged();
        return this;
      }

      // optional string amNodeLabelExpression = 25;
      private java.lang.Object amNodeLabelExpression_ = "";
      /**
       * <code>optional string amNodeLabelExpression = 25;</code>
       */
      public boolean hasAmNodeLabelExpression() {
        return ((bitField0_ & 0x01000000) == 0x01000000);
      }
      /**
       * <code>optional string amNodeLabelExpression = 25;</code>
       */
      public java.lang.String getAmNodeLabelExpression() {
        java.lang.Object ref = amNodeLabelExpression_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          amNodeLabelExpression_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string amNodeLabelExpression = 25;</code>
       */
      public com.google.protobuf.ByteString
          getAmNodeLabelExpressionBytes() {
        java.lang.Object ref = amNodeLabelExpression_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          amNodeLabelExpression_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string amNodeLabelExpression = 25;</code>
       */
      public Builder setAmNodeLabelExpression(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x01000000;
        amNodeLabelExpression_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string amNodeLabelExpression = 25;</code>
       */
      public Builder clearAmNodeLabelExpression() {
        bitField0_ = (bitField0_ & ~0x01000000);
        amNodeLabelExpression_ = getDefaultInstance().getAmNodeLabelExpression();
        onChanged();
        return this;
      }
      /**
       * <code>optional string amNodeLabelExpression = 25;</code>
       */
      public Builder setAmNodeLabelExpressionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x01000000;
        amNodeLabelExpression_ = value;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto> appTimeouts_ =
        java.util.Collections.emptyList();
      private void ensureAppTimeoutsIsMutable() {
        if (!((bitField0_ & 0x02000000) == 0x02000000)) {
          appTimeouts_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto>(appTimeouts_);
          bitField0_ |= 0x02000000;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProtoOrBuilder> appTimeoutsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto> getAppTimeoutsList() {
        if (appTimeoutsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(appTimeouts_);
        } else {
          return appTimeoutsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public int getAppTimeoutsCount() {
        if (appTimeoutsBuilder_ == null) {
          return appTimeouts_.size();
        } else {
          return appTimeoutsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto getAppTimeouts(int index) {
        if (appTimeoutsBuilder_ == null) {
          return appTimeouts_.get(index);
        } else {
          return appTimeoutsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public Builder setAppTimeouts(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto value) {
        if (appTimeoutsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAppTimeoutsIsMutable();
          appTimeouts_.set(index, value);
          onChanged();
        } else {
          appTimeoutsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public Builder setAppTimeouts(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder builderForValue) {
        if (appTimeoutsBuilder_ == null) {
          ensureAppTimeoutsIsMutable();
          appTimeouts_.set(index, builderForValue.build());
          onChanged();
        } else {
          appTimeoutsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public Builder addAppTimeouts(org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto value) {
        if (appTimeoutsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAppTimeoutsIsMutable();
          appTimeouts_.add(value);
          onChanged();
        } else {
          appTimeoutsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public Builder addAppTimeouts(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto value) {
        if (appTimeoutsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAppTimeoutsIsMutable();
          appTimeouts_.add(index, value);
          onChanged();
        } else {
          appTimeoutsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public Builder addAppTimeouts(
          org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder builderForValue) {
        if (appTimeoutsBuilder_ == null) {
          ensureAppTimeoutsIsMutable();
          appTimeouts_.add(builderForValue.build());
          onChanged();
        } else {
          appTimeoutsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public Builder addAppTimeouts(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder builderForValue) {
        if (appTimeoutsBuilder_ == null) {
          ensureAppTimeoutsIsMutable();
          appTimeouts_.add(index, builderForValue.build());
          onChanged();
        } else {
          appTimeoutsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public Builder addAllAppTimeouts(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto> values) {
        if (appTimeoutsBuilder_ == null) {
          ensureAppTimeoutsIsMutable();
          super.addAll(values, appTimeouts_);
          onChanged();
        } else {
          appTimeoutsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public Builder clearAppTimeouts() {
        if (appTimeoutsBuilder_ == null) {
          appTimeouts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x02000000);
          onChanged();
        } else {
          appTimeoutsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public Builder removeAppTimeouts(int index) {
        if (appTimeoutsBuilder_ == null) {
          ensureAppTimeoutsIsMutable();
          appTimeouts_.remove(index);
          onChanged();
        } else {
          appTimeoutsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder getAppTimeoutsBuilder(
          int index) {
        return getAppTimeoutsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProtoOrBuilder getAppTimeoutsOrBuilder(
          int index) {
        if (appTimeoutsBuilder_ == null) {
          return appTimeouts_.get(index);  } else {
          return appTimeoutsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProtoOrBuilder> 
           getAppTimeoutsOrBuilderList() {
        if (appTimeoutsBuilder_ != null) {
          return appTimeoutsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(appTimeouts_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder addAppTimeoutsBuilder() {
        return getAppTimeoutsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder addAppTimeoutsBuilder(
          int index) {
        return getAppTimeoutsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.AppTimeoutsMapProto appTimeouts = 26;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder> 
           getAppTimeoutsBuilderList() {
        return getAppTimeoutsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProtoOrBuilder> 
          getAppTimeoutsFieldBuilder() {
        if (appTimeoutsBuilder_ == null) {
          appTimeoutsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProtoOrBuilder>(
                  appTimeouts_,
                  ((bitField0_ & 0x02000000) == 0x02000000),
                  getParentForChildren(),
                  isClean());
          appTimeouts_ = null;
        }
        return appTimeoutsBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationReportProto)
    }

    static {
      defaultInstance = new ApplicationReportProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationReportProto)
  }

  public interface AppTimeoutsMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    boolean hasApplicationTimeoutType();
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType();

    // optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
     */
    boolean hasApplicationTimeout();
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto getApplicationTimeout();
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProtoOrBuilder getApplicationTimeoutOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.AppTimeoutsMapProto}
   */
  public static final class AppTimeoutsMapProto extends
      com.google.protobuf.GeneratedMessage
      implements AppTimeoutsMapProtoOrBuilder {
    // Use AppTimeoutsMapProto.newBuilder() to construct.
    private AppTimeoutsMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private AppTimeoutsMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final AppTimeoutsMapProto defaultInstance;
    public static AppTimeoutsMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public AppTimeoutsMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private AppTimeoutsMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                applicationTimeoutType_ = value;
              }
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = applicationTimeout_.toBuilder();
              }
              applicationTimeout_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationTimeout_);
                applicationTimeout_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_AppTimeoutsMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_AppTimeoutsMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<AppTimeoutsMapProto> PARSER =
        new com.google.protobuf.AbstractParser<AppTimeoutsMapProto>() {
      public AppTimeoutsMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new AppTimeoutsMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<AppTimeoutsMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
    public static final int APPLICATION_TIMEOUT_TYPE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto applicationTimeoutType_;
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    public boolean hasApplicationTimeoutType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType() {
      return applicationTimeoutType_;
    }

    // optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;
    public static final int APPLICATION_TIMEOUT_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto applicationTimeout_;
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
     */
    public boolean hasApplicationTimeout() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto getApplicationTimeout() {
      return applicationTimeout_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProtoOrBuilder getApplicationTimeoutOrBuilder() {
      return applicationTimeout_;
    }

    private void initFields() {
      applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
      applicationTimeout_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasApplicationTimeout()) {
        if (!getApplicationTimeout().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, applicationTimeoutType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, applicationTimeout_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, applicationTimeoutType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, applicationTimeout_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto) obj;

      boolean result = true;
      result = result && (hasApplicationTimeoutType() == other.hasApplicationTimeoutType());
      if (hasApplicationTimeoutType()) {
        result = result &&
            (getApplicationTimeoutType() == other.getApplicationTimeoutType());
      }
      result = result && (hasApplicationTimeout() == other.hasApplicationTimeout());
      if (hasApplicationTimeout()) {
        result = result && getApplicationTimeout()
            .equals(other.getApplicationTimeout());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationTimeoutType()) {
        hash = (37 * hash) + APPLICATION_TIMEOUT_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getApplicationTimeoutType());
      }
      if (hasApplicationTimeout()) {
        hash = (37 * hash) + APPLICATION_TIMEOUT_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationTimeout().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.AppTimeoutsMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_AppTimeoutsMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_AppTimeoutsMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationTimeoutFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (applicationTimeoutBuilder_ == null) {
          applicationTimeout_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.getDefaultInstance();
        } else {
          applicationTimeoutBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_AppTimeoutsMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.applicationTimeoutType_ = applicationTimeoutType_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (applicationTimeoutBuilder_ == null) {
          result.applicationTimeout_ = applicationTimeout_;
        } else {
          result.applicationTimeout_ = applicationTimeoutBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto.getDefaultInstance()) return this;
        if (other.hasApplicationTimeoutType()) {
          setApplicationTimeoutType(other.getApplicationTimeoutType());
        }
        if (other.hasApplicationTimeout()) {
          mergeApplicationTimeout(other.getApplicationTimeout());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasApplicationTimeout()) {
          if (!getApplicationTimeout().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.AppTimeoutsMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public boolean hasApplicationTimeoutType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType() {
        return applicationTimeoutType_;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public Builder setApplicationTimeoutType(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        applicationTimeoutType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public Builder clearApplicationTimeoutType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto applicationTimeout_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProtoOrBuilder> applicationTimeoutBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
       */
      public boolean hasApplicationTimeout() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto getApplicationTimeout() {
        if (applicationTimeoutBuilder_ == null) {
          return applicationTimeout_;
        } else {
          return applicationTimeoutBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
       */
      public Builder setApplicationTimeout(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto value) {
        if (applicationTimeoutBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationTimeout_ = value;
          onChanged();
        } else {
          applicationTimeoutBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
       */
      public Builder setApplicationTimeout(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.Builder builderForValue) {
        if (applicationTimeoutBuilder_ == null) {
          applicationTimeout_ = builderForValue.build();
          onChanged();
        } else {
          applicationTimeoutBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
       */
      public Builder mergeApplicationTimeout(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto value) {
        if (applicationTimeoutBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              applicationTimeout_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.getDefaultInstance()) {
            applicationTimeout_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.newBuilder(applicationTimeout_).mergeFrom(value).buildPartial();
          } else {
            applicationTimeout_ = value;
          }
          onChanged();
        } else {
          applicationTimeoutBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
       */
      public Builder clearApplicationTimeout() {
        if (applicationTimeoutBuilder_ == null) {
          applicationTimeout_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.getDefaultInstance();
          onChanged();
        } else {
          applicationTimeoutBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.Builder getApplicationTimeoutBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getApplicationTimeoutFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProtoOrBuilder getApplicationTimeoutOrBuilder() {
        if (applicationTimeoutBuilder_ != null) {
          return applicationTimeoutBuilder_.getMessageOrBuilder();
        } else {
          return applicationTimeout_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutProto application_timeout = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProtoOrBuilder> 
          getApplicationTimeoutFieldBuilder() {
        if (applicationTimeoutBuilder_ == null) {
          applicationTimeoutBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProtoOrBuilder>(
                  applicationTimeout_,
                  getParentForChildren(),
                  isClean());
          applicationTimeout_ = null;
        }
        return applicationTimeoutBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.AppTimeoutsMapProto)
    }

    static {
      defaultInstance = new AppTimeoutsMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.AppTimeoutsMapProto)
  }

  public interface ApplicationTimeoutProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
    /**
     * <code>required .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    boolean hasApplicationTimeoutType();
    /**
     * <code>required .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType();

    // optional string expire_time = 2;
    /**
     * <code>optional string expire_time = 2;</code>
     */
    boolean hasExpireTime();
    /**
     * <code>optional string expire_time = 2;</code>
     */
    java.lang.String getExpireTime();
    /**
     * <code>optional string expire_time = 2;</code>
     */
    com.google.protobuf.ByteString
        getExpireTimeBytes();

    // optional int64 remaining_time = 3;
    /**
     * <code>optional int64 remaining_time = 3;</code>
     */
    boolean hasRemainingTime();
    /**
     * <code>optional int64 remaining_time = 3;</code>
     */
    long getRemainingTime();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationTimeoutProto}
   */
  public static final class ApplicationTimeoutProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationTimeoutProtoOrBuilder {
    // Use ApplicationTimeoutProto.newBuilder() to construct.
    private ApplicationTimeoutProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationTimeoutProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationTimeoutProto defaultInstance;
    public static ApplicationTimeoutProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationTimeoutProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationTimeoutProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                applicationTimeoutType_ = value;
              }
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              expireTime_ = input.readBytes();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              remainingTime_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationTimeoutProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationTimeoutProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationTimeoutProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationTimeoutProto>() {
      public ApplicationTimeoutProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationTimeoutProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationTimeoutProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
    public static final int APPLICATION_TIMEOUT_TYPE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto applicationTimeoutType_;
    /**
     * <code>required .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    public boolean hasApplicationTimeoutType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType() {
      return applicationTimeoutType_;
    }

    // optional string expire_time = 2;
    public static final int EXPIRE_TIME_FIELD_NUMBER = 2;
    private java.lang.Object expireTime_;
    /**
     * <code>optional string expire_time = 2;</code>
     */
    public boolean hasExpireTime() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string expire_time = 2;</code>
     */
    public java.lang.String getExpireTime() {
      java.lang.Object ref = expireTime_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          expireTime_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string expire_time = 2;</code>
     */
    public com.google.protobuf.ByteString
        getExpireTimeBytes() {
      java.lang.Object ref = expireTime_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        expireTime_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int64 remaining_time = 3;
    public static final int REMAINING_TIME_FIELD_NUMBER = 3;
    private long remainingTime_;
    /**
     * <code>optional int64 remaining_time = 3;</code>
     */
    public boolean hasRemainingTime() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 remaining_time = 3;</code>
     */
    public long getRemainingTime() {
      return remainingTime_;
    }

    private void initFields() {
      applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
      expireTime_ = "";
      remainingTime_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasApplicationTimeoutType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, applicationTimeoutType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getExpireTimeBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, remainingTime_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, applicationTimeoutType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getExpireTimeBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, remainingTime_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto) obj;

      boolean result = true;
      result = result && (hasApplicationTimeoutType() == other.hasApplicationTimeoutType());
      if (hasApplicationTimeoutType()) {
        result = result &&
            (getApplicationTimeoutType() == other.getApplicationTimeoutType());
      }
      result = result && (hasExpireTime() == other.hasExpireTime());
      if (hasExpireTime()) {
        result = result && getExpireTime()
            .equals(other.getExpireTime());
      }
      result = result && (hasRemainingTime() == other.hasRemainingTime());
      if (hasRemainingTime()) {
        result = result && (getRemainingTime()
            == other.getRemainingTime());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationTimeoutType()) {
        hash = (37 * hash) + APPLICATION_TIMEOUT_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getApplicationTimeoutType());
      }
      if (hasExpireTime()) {
        hash = (37 * hash) + EXPIRE_TIME_FIELD_NUMBER;
        hash = (53 * hash) + getExpireTime().hashCode();
      }
      if (hasRemainingTime()) {
        hash = (37 * hash) + REMAINING_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getRemainingTime());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationTimeoutProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationTimeoutProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationTimeoutProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
        bitField0_ = (bitField0_ & ~0x00000001);
        expireTime_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        remainingTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationTimeoutProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.applicationTimeoutType_ = applicationTimeoutType_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.expireTime_ = expireTime_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.remainingTime_ = remainingTime_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto.getDefaultInstance()) return this;
        if (other.hasApplicationTimeoutType()) {
          setApplicationTimeoutType(other.getApplicationTimeoutType());
        }
        if (other.hasExpireTime()) {
          bitField0_ |= 0x00000002;
          expireTime_ = other.expireTime_;
          onChanged();
        }
        if (other.hasRemainingTime()) {
          setRemainingTime(other.getRemainingTime());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasApplicationTimeoutType()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
      /**
       * <code>required .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public boolean hasApplicationTimeoutType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType() {
        return applicationTimeoutType_;
      }
      /**
       * <code>required .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public Builder setApplicationTimeoutType(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        applicationTimeoutType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public Builder clearApplicationTimeoutType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
        onChanged();
        return this;
      }

      // optional string expire_time = 2;
      private java.lang.Object expireTime_ = "";
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public boolean hasExpireTime() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public java.lang.String getExpireTime() {
        java.lang.Object ref = expireTime_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          expireTime_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public com.google.protobuf.ByteString
          getExpireTimeBytes() {
        java.lang.Object ref = expireTime_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          expireTime_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public Builder setExpireTime(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        expireTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public Builder clearExpireTime() {
        bitField0_ = (bitField0_ & ~0x00000002);
        expireTime_ = getDefaultInstance().getExpireTime();
        onChanged();
        return this;
      }
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public Builder setExpireTimeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        expireTime_ = value;
        onChanged();
        return this;
      }

      // optional int64 remaining_time = 3;
      private long remainingTime_ ;
      /**
       * <code>optional int64 remaining_time = 3;</code>
       */
      public boolean hasRemainingTime() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 remaining_time = 3;</code>
       */
      public long getRemainingTime() {
        return remainingTime_;
      }
      /**
       * <code>optional int64 remaining_time = 3;</code>
       */
      public Builder setRemainingTime(long value) {
        bitField0_ |= 0x00000004;
        remainingTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 remaining_time = 3;</code>
       */
      public Builder clearRemainingTime() {
        bitField0_ = (bitField0_ & ~0x00000004);
        remainingTime_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationTimeoutProto)
    }

    static {
      defaultInstance = new ApplicationTimeoutProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationTimeoutProto)
  }

  public interface ApplicationAttemptReportProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    boolean hasApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder();

    // optional string host = 2;
    /**
     * <code>optional string host = 2;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 2;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 2;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    // optional int32 rpc_port = 3;
    /**
     * <code>optional int32 rpc_port = 3;</code>
     */
    boolean hasRpcPort();
    /**
     * <code>optional int32 rpc_port = 3;</code>
     */
    int getRpcPort();

    // optional string tracking_url = 4;
    /**
     * <code>optional string tracking_url = 4;</code>
     */
    boolean hasTrackingUrl();
    /**
     * <code>optional string tracking_url = 4;</code>
     */
    java.lang.String getTrackingUrl();
    /**
     * <code>optional string tracking_url = 4;</code>
     */
    com.google.protobuf.ByteString
        getTrackingUrlBytes();

    // optional string diagnostics = 5 [default = "N/A"];
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    boolean hasDiagnostics();
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    java.lang.String getDiagnostics();
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsBytes();

    // optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;
    /**
     * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
     */
    boolean hasYarnApplicationAttemptState();
    /**
     * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto getYarnApplicationAttemptState();

    // optional .hadoop.yarn.ContainerIdProto am_container_id = 7;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    boolean hasAmContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getAmContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getAmContainerIdOrBuilder();

    // optional string original_tracking_url = 8;
    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    boolean hasOriginalTrackingUrl();
    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    java.lang.String getOriginalTrackingUrl();
    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    com.google.protobuf.ByteString
        getOriginalTrackingUrlBytes();

    // optional int64 startTime = 9;
    /**
     * <code>optional int64 startTime = 9;</code>
     */
    boolean hasStartTime();
    /**
     * <code>optional int64 startTime = 9;</code>
     */
    long getStartTime();

    // optional int64 finishTime = 10;
    /**
     * <code>optional int64 finishTime = 10;</code>
     */
    boolean hasFinishTime();
    /**
     * <code>optional int64 finishTime = 10;</code>
     */
    long getFinishTime();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationAttemptReportProto}
   */
  public static final class ApplicationAttemptReportProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationAttemptReportProtoOrBuilder {
    // Use ApplicationAttemptReportProto.newBuilder() to construct.
    private ApplicationAttemptReportProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationAttemptReportProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationAttemptReportProto defaultInstance;
    public static ApplicationAttemptReportProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationAttemptReportProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationAttemptReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationAttemptId_.toBuilder();
              }
              applicationAttemptId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationAttemptId_);
                applicationAttemptId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              host_ = input.readBytes();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              rpcPort_ = input.readInt32();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              trackingUrl_ = input.readBytes();
              break;
            }
            case 42: {
              bitField0_ |= 0x00000010;
              diagnostics_ = input.readBytes();
              break;
            }
            case 48: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(6, rawValue);
              } else {
                bitField0_ |= 0x00000020;
                yarnApplicationAttemptState_ = value;
              }
              break;
            }
            case 58: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000040) == 0x00000040)) {
                subBuilder = amContainerId_.toBuilder();
              }
              amContainerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(amContainerId_);
                amContainerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000040;
              break;
            }
            case 66: {
              bitField0_ |= 0x00000080;
              originalTrackingUrl_ = input.readBytes();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              startTime_ = input.readInt64();
              break;
            }
            case 80: {
              bitField0_ |= 0x00000200;
              finishTime_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationAttemptReportProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationAttemptReportProto>() {
      public ApplicationAttemptReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationAttemptReportProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationAttemptReportProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;
    public static final int APPLICATION_ATTEMPT_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public boolean hasApplicationAttemptId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
      return applicationAttemptId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
      return applicationAttemptId_;
    }

    // optional string host = 2;
    public static final int HOST_FIELD_NUMBER = 2;
    private java.lang.Object host_;
    /**
     * <code>optional string host = 2;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string host = 2;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 2;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int32 rpc_port = 3;
    public static final int RPC_PORT_FIELD_NUMBER = 3;
    private int rpcPort_;
    /**
     * <code>optional int32 rpc_port = 3;</code>
     */
    public boolean hasRpcPort() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int32 rpc_port = 3;</code>
     */
    public int getRpcPort() {
      return rpcPort_;
    }

    // optional string tracking_url = 4;
    public static final int TRACKING_URL_FIELD_NUMBER = 4;
    private java.lang.Object trackingUrl_;
    /**
     * <code>optional string tracking_url = 4;</code>
     */
    public boolean hasTrackingUrl() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string tracking_url = 4;</code>
     */
    public java.lang.String getTrackingUrl() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          trackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string tracking_url = 4;</code>
     */
    public com.google.protobuf.ByteString
        getTrackingUrlBytes() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        trackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string diagnostics = 5 [default = "N/A"];
    public static final int DIAGNOSTICS_FIELD_NUMBER = 5;
    private java.lang.Object diagnostics_;
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;
    public static final int YARN_APPLICATION_ATTEMPT_STATE_FIELD_NUMBER = 6;
    private org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto yarnApplicationAttemptState_;
    /**
     * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
     */
    public boolean hasYarnApplicationAttemptState() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto getYarnApplicationAttemptState() {
      return yarnApplicationAttemptState_;
    }

    // optional .hadoop.yarn.ContainerIdProto am_container_id = 7;
    public static final int AM_CONTAINER_ID_FIELD_NUMBER = 7;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto amContainerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    public boolean hasAmContainerId() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getAmContainerId() {
      return amContainerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getAmContainerIdOrBuilder() {
      return amContainerId_;
    }

    // optional string original_tracking_url = 8;
    public static final int ORIGINAL_TRACKING_URL_FIELD_NUMBER = 8;
    private java.lang.Object originalTrackingUrl_;
    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    public boolean hasOriginalTrackingUrl() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    public java.lang.String getOriginalTrackingUrl() {
      java.lang.Object ref = originalTrackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          originalTrackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    public com.google.protobuf.ByteString
        getOriginalTrackingUrlBytes() {
      java.lang.Object ref = originalTrackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        originalTrackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int64 startTime = 9;
    public static final int STARTTIME_FIELD_NUMBER = 9;
    private long startTime_;
    /**
     * <code>optional int64 startTime = 9;</code>
     */
    public boolean hasStartTime() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional int64 startTime = 9;</code>
     */
    public long getStartTime() {
      return startTime_;
    }

    // optional int64 finishTime = 10;
    public static final int FINISHTIME_FIELD_NUMBER = 10;
    private long finishTime_;
    /**
     * <code>optional int64 finishTime = 10;</code>
     */
    public boolean hasFinishTime() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional int64 finishTime = 10;</code>
     */
    public long getFinishTime() {
      return finishTime_;
    }

    private void initFields() {
      applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      host_ = "";
      rpcPort_ = 0;
      trackingUrl_ = "";
      diagnostics_ = "N/A";
      yarnApplicationAttemptState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto.APP_ATTEMPT_NEW;
      amContainerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      originalTrackingUrl_ = "";
      startTime_ = 0L;
      finishTime_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationAttemptId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getHostBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(3, rpcPort_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(4, getTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBytes(5, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeEnum(6, yarnApplicationAttemptState_.getNumber());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeMessage(7, amContainerId_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeBytes(8, getOriginalTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeInt64(9, startTime_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeInt64(10, finishTime_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationAttemptId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getHostBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, rpcPort_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, getTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(5, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(6, yarnApplicationAttemptState_.getNumber());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, amContainerId_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(8, getOriginalTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(9, startTime_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(10, finishTime_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto) obj;

      boolean result = true;
      result = result && (hasApplicationAttemptId() == other.hasApplicationAttemptId());
      if (hasApplicationAttemptId()) {
        result = result && getApplicationAttemptId()
            .equals(other.getApplicationAttemptId());
      }
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasRpcPort() == other.hasRpcPort());
      if (hasRpcPort()) {
        result = result && (getRpcPort()
            == other.getRpcPort());
      }
      result = result && (hasTrackingUrl() == other.hasTrackingUrl());
      if (hasTrackingUrl()) {
        result = result && getTrackingUrl()
            .equals(other.getTrackingUrl());
      }
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result && (hasYarnApplicationAttemptState() == other.hasYarnApplicationAttemptState());
      if (hasYarnApplicationAttemptState()) {
        result = result &&
            (getYarnApplicationAttemptState() == other.getYarnApplicationAttemptState());
      }
      result = result && (hasAmContainerId() == other.hasAmContainerId());
      if (hasAmContainerId()) {
        result = result && getAmContainerId()
            .equals(other.getAmContainerId());
      }
      result = result && (hasOriginalTrackingUrl() == other.hasOriginalTrackingUrl());
      if (hasOriginalTrackingUrl()) {
        result = result && getOriginalTrackingUrl()
            .equals(other.getOriginalTrackingUrl());
      }
      result = result && (hasStartTime() == other.hasStartTime());
      if (hasStartTime()) {
        result = result && (getStartTime()
            == other.getStartTime());
      }
      result = result && (hasFinishTime() == other.hasFinishTime());
      if (hasFinishTime()) {
        result = result && (getFinishTime()
            == other.getFinishTime());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationAttemptId()) {
        hash = (37 * hash) + APPLICATION_ATTEMPT_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationAttemptId().hashCode();
      }
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasRpcPort()) {
        hash = (37 * hash) + RPC_PORT_FIELD_NUMBER;
        hash = (53 * hash) + getRpcPort();
      }
      if (hasTrackingUrl()) {
        hash = (37 * hash) + TRACKING_URL_FIELD_NUMBER;
        hash = (53 * hash) + getTrackingUrl().hashCode();
      }
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      if (hasYarnApplicationAttemptState()) {
        hash = (37 * hash) + YARN_APPLICATION_ATTEMPT_STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getYarnApplicationAttemptState());
      }
      if (hasAmContainerId()) {
        hash = (37 * hash) + AM_CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getAmContainerId().hashCode();
      }
      if (hasOriginalTrackingUrl()) {
        hash = (37 * hash) + ORIGINAL_TRACKING_URL_FIELD_NUMBER;
        hash = (53 * hash) + getOriginalTrackingUrl().hashCode();
      }
      if (hasStartTime()) {
        hash = (37 * hash) + STARTTIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getStartTime());
      }
      if (hasFinishTime()) {
        hash = (37 * hash) + FINISHTIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getFinishTime());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationAttemptReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationAttemptIdFieldBuilder();
          getAmContainerIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        rpcPort_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        trackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        diagnostics_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000010);
        yarnApplicationAttemptState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto.APP_ATTEMPT_NEW;
        bitField0_ = (bitField0_ & ~0x00000020);
        if (amContainerIdBuilder_ == null) {
          amContainerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          amContainerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        originalTrackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000080);
        startTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000100);
        finishTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000200);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationAttemptIdBuilder_ == null) {
          result.applicationAttemptId_ = applicationAttemptId_;
        } else {
          result.applicationAttemptId_ = applicationAttemptIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.rpcPort_ = rpcPort_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.trackingUrl_ = trackingUrl_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.diagnostics_ = diagnostics_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.yarnApplicationAttemptState_ = yarnApplicationAttemptState_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        if (amContainerIdBuilder_ == null) {
          result.amContainerId_ = amContainerId_;
        } else {
          result.amContainerId_ = amContainerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.originalTrackingUrl_ = originalTrackingUrl_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.startTime_ = startTime_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.finishTime_ = finishTime_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.getDefaultInstance()) return this;
        if (other.hasApplicationAttemptId()) {
          mergeApplicationAttemptId(other.getApplicationAttemptId());
        }
        if (other.hasHost()) {
          bitField0_ |= 0x00000002;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasRpcPort()) {
          setRpcPort(other.getRpcPort());
        }
        if (other.hasTrackingUrl()) {
          bitField0_ |= 0x00000008;
          trackingUrl_ = other.trackingUrl_;
          onChanged();
        }
        if (other.hasDiagnostics()) {
          bitField0_ |= 0x00000010;
          diagnostics_ = other.diagnostics_;
          onChanged();
        }
        if (other.hasYarnApplicationAttemptState()) {
          setYarnApplicationAttemptState(other.getYarnApplicationAttemptState());
        }
        if (other.hasAmContainerId()) {
          mergeAmContainerId(other.getAmContainerId());
        }
        if (other.hasOriginalTrackingUrl()) {
          bitField0_ |= 0x00000080;
          originalTrackingUrl_ = other.originalTrackingUrl_;
          onChanged();
        }
        if (other.hasStartTime()) {
          setStartTime(other.getStartTime());
        }
        if (other.hasFinishTime()) {
          setFinishTime(other.getFinishTime());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> applicationAttemptIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public boolean hasApplicationAttemptId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          return applicationAttemptId_;
        } else {
          return applicationAttemptIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder setApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationAttemptId_ = value;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder setApplicationAttemptId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder mergeApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationAttemptId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            applicationAttemptId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(applicationAttemptId_).mergeFrom(value).buildPartial();
          } else {
            applicationAttemptId_ = value;
          }
          onChanged();
        } else {
          applicationAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder clearApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getApplicationAttemptIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationAttemptIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
        if (applicationAttemptIdBuilder_ != null) {
          return applicationAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationAttemptId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getApplicationAttemptIdFieldBuilder() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  applicationAttemptId_,
                  getParentForChildren(),
                  isClean());
          applicationAttemptId_ = null;
        }
        return applicationAttemptIdBuilder_;
      }

      // optional string host = 2;
      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 2;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          host_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000002);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
        return this;
      }

      // optional int32 rpc_port = 3;
      private int rpcPort_ ;
      /**
       * <code>optional int32 rpc_port = 3;</code>
       */
      public boolean hasRpcPort() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int32 rpc_port = 3;</code>
       */
      public int getRpcPort() {
        return rpcPort_;
      }
      /**
       * <code>optional int32 rpc_port = 3;</code>
       */
      public Builder setRpcPort(int value) {
        bitField0_ |= 0x00000004;
        rpcPort_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 rpc_port = 3;</code>
       */
      public Builder clearRpcPort() {
        bitField0_ = (bitField0_ & ~0x00000004);
        rpcPort_ = 0;
        onChanged();
        return this;
      }

      // optional string tracking_url = 4;
      private java.lang.Object trackingUrl_ = "";
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public boolean hasTrackingUrl() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public java.lang.String getTrackingUrl() {
        java.lang.Object ref = trackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          trackingUrl_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public com.google.protobuf.ByteString
          getTrackingUrlBytes() {
        java.lang.Object ref = trackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          trackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public Builder setTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        trackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public Builder clearTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00000008);
        trackingUrl_ = getDefaultInstance().getTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public Builder setTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        trackingUrl_ = value;
        onChanged();
        return this;
      }

      // optional string diagnostics = 5 [default = "N/A"];
      private java.lang.Object diagnostics_ = "N/A";
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          diagnostics_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsBytes() {
        java.lang.Object ref = diagnostics_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnostics_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public Builder setDiagnostics(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000010);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        diagnostics_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;
      private org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto yarnApplicationAttemptState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto.APP_ATTEMPT_NEW;
      /**
       * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
       */
      public boolean hasYarnApplicationAttemptState() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto getYarnApplicationAttemptState() {
        return yarnApplicationAttemptState_;
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
       */
      public Builder setYarnApplicationAttemptState(org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000020;
        yarnApplicationAttemptState_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
       */
      public Builder clearYarnApplicationAttemptState() {
        bitField0_ = (bitField0_ & ~0x00000020);
        yarnApplicationAttemptState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto.APP_ATTEMPT_NEW;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ContainerIdProto am_container_id = 7;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto amContainerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> amContainerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public boolean hasAmContainerId() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getAmContainerId() {
        if (amContainerIdBuilder_ == null) {
          return amContainerId_;
        } else {
          return amContainerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public Builder setAmContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (amContainerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          amContainerId_ = value;
          onChanged();
        } else {
          amContainerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public Builder setAmContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (amContainerIdBuilder_ == null) {
          amContainerId_ = builderForValue.build();
          onChanged();
        } else {
          amContainerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public Builder mergeAmContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (amContainerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040) &&
              amContainerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            amContainerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(amContainerId_).mergeFrom(value).buildPartial();
          } else {
            amContainerId_ = value;
          }
          onChanged();
        } else {
          amContainerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public Builder clearAmContainerId() {
        if (amContainerIdBuilder_ == null) {
          amContainerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          amContainerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getAmContainerIdBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getAmContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getAmContainerIdOrBuilder() {
        if (amContainerIdBuilder_ != null) {
          return amContainerIdBuilder_.getMessageOrBuilder();
        } else {
          return amContainerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getAmContainerIdFieldBuilder() {
        if (amContainerIdBuilder_ == null) {
          amContainerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  amContainerId_,
                  getParentForChildren(),
                  isClean());
          amContainerId_ = null;
        }
        return amContainerIdBuilder_;
      }

      // optional string original_tracking_url = 8;
      private java.lang.Object originalTrackingUrl_ = "";
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public boolean hasOriginalTrackingUrl() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public java.lang.String getOriginalTrackingUrl() {
        java.lang.Object ref = originalTrackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          originalTrackingUrl_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public com.google.protobuf.ByteString
          getOriginalTrackingUrlBytes() {
        java.lang.Object ref = originalTrackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          originalTrackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public Builder setOriginalTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        originalTrackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public Builder clearOriginalTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00000080);
        originalTrackingUrl_ = getDefaultInstance().getOriginalTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public Builder setOriginalTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        originalTrackingUrl_ = value;
        onChanged();
        return this;
      }

      // optional int64 startTime = 9;
      private long startTime_ ;
      /**
       * <code>optional int64 startTime = 9;</code>
       */
      public boolean hasStartTime() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional int64 startTime = 9;</code>
       */
      public long getStartTime() {
        return startTime_;
      }
      /**
       * <code>optional int64 startTime = 9;</code>
       */
      public Builder setStartTime(long value) {
        bitField0_ |= 0x00000100;
        startTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 startTime = 9;</code>
       */
      public Builder clearStartTime() {
        bitField0_ = (bitField0_ & ~0x00000100);
        startTime_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 finishTime = 10;
      private long finishTime_ ;
      /**
       * <code>optional int64 finishTime = 10;</code>
       */
      public boolean hasFinishTime() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional int64 finishTime = 10;</code>
       */
      public long getFinishTime() {
        return finishTime_;
      }
      /**
       * <code>optional int64 finishTime = 10;</code>
       */
      public Builder setFinishTime(long value) {
        bitField0_ |= 0x00000200;
        finishTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 finishTime = 10;</code>
       */
      public Builder clearFinishTime() {
        bitField0_ = (bitField0_ & ~0x00000200);
        finishTime_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationAttemptReportProto)
    }

    static {
      defaultInstance = new ApplicationAttemptReportProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationAttemptReportProto)
  }

  public interface NodeIdProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string host = 1;
    /**
     * <code>optional string host = 1;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 1;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 1;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    // optional int32 port = 2;
    /**
     * <code>optional int32 port = 2;</code>
     */
    boolean hasPort();
    /**
     * <code>optional int32 port = 2;</code>
     */
    int getPort();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeIdProto}
   */
  public static final class NodeIdProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeIdProtoOrBuilder {
    // Use NodeIdProto.newBuilder() to construct.
    private NodeIdProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeIdProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeIdProto defaultInstance;
    public static NodeIdProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeIdProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              host_ = input.readBytes();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              port_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeIdProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeIdProto>() {
      public NodeIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeIdProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeIdProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string host = 1;
    public static final int HOST_FIELD_NUMBER = 1;
    private java.lang.Object host_;
    /**
     * <code>optional string host = 1;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string host = 1;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 1;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int32 port = 2;
    public static final int PORT_FIELD_NUMBER = 2;
    private int port_;
    /**
     * <code>optional int32 port = 2;</code>
     */
    public boolean hasPort() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 port = 2;</code>
     */
    public int getPort() {
      return port_;
    }

    private void initFields() {
      host_ = "";
      port_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getHostBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, port_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getHostBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, port_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto) obj;

      boolean result = true;
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasPort() == other.hasPort());
      if (hasPort()) {
        result = result && (getPort()
            == other.getPort());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasPort()) {
        hash = (37 * hash) + PORT_FIELD_NUMBER;
        hash = (53 * hash) + getPort();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        port_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.port_ = port_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) return this;
        if (other.hasHost()) {
          bitField0_ |= 0x00000001;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasPort()) {
          setPort(other.getPort());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string host = 1;
      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 1;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          host_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000001);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        host_ = value;
        onChanged();
        return this;
      }

      // optional int32 port = 2;
      private int port_ ;
      /**
       * <code>optional int32 port = 2;</code>
       */
      public boolean hasPort() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 port = 2;</code>
       */
      public int getPort() {
        return port_;
      }
      /**
       * <code>optional int32 port = 2;</code>
       */
      public Builder setPort(int value) {
        bitField0_ |= 0x00000002;
        port_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 port = 2;</code>
       */
      public Builder clearPort() {
        bitField0_ = (bitField0_ & ~0x00000002);
        port_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeIdProto)
    }

    static {
      defaultInstance = new NodeIdProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeIdProto)
  }

  public interface NodeReportProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.NodeIdProto nodeId = 1;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    // optional string httpAddress = 2;
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    boolean hasHttpAddress();
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    java.lang.String getHttpAddress();
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    com.google.protobuf.ByteString
        getHttpAddressBytes();

    // optional string rackName = 3;
    /**
     * <code>optional string rackName = 3;</code>
     */
    boolean hasRackName();
    /**
     * <code>optional string rackName = 3;</code>
     */
    java.lang.String getRackName();
    /**
     * <code>optional string rackName = 3;</code>
     */
    com.google.protobuf.ByteString
        getRackNameBytes();

    // optional .hadoop.yarn.ResourceProto used = 4;
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    boolean hasUsed();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsed();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedOrBuilder();

    // optional .hadoop.yarn.ResourceProto capability = 5;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    // optional int32 numContainers = 6;
    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    boolean hasNumContainers();
    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    int getNumContainers();

    // optional .hadoop.yarn.NodeStateProto node_state = 7;
    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    boolean hasNodeState();
    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeState();

    // optional string health_report = 8;
    /**
     * <code>optional string health_report = 8;</code>
     */
    boolean hasHealthReport();
    /**
     * <code>optional string health_report = 8;</code>
     */
    java.lang.String getHealthReport();
    /**
     * <code>optional string health_report = 8;</code>
     */
    com.google.protobuf.ByteString
        getHealthReportBytes();

    // optional int64 last_health_report_time = 9;
    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    boolean hasLastHealthReportTime();
    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    long getLastHealthReportTime();

    // repeated string node_labels = 10;
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    java.util.List<java.lang.String>
    getNodeLabelsList();
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    int getNodeLabelsCount();
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    java.lang.String getNodeLabels(int index);
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    com.google.protobuf.ByteString
        getNodeLabelsBytes(int index);

    // optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
     */
    boolean hasContainersUtilization();
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getContainersUtilization();
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getContainersUtilizationOrBuilder();

    // optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
     */
    boolean hasNodeUtilization();
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getNodeUtilization();
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getNodeUtilizationOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeReportProto}
   */
  public static final class NodeReportProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeReportProtoOrBuilder {
    // Use NodeReportProto.newBuilder() to construct.
    private NodeReportProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeReportProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeReportProto defaultInstance;
    public static NodeReportProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeReportProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              httpAddress_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              rackName_ = input.readBytes();
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = used_.toBuilder();
              }
              used_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(used_);
                used_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              numContainers_ = input.readInt32();
              break;
            }
            case 56: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(7, rawValue);
              } else {
                bitField0_ |= 0x00000040;
                nodeState_ = value;
              }
              break;
            }
            case 66: {
              bitField0_ |= 0x00000080;
              healthReport_ = input.readBytes();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              lastHealthReportTime_ = input.readInt64();
              break;
            }
            case 82: {
              if (!((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
                nodeLabels_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000200;
              }
              nodeLabels_.add(input.readBytes());
              break;
            }
            case 90: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000200) == 0x00000200)) {
                subBuilder = containersUtilization_.toBuilder();
              }
              containersUtilization_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containersUtilization_);
                containersUtilization_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000200;
              break;
            }
            case 98: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000400) == 0x00000400)) {
                subBuilder = nodeUtilization_.toBuilder();
              }
              nodeUtilization_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeUtilization_);
                nodeUtilization_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000400;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
          nodeLabels_ = new com.google.protobuf.UnmodifiableLazyStringList(nodeLabels_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeReportProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeReportProto>() {
      public NodeReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeReportProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeReportProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.NodeIdProto nodeId = 1;
    public static final int NODEID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_;
    }

    // optional string httpAddress = 2;
    public static final int HTTPADDRESS_FIELD_NUMBER = 2;
    private java.lang.Object httpAddress_;
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    public boolean hasHttpAddress() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    public java.lang.String getHttpAddress() {
      java.lang.Object ref = httpAddress_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          httpAddress_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    public com.google.protobuf.ByteString
        getHttpAddressBytes() {
      java.lang.Object ref = httpAddress_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        httpAddress_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string rackName = 3;
    public static final int RACKNAME_FIELD_NUMBER = 3;
    private java.lang.Object rackName_;
    /**
     * <code>optional string rackName = 3;</code>
     */
    public boolean hasRackName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string rackName = 3;</code>
     */
    public java.lang.String getRackName() {
      java.lang.Object ref = rackName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          rackName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string rackName = 3;</code>
     */
    public com.google.protobuf.ByteString
        getRackNameBytes() {
      java.lang.Object ref = rackName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        rackName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.ResourceProto used = 4;
    public static final int USED_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto used_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    public boolean hasUsed() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsed() {
      return used_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedOrBuilder() {
      return used_;
    }

    // optional .hadoop.yarn.ResourceProto capability = 5;
    public static final int CAPABILITY_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    // optional int32 numContainers = 6;
    public static final int NUMCONTAINERS_FIELD_NUMBER = 6;
    private int numContainers_;
    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    public boolean hasNumContainers() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    public int getNumContainers() {
      return numContainers_;
    }

    // optional .hadoop.yarn.NodeStateProto node_state = 7;
    public static final int NODE_STATE_FIELD_NUMBER = 7;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto nodeState_;
    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    public boolean hasNodeState() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeState() {
      return nodeState_;
    }

    // optional string health_report = 8;
    public static final int HEALTH_REPORT_FIELD_NUMBER = 8;
    private java.lang.Object healthReport_;
    /**
     * <code>optional string health_report = 8;</code>
     */
    public boolean hasHealthReport() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional string health_report = 8;</code>
     */
    public java.lang.String getHealthReport() {
      java.lang.Object ref = healthReport_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          healthReport_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string health_report = 8;</code>
     */
    public com.google.protobuf.ByteString
        getHealthReportBytes() {
      java.lang.Object ref = healthReport_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        healthReport_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int64 last_health_report_time = 9;
    public static final int LAST_HEALTH_REPORT_TIME_FIELD_NUMBER = 9;
    private long lastHealthReportTime_;
    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    public boolean hasLastHealthReportTime() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    public long getLastHealthReportTime() {
      return lastHealthReportTime_;
    }

    // repeated string node_labels = 10;
    public static final int NODE_LABELS_FIELD_NUMBER = 10;
    private com.google.protobuf.LazyStringList nodeLabels_;
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    public java.util.List<java.lang.String>
        getNodeLabelsList() {
      return nodeLabels_;
    }
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    public int getNodeLabelsCount() {
      return nodeLabels_.size();
    }
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    public java.lang.String getNodeLabels(int index) {
      return nodeLabels_.get(index);
    }
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    public com.google.protobuf.ByteString
        getNodeLabelsBytes(int index) {
      return nodeLabels_.getByteString(index);
    }

    // optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;
    public static final int CONTAINERS_UTILIZATION_FIELD_NUMBER = 11;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto containersUtilization_;
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
     */
    public boolean hasContainersUtilization() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getContainersUtilization() {
      return containersUtilization_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getContainersUtilizationOrBuilder() {
      return containersUtilization_;
    }

    // optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;
    public static final int NODE_UTILIZATION_FIELD_NUMBER = 12;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto nodeUtilization_;
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
     */
    public boolean hasNodeUtilization() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getNodeUtilization() {
      return nodeUtilization_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getNodeUtilizationOrBuilder() {
      return nodeUtilization_;
    }

    private void initFields() {
      nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      httpAddress_ = "";
      rackName_ = "";
      used_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      numContainers_ = 0;
      nodeState_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.NS_NEW;
      healthReport_ = "";
      lastHealthReportTime_ = 0L;
      nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      containersUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
      nodeUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getHttpAddressBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getRackNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, used_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, capability_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt32(6, numContainers_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeEnum(7, nodeState_.getNumber());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeBytes(8, getHealthReportBytes());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeInt64(9, lastHealthReportTime_);
      }
      for (int i = 0; i < nodeLabels_.size(); i++) {
        output.writeBytes(10, nodeLabels_.getByteString(i));
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeMessage(11, containersUtilization_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeMessage(12, nodeUtilization_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getHttpAddressBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getRackNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, used_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, capability_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(6, numContainers_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(7, nodeState_.getNumber());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(8, getHealthReportBytes());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(9, lastHealthReportTime_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < nodeLabels_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(nodeLabels_.getByteString(i));
        }
        size += dataSize;
        size += 1 * getNodeLabelsList().size();
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, containersUtilization_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, nodeUtilization_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasHttpAddress() == other.hasHttpAddress());
      if (hasHttpAddress()) {
        result = result && getHttpAddress()
            .equals(other.getHttpAddress());
      }
      result = result && (hasRackName() == other.hasRackName());
      if (hasRackName()) {
        result = result && getRackName()
            .equals(other.getRackName());
      }
      result = result && (hasUsed() == other.hasUsed());
      if (hasUsed()) {
        result = result && getUsed()
            .equals(other.getUsed());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasNumContainers() == other.hasNumContainers());
      if (hasNumContainers()) {
        result = result && (getNumContainers()
            == other.getNumContainers());
      }
      result = result && (hasNodeState() == other.hasNodeState());
      if (hasNodeState()) {
        result = result &&
            (getNodeState() == other.getNodeState());
      }
      result = result && (hasHealthReport() == other.hasHealthReport());
      if (hasHealthReport()) {
        result = result && getHealthReport()
            .equals(other.getHealthReport());
      }
      result = result && (hasLastHealthReportTime() == other.hasLastHealthReportTime());
      if (hasLastHealthReportTime()) {
        result = result && (getLastHealthReportTime()
            == other.getLastHealthReportTime());
      }
      result = result && getNodeLabelsList()
          .equals(other.getNodeLabelsList());
      result = result && (hasContainersUtilization() == other.hasContainersUtilization());
      if (hasContainersUtilization()) {
        result = result && getContainersUtilization()
            .equals(other.getContainersUtilization());
      }
      result = result && (hasNodeUtilization() == other.hasNodeUtilization());
      if (hasNodeUtilization()) {
        result = result && getNodeUtilization()
            .equals(other.getNodeUtilization());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODEID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasHttpAddress()) {
        hash = (37 * hash) + HTTPADDRESS_FIELD_NUMBER;
        hash = (53 * hash) + getHttpAddress().hashCode();
      }
      if (hasRackName()) {
        hash = (37 * hash) + RACKNAME_FIELD_NUMBER;
        hash = (53 * hash) + getRackName().hashCode();
      }
      if (hasUsed()) {
        hash = (37 * hash) + USED_FIELD_NUMBER;
        hash = (53 * hash) + getUsed().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasNumContainers()) {
        hash = (37 * hash) + NUMCONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumContainers();
      }
      if (hasNodeState()) {
        hash = (37 * hash) + NODE_STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getNodeState());
      }
      if (hasHealthReport()) {
        hash = (37 * hash) + HEALTH_REPORT_FIELD_NUMBER;
        hash = (53 * hash) + getHealthReport().hashCode();
      }
      if (hasLastHealthReportTime()) {
        hash = (37 * hash) + LAST_HEALTH_REPORT_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getLastHealthReportTime());
      }
      if (getNodeLabelsCount() > 0) {
        hash = (37 * hash) + NODE_LABELS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelsList().hashCode();
      }
      if (hasContainersUtilization()) {
        hash = (37 * hash) + CONTAINERS_UTILIZATION_FIELD_NUMBER;
        hash = (53 * hash) + getContainersUtilization().hashCode();
      }
      if (hasNodeUtilization()) {
        hash = (37 * hash) + NODE_UTILIZATION_FIELD_NUMBER;
        hash = (53 * hash) + getNodeUtilization().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
          getUsedFieldBuilder();
          getCapabilityFieldBuilder();
          getContainersUtilizationFieldBuilder();
          getNodeUtilizationFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        httpAddress_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        rackName_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (usedBuilder_ == null) {
          used_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          usedBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        numContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000020);
        nodeState_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.NS_NEW;
        bitField0_ = (bitField0_ & ~0x00000040);
        healthReport_ = "";
        bitField0_ = (bitField0_ & ~0x00000080);
        lastHealthReportTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000100);
        nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000200);
        if (containersUtilizationBuilder_ == null) {
          containersUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
        } else {
          containersUtilizationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000400);
        if (nodeUtilizationBuilder_ == null) {
          nodeUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
        } else {
          nodeUtilizationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000800);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.httpAddress_ = httpAddress_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.rackName_ = rackName_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (usedBuilder_ == null) {
          result.used_ = used_;
        } else {
          result.used_ = usedBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.numContainers_ = numContainers_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.nodeState_ = nodeState_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.healthReport_ = healthReport_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.lastHealthReportTime_ = lastHealthReportTime_;
        if (((bitField0_ & 0x00000200) == 0x00000200)) {
          nodeLabels_ = new com.google.protobuf.UnmodifiableLazyStringList(
              nodeLabels_);
          bitField0_ = (bitField0_ & ~0x00000200);
        }
        result.nodeLabels_ = nodeLabels_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000200;
        }
        if (containersUtilizationBuilder_ == null) {
          result.containersUtilization_ = containersUtilization_;
        } else {
          result.containersUtilization_ = containersUtilizationBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000800) == 0x00000800)) {
          to_bitField0_ |= 0x00000400;
        }
        if (nodeUtilizationBuilder_ == null) {
          result.nodeUtilization_ = nodeUtilization_;
        } else {
          result.nodeUtilization_ = nodeUtilizationBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasHttpAddress()) {
          bitField0_ |= 0x00000002;
          httpAddress_ = other.httpAddress_;
          onChanged();
        }
        if (other.hasRackName()) {
          bitField0_ |= 0x00000004;
          rackName_ = other.rackName_;
          onChanged();
        }
        if (other.hasUsed()) {
          mergeUsed(other.getUsed());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasNumContainers()) {
          setNumContainers(other.getNumContainers());
        }
        if (other.hasNodeState()) {
          setNodeState(other.getNodeState());
        }
        if (other.hasHealthReport()) {
          bitField0_ |= 0x00000080;
          healthReport_ = other.healthReport_;
          onChanged();
        }
        if (other.hasLastHealthReportTime()) {
          setLastHealthReportTime(other.getLastHealthReportTime());
        }
        if (!other.nodeLabels_.isEmpty()) {
          if (nodeLabels_.isEmpty()) {
            nodeLabels_ = other.nodeLabels_;
            bitField0_ = (bitField0_ & ~0x00000200);
          } else {
            ensureNodeLabelsIsMutable();
            nodeLabels_.addAll(other.nodeLabels_);
          }
          onChanged();
        }
        if (other.hasContainersUtilization()) {
          mergeContainersUtilization(other.getContainersUtilization());
        }
        if (other.hasNodeUtilization()) {
          mergeNodeUtilization(other.getNodeUtilization());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.NodeIdProto nodeId = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // optional string httpAddress = 2;
      private java.lang.Object httpAddress_ = "";
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public boolean hasHttpAddress() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public java.lang.String getHttpAddress() {
        java.lang.Object ref = httpAddress_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          httpAddress_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public com.google.protobuf.ByteString
          getHttpAddressBytes() {
        java.lang.Object ref = httpAddress_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          httpAddress_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public Builder setHttpAddress(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        httpAddress_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public Builder clearHttpAddress() {
        bitField0_ = (bitField0_ & ~0x00000002);
        httpAddress_ = getDefaultInstance().getHttpAddress();
        onChanged();
        return this;
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public Builder setHttpAddressBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        httpAddress_ = value;
        onChanged();
        return this;
      }

      // optional string rackName = 3;
      private java.lang.Object rackName_ = "";
      /**
       * <code>optional string rackName = 3;</code>
       */
      public boolean hasRackName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public java.lang.String getRackName() {
        java.lang.Object ref = rackName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          rackName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public com.google.protobuf.ByteString
          getRackNameBytes() {
        java.lang.Object ref = rackName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          rackName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public Builder setRackName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        rackName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public Builder clearRackName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        rackName_ = getDefaultInstance().getRackName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public Builder setRackNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        rackName_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto used = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto used_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> usedBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public boolean hasUsed() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsed() {
        if (usedBuilder_ == null) {
          return used_;
        } else {
          return usedBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder setUsed(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          used_ = value;
          onChanged();
        } else {
          usedBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder setUsed(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (usedBuilder_ == null) {
          used_ = builderForValue.build();
          onChanged();
        } else {
          usedBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder mergeUsed(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              used_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            used_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(used_).mergeFrom(value).buildPartial();
          } else {
            used_ = value;
          }
          onChanged();
        } else {
          usedBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder clearUsed() {
        if (usedBuilder_ == null) {
          used_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          usedBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getUsedBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getUsedFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedOrBuilder() {
        if (usedBuilder_ != null) {
          return usedBuilder_.getMessageOrBuilder();
        } else {
          return used_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getUsedFieldBuilder() {
        if (usedBuilder_ == null) {
          usedBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  used_,
                  getParentForChildren(),
                  isClean());
          used_ = null;
        }
        return usedBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto capability = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // optional int32 numContainers = 6;
      private int numContainers_ ;
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public boolean hasNumContainers() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public int getNumContainers() {
        return numContainers_;
      }
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public Builder setNumContainers(int value) {
        bitField0_ |= 0x00000020;
        numContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public Builder clearNumContainers() {
        bitField0_ = (bitField0_ & ~0x00000020);
        numContainers_ = 0;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.NodeStateProto node_state = 7;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto nodeState_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.NS_NEW;
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public boolean hasNodeState() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeState() {
        return nodeState_;
      }
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public Builder setNodeState(org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000040;
        nodeState_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public Builder clearNodeState() {
        bitField0_ = (bitField0_ & ~0x00000040);
        nodeState_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.NS_NEW;
        onChanged();
        return this;
      }

      // optional string health_report = 8;
      private java.lang.Object healthReport_ = "";
      /**
       * <code>optional string health_report = 8;</code>
       */
      public boolean hasHealthReport() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public java.lang.String getHealthReport() {
        java.lang.Object ref = healthReport_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          healthReport_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public com.google.protobuf.ByteString
          getHealthReportBytes() {
        java.lang.Object ref = healthReport_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          healthReport_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public Builder setHealthReport(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        healthReport_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public Builder clearHealthReport() {
        bitField0_ = (bitField0_ & ~0x00000080);
        healthReport_ = getDefaultInstance().getHealthReport();
        onChanged();
        return this;
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public Builder setHealthReportBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        healthReport_ = value;
        onChanged();
        return this;
      }

      // optional int64 last_health_report_time = 9;
      private long lastHealthReportTime_ ;
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public boolean hasLastHealthReportTime() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public long getLastHealthReportTime() {
        return lastHealthReportTime_;
      }
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public Builder setLastHealthReportTime(long value) {
        bitField0_ |= 0x00000100;
        lastHealthReportTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public Builder clearLastHealthReportTime() {
        bitField0_ = (bitField0_ & ~0x00000100);
        lastHealthReportTime_ = 0L;
        onChanged();
        return this;
      }

      // repeated string node_labels = 10;
      private com.google.protobuf.LazyStringList nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureNodeLabelsIsMutable() {
        if (!((bitField0_ & 0x00000200) == 0x00000200)) {
          nodeLabels_ = new com.google.protobuf.LazyStringArrayList(nodeLabels_);
          bitField0_ |= 0x00000200;
         }
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public java.util.List<java.lang.String>
          getNodeLabelsList() {
        return java.util.Collections.unmodifiableList(nodeLabels_);
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public int getNodeLabelsCount() {
        return nodeLabels_.size();
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public java.lang.String getNodeLabels(int index) {
        return nodeLabels_.get(index);
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public com.google.protobuf.ByteString
          getNodeLabelsBytes(int index) {
        return nodeLabels_.getByteString(index);
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public Builder setNodeLabels(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public Builder addNodeLabels(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public Builder addAllNodeLabels(
          java.lang.Iterable<java.lang.String> values) {
        ensureNodeLabelsIsMutable();
        super.addAll(values, nodeLabels_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public Builder clearNodeLabels() {
        nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000200);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public Builder addNodeLabelsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.add(value);
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto containersUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder> containersUtilizationBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
       */
      public boolean hasContainersUtilization() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getContainersUtilization() {
        if (containersUtilizationBuilder_ == null) {
          return containersUtilization_;
        } else {
          return containersUtilizationBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
       */
      public Builder setContainersUtilization(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto value) {
        if (containersUtilizationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containersUtilization_ = value;
          onChanged();
        } else {
          containersUtilizationBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000400;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
       */
      public Builder setContainersUtilization(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder builderForValue) {
        if (containersUtilizationBuilder_ == null) {
          containersUtilization_ = builderForValue.build();
          onChanged();
        } else {
          containersUtilizationBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000400;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
       */
      public Builder mergeContainersUtilization(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto value) {
        if (containersUtilizationBuilder_ == null) {
          if (((bitField0_ & 0x00000400) == 0x00000400) &&
              containersUtilization_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance()) {
            containersUtilization_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.newBuilder(containersUtilization_).mergeFrom(value).buildPartial();
          } else {
            containersUtilization_ = value;
          }
          onChanged();
        } else {
          containersUtilizationBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000400;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
       */
      public Builder clearContainersUtilization() {
        if (containersUtilizationBuilder_ == null) {
          containersUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
          onChanged();
        } else {
          containersUtilizationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000400);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder getContainersUtilizationBuilder() {
        bitField0_ |= 0x00000400;
        onChanged();
        return getContainersUtilizationFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getContainersUtilizationOrBuilder() {
        if (containersUtilizationBuilder_ != null) {
          return containersUtilizationBuilder_.getMessageOrBuilder();
        } else {
          return containersUtilization_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto containers_utilization = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder> 
          getContainersUtilizationFieldBuilder() {
        if (containersUtilizationBuilder_ == null) {
          containersUtilizationBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder>(
                  containersUtilization_,
                  getParentForChildren(),
                  isClean());
          containersUtilization_ = null;
        }
        return containersUtilizationBuilder_;
      }

      // optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto nodeUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder> nodeUtilizationBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
       */
      public boolean hasNodeUtilization() {
        return ((bitField0_ & 0x00000800) == 0x00000800);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto getNodeUtilization() {
        if (nodeUtilizationBuilder_ == null) {
          return nodeUtilization_;
        } else {
          return nodeUtilizationBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
       */
      public Builder setNodeUtilization(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto value) {
        if (nodeUtilizationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeUtilization_ = value;
          onChanged();
        } else {
          nodeUtilizationBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000800;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
       */
      public Builder setNodeUtilization(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder builderForValue) {
        if (nodeUtilizationBuilder_ == null) {
          nodeUtilization_ = builderForValue.build();
          onChanged();
        } else {
          nodeUtilizationBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000800;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
       */
      public Builder mergeNodeUtilization(org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto value) {
        if (nodeUtilizationBuilder_ == null) {
          if (((bitField0_ & 0x00000800) == 0x00000800) &&
              nodeUtilization_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance()) {
            nodeUtilization_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.newBuilder(nodeUtilization_).mergeFrom(value).buildPartial();
          } else {
            nodeUtilization_ = value;
          }
          onChanged();
        } else {
          nodeUtilizationBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000800;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
       */
      public Builder clearNodeUtilization() {
        if (nodeUtilizationBuilder_ == null) {
          nodeUtilization_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.getDefaultInstance();
          onChanged();
        } else {
          nodeUtilizationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000800);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder getNodeUtilizationBuilder() {
        bitField0_ |= 0x00000800;
        onChanged();
        return getNodeUtilizationFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder getNodeUtilizationOrBuilder() {
        if (nodeUtilizationBuilder_ != null) {
          return nodeUtilizationBuilder_.getMessageOrBuilder();
        } else {
          return nodeUtilization_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceUtilizationProto node_utilization = 12;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder> 
          getNodeUtilizationFieldBuilder() {
        if (nodeUtilizationBuilder_ == null) {
          nodeUtilizationBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceUtilizationProtoOrBuilder>(
                  nodeUtilization_,
                  getParentForChildren(),
                  isClean());
          nodeUtilization_ = null;
        }
        return nodeUtilizationBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeReportProto)
    }

    static {
      defaultInstance = new NodeReportProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeReportProto)
  }

  public interface NodeIdToLabelsProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.NodeIdProto nodeId = 1;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    // repeated string nodeLabels = 2;
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    java.util.List<java.lang.String>
    getNodeLabelsList();
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    int getNodeLabelsCount();
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    java.lang.String getNodeLabels(int index);
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    com.google.protobuf.ByteString
        getNodeLabelsBytes(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeIdToLabelsProto}
   */
  public static final class NodeIdToLabelsProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeIdToLabelsProtoOrBuilder {
    // Use NodeIdToLabelsProto.newBuilder() to construct.
    private NodeIdToLabelsProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeIdToLabelsProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeIdToLabelsProto defaultInstance;
    public static NodeIdToLabelsProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeIdToLabelsProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeIdToLabelsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                nodeLabels_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              nodeLabels_.add(input.readBytes());
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          nodeLabels_ = new com.google.protobuf.UnmodifiableLazyStringList(nodeLabels_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdToLabelsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeIdToLabelsProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeIdToLabelsProto>() {
      public NodeIdToLabelsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeIdToLabelsProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeIdToLabelsProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.NodeIdProto nodeId = 1;
    public static final int NODEID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_;
    }

    // repeated string nodeLabels = 2;
    public static final int NODELABELS_FIELD_NUMBER = 2;
    private com.google.protobuf.LazyStringList nodeLabels_;
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    public java.util.List<java.lang.String>
        getNodeLabelsList() {
      return nodeLabels_;
    }
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    public int getNodeLabelsCount() {
      return nodeLabels_.size();
    }
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    public java.lang.String getNodeLabels(int index) {
      return nodeLabels_.get(index);
    }
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    public com.google.protobuf.ByteString
        getNodeLabelsBytes(int index) {
      return nodeLabels_.getByteString(index);
    }

    private void initFields() {
      nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, nodeId_);
      }
      for (int i = 0; i < nodeLabels_.size(); i++) {
        output.writeBytes(2, nodeLabels_.getByteString(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeId_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < nodeLabels_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(nodeLabels_.getByteString(i));
        }
        size += dataSize;
        size += 1 * getNodeLabelsList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && getNodeLabelsList()
          .equals(other.getNodeLabelsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODEID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (getNodeLabelsCount() > 0) {
        hash = (37 * hash) + NODELABELS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeIdToLabelsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdToLabelsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          nodeLabels_ = new com.google.protobuf.UnmodifiableLazyStringList(
              nodeLabels_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.nodeLabels_ = nodeLabels_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (!other.nodeLabels_.isEmpty()) {
          if (nodeLabels_.isEmpty()) {
            nodeLabels_ = other.nodeLabels_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureNodeLabelsIsMutable();
            nodeLabels_.addAll(other.nodeLabels_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.NodeIdProto nodeId = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // repeated string nodeLabels = 2;
      private com.google.protobuf.LazyStringList nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureNodeLabelsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          nodeLabels_ = new com.google.protobuf.LazyStringArrayList(nodeLabels_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public java.util.List<java.lang.String>
          getNodeLabelsList() {
        return java.util.Collections.unmodifiableList(nodeLabels_);
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public int getNodeLabelsCount() {
        return nodeLabels_.size();
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public java.lang.String getNodeLabels(int index) {
        return nodeLabels_.get(index);
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public com.google.protobuf.ByteString
          getNodeLabelsBytes(int index) {
        return nodeLabels_.getByteString(index);
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public Builder setNodeLabels(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public Builder addNodeLabels(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public Builder addAllNodeLabels(
          java.lang.Iterable<java.lang.String> values) {
        ensureNodeLabelsIsMutable();
        super.addAll(values, nodeLabels_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public Builder clearNodeLabels() {
        nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public Builder addNodeLabelsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.add(value);
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeIdToLabelsProto)
    }

    static {
      defaultInstance = new NodeIdToLabelsProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeIdToLabelsProto)
  }

  public interface LabelsToNodeIdsProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string nodeLabels = 1;
    /**
     * <code>optional string nodeLabels = 1;</code>
     */
    boolean hasNodeLabels();
    /**
     * <code>optional string nodeLabels = 1;</code>
     */
    java.lang.String getNodeLabels();
    /**
     * <code>optional string nodeLabels = 1;</code>
     */
    com.google.protobuf.ByteString
        getNodeLabelsBytes();

    // repeated .hadoop.yarn.NodeIdProto nodeId = 2;
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> 
        getNodeIdList();
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId(int index);
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    int getNodeIdCount();
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
        getNodeIdOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.LabelsToNodeIdsProto}
   */
  public static final class LabelsToNodeIdsProto extends
      com.google.protobuf.GeneratedMessage
      implements LabelsToNodeIdsProtoOrBuilder {
    // Use LabelsToNodeIdsProto.newBuilder() to construct.
    private LabelsToNodeIdsProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private LabelsToNodeIdsProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final LabelsToNodeIdsProto defaultInstance;
    public static LabelsToNodeIdsProto getDefaultInstance() {
      return defaultInstance;
    }

    public LabelsToNodeIdsProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private LabelsToNodeIdsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              nodeLabels_ = input.readBytes();
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                nodeId_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              nodeId_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          nodeId_ = java.util.Collections.unmodifiableList(nodeId_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LabelsToNodeIdsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LabelsToNodeIdsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder.class);
    }

    public static com.google.protobuf.Parser<LabelsToNodeIdsProto> PARSER =
        new com.google.protobuf.AbstractParser<LabelsToNodeIdsProto>() {
      public LabelsToNodeIdsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new LabelsToNodeIdsProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<LabelsToNodeIdsProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string nodeLabels = 1;
    public static final int NODELABELS_FIELD_NUMBER = 1;
    private java.lang.Object nodeLabels_;
    /**
     * <code>optional string nodeLabels = 1;</code>
     */
    public boolean hasNodeLabels() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string nodeLabels = 1;</code>
     */
    public java.lang.String getNodeLabels() {
      java.lang.Object ref = nodeLabels_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          nodeLabels_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string nodeLabels = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNodeLabelsBytes() {
      java.lang.Object ref = nodeLabels_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nodeLabels_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // repeated .hadoop.yarn.NodeIdProto nodeId = 2;
    public static final int NODEID_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> nodeId_;
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> getNodeIdList() {
      return nodeId_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
        getNodeIdOrBuilderList() {
      return nodeId_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public int getNodeIdCount() {
      return nodeId_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId(int index) {
      return nodeId_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder(
        int index) {
      return nodeId_.get(index);
    }

    private void initFields() {
      nodeLabels_ = "";
      nodeId_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getNodeLabelsBytes());
      }
      for (int i = 0; i < nodeId_.size(); i++) {
        output.writeMessage(2, nodeId_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getNodeLabelsBytes());
      }
      for (int i = 0; i < nodeId_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, nodeId_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto other = (org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto) obj;

      boolean result = true;
      result = result && (hasNodeLabels() == other.hasNodeLabels());
      if (hasNodeLabels()) {
        result = result && getNodeLabels()
            .equals(other.getNodeLabels());
      }
      result = result && getNodeIdList()
          .equals(other.getNodeIdList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNodeLabels()) {
        hash = (37 * hash) + NODELABELS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabels().hashCode();
      }
      if (getNodeIdCount() > 0) {
        hash = (37 * hash) + NODEID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeIdList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.LabelsToNodeIdsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LabelsToNodeIdsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LabelsToNodeIdsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        nodeLabels_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (nodeIdBuilder_ == null) {
          nodeId_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          nodeIdBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LabelsToNodeIdsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto result = new org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.nodeLabels_ = nodeLabels_;
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            nodeId_ = java.util.Collections.unmodifiableList(nodeId_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto.getDefaultInstance()) return this;
        if (other.hasNodeLabels()) {
          bitField0_ |= 0x00000001;
          nodeLabels_ = other.nodeLabels_;
          onChanged();
        }
        if (nodeIdBuilder_ == null) {
          if (!other.nodeId_.isEmpty()) {
            if (nodeId_.isEmpty()) {
              nodeId_ = other.nodeId_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureNodeIdIsMutable();
              nodeId_.addAll(other.nodeId_);
            }
            onChanged();
          }
        } else {
          if (!other.nodeId_.isEmpty()) {
            if (nodeIdBuilder_.isEmpty()) {
              nodeIdBuilder_.dispose();
              nodeIdBuilder_ = null;
              nodeId_ = other.nodeId_;
              bitField0_ = (bitField0_ & ~0x00000002);
              nodeIdBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getNodeIdFieldBuilder() : null;
            } else {
              nodeIdBuilder_.addAllMessages(other.nodeId_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.LabelsToNodeIdsProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string nodeLabels = 1;
      private java.lang.Object nodeLabels_ = "";
      /**
       * <code>optional string nodeLabels = 1;</code>
       */
      public boolean hasNodeLabels() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string nodeLabels = 1;</code>
       */
      public java.lang.String getNodeLabels() {
        java.lang.Object ref = nodeLabels_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          nodeLabels_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string nodeLabels = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNodeLabelsBytes() {
        java.lang.Object ref = nodeLabels_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nodeLabels_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string nodeLabels = 1;</code>
       */
      public Builder setNodeLabels(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        nodeLabels_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string nodeLabels = 1;</code>
       */
      public Builder clearNodeLabels() {
        bitField0_ = (bitField0_ & ~0x00000001);
        nodeLabels_ = getDefaultInstance().getNodeLabels();
        onChanged();
        return this;
      }
      /**
       * <code>optional string nodeLabels = 1;</code>
       */
      public Builder setNodeLabelsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        nodeLabels_ = value;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.NodeIdProto nodeId = 2;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> nodeId_ =
        java.util.Collections.emptyList();
      private void ensureNodeIdIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          nodeId_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto>(nodeId_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;

      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> getNodeIdList() {
        if (nodeIdBuilder_ == null) {
          return java.util.Collections.unmodifiableList(nodeId_);
        } else {
          return nodeIdBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public int getNodeIdCount() {
        if (nodeIdBuilder_ == null) {
          return nodeId_.size();
        } else {
          return nodeIdBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId(int index) {
        if (nodeIdBuilder_ == null) {
          return nodeId_.get(index);
        } else {
          return nodeIdBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder setNodeId(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeIdIsMutable();
          nodeId_.set(index, value);
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder setNodeId(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          ensureNodeIdIsMutable();
          nodeId_.set(index, builderForValue.build());
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder addNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeIdIsMutable();
          nodeId_.add(value);
          onChanged();
        } else {
          nodeIdBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder addNodeId(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeIdIsMutable();
          nodeId_.add(index, value);
          onChanged();
        } else {
          nodeIdBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder addNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          ensureNodeIdIsMutable();
          nodeId_.add(builderForValue.build());
          onChanged();
        } else {
          nodeIdBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder addNodeId(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          ensureNodeIdIsMutable();
          nodeId_.add(index, builderForValue.build());
          onChanged();
        } else {
          nodeIdBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder addAllNodeId(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> values) {
        if (nodeIdBuilder_ == null) {
          ensureNodeIdIsMutable();
          super.addAll(values, nodeId_);
          onChanged();
        } else {
          nodeIdBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder removeNodeId(int index) {
        if (nodeIdBuilder_ == null) {
          ensureNodeIdIsMutable();
          nodeId_.remove(index);
          onChanged();
        } else {
          nodeIdBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder(
          int index) {
        return getNodeIdFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder(
          int index) {
        if (nodeIdBuilder_ == null) {
          return nodeId_.get(index);  } else {
          return nodeIdBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
           getNodeIdOrBuilderList() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(nodeId_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder addNodeIdBuilder() {
        return getNodeIdFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder addNodeIdBuilder(
          int index) {
        return getNodeIdFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder> 
           getNodeIdBuilderList() {
        return getNodeIdFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.LabelsToNodeIdsProto)
    }

    static {
      defaultInstance = new LabelsToNodeIdsProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.LabelsToNodeIdsProto)
  }

  public interface NodeLabelProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string name = 1;
    /**
     * <code>optional string name = 1;</code>
     */
    boolean hasName();
    /**
     * <code>optional string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <code>optional string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    // optional bool isExclusive = 2 [default = true];
    /**
     * <code>optional bool isExclusive = 2 [default = true];</code>
     */
    boolean hasIsExclusive();
    /**
     * <code>optional bool isExclusive = 2 [default = true];</code>
     */
    boolean getIsExclusive();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeLabelProto}
   */
  public static final class NodeLabelProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeLabelProtoOrBuilder {
    // Use NodeLabelProto.newBuilder() to construct.
    private NodeLabelProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeLabelProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeLabelProto defaultInstance;
    public static NodeLabelProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeLabelProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeLabelProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              name_ = input.readBytes();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              isExclusive_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeLabelProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeLabelProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeLabelProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeLabelProto>() {
      public NodeLabelProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeLabelProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeLabelProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private java.lang.Object name_;
    /**
     * <code>optional string name = 1;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional bool isExclusive = 2 [default = true];
    public static final int ISEXCLUSIVE_FIELD_NUMBER = 2;
    private boolean isExclusive_;
    /**
     * <code>optional bool isExclusive = 2 [default = true];</code>
     */
    public boolean hasIsExclusive() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool isExclusive = 2 [default = true];</code>
     */
    public boolean getIsExclusive() {
      return isExclusive_;
    }

    private void initFields() {
      name_ = "";
      isExclusive_ = true;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, isExclusive_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, isExclusive_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto) obj;

      boolean result = true;
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result && (hasIsExclusive() == other.hasIsExclusive());
      if (hasIsExclusive()) {
        result = result && (getIsExclusive()
            == other.getIsExclusive());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (hasIsExclusive()) {
        hash = (37 * hash) + ISEXCLUSIVE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getIsExclusive());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeLabelProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeLabelProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeLabelProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        isExclusive_ = true;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeLabelProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.name_ = name_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.isExclusive_ = isExclusive_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.getDefaultInstance()) return this;
        if (other.hasName()) {
          bitField0_ |= 0x00000001;
          name_ = other.name_;
          onChanged();
        }
        if (other.hasIsExclusive()) {
          setIsExclusive(other.getIsExclusive());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string name = 1;
      private java.lang.Object name_ = "";
      /**
       * <code>optional string name = 1;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string name = 1;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }

      // optional bool isExclusive = 2 [default = true];
      private boolean isExclusive_ = true;
      /**
       * <code>optional bool isExclusive = 2 [default = true];</code>
       */
      public boolean hasIsExclusive() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bool isExclusive = 2 [default = true];</code>
       */
      public boolean getIsExclusive() {
        return isExclusive_;
      }
      /**
       * <code>optional bool isExclusive = 2 [default = true];</code>
       */
      public Builder setIsExclusive(boolean value) {
        bitField0_ |= 0x00000002;
        isExclusive_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool isExclusive = 2 [default = true];</code>
       */
      public Builder clearIsExclusive() {
        bitField0_ = (bitField0_ & ~0x00000002);
        isExclusive_ = true;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeLabelProto)
    }

    static {
      defaultInstance = new NodeLabelProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeLabelProto)
  }

  public interface AMBlackListingRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional bool blacklisting_enabled = 1 [default = false];
    /**
     * <code>optional bool blacklisting_enabled = 1 [default = false];</code>
     */
    boolean hasBlacklistingEnabled();
    /**
     * <code>optional bool blacklisting_enabled = 1 [default = false];</code>
     */
    boolean getBlacklistingEnabled();

    // optional float blacklisting_failure_threshold = 2;
    /**
     * <code>optional float blacklisting_failure_threshold = 2;</code>
     */
    boolean hasBlacklistingFailureThreshold();
    /**
     * <code>optional float blacklisting_failure_threshold = 2;</code>
     */
    float getBlacklistingFailureThreshold();
  }
  /**
   * Protobuf type {@code hadoop.yarn.AMBlackListingRequestProto}
   */
  public static final class AMBlackListingRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements AMBlackListingRequestProtoOrBuilder {
    // Use AMBlackListingRequestProto.newBuilder() to construct.
    private AMBlackListingRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private AMBlackListingRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final AMBlackListingRequestProto defaultInstance;
    public static AMBlackListingRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public AMBlackListingRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private AMBlackListingRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              blacklistingEnabled_ = input.readBool();
              break;
            }
            case 21: {
              bitField0_ |= 0x00000002;
              blacklistingFailureThreshold_ = input.readFloat();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_AMBlackListingRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_AMBlackListingRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<AMBlackListingRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<AMBlackListingRequestProto>() {
      public AMBlackListingRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new AMBlackListingRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<AMBlackListingRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional bool blacklisting_enabled = 1 [default = false];
    public static final int BLACKLISTING_ENABLED_FIELD_NUMBER = 1;
    private boolean blacklistingEnabled_;
    /**
     * <code>optional bool blacklisting_enabled = 1 [default = false];</code>
     */
    public boolean hasBlacklistingEnabled() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bool blacklisting_enabled = 1 [default = false];</code>
     */
    public boolean getBlacklistingEnabled() {
      return blacklistingEnabled_;
    }

    // optional float blacklisting_failure_threshold = 2;
    public static final int BLACKLISTING_FAILURE_THRESHOLD_FIELD_NUMBER = 2;
    private float blacklistingFailureThreshold_;
    /**
     * <code>optional float blacklisting_failure_threshold = 2;</code>
     */
    public boolean hasBlacklistingFailureThreshold() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional float blacklisting_failure_threshold = 2;</code>
     */
    public float getBlacklistingFailureThreshold() {
      return blacklistingFailureThreshold_;
    }

    private void initFields() {
      blacklistingEnabled_ = false;
      blacklistingFailureThreshold_ = 0F;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, blacklistingEnabled_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeFloat(2, blacklistingFailureThreshold_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, blacklistingEnabled_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(2, blacklistingFailureThreshold_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto) obj;

      boolean result = true;
      result = result && (hasBlacklistingEnabled() == other.hasBlacklistingEnabled());
      if (hasBlacklistingEnabled()) {
        result = result && (getBlacklistingEnabled()
            == other.getBlacklistingEnabled());
      }
      result = result && (hasBlacklistingFailureThreshold() == other.hasBlacklistingFailureThreshold());
      if (hasBlacklistingFailureThreshold()) {
        result = result && (Float.floatToIntBits(getBlacklistingFailureThreshold())    == Float.floatToIntBits(other.getBlacklistingFailureThreshold()));
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasBlacklistingEnabled()) {
        hash = (37 * hash) + BLACKLISTING_ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getBlacklistingEnabled());
      }
      if (hasBlacklistingFailureThreshold()) {
        hash = (37 * hash) + BLACKLISTING_FAILURE_THRESHOLD_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getBlacklistingFailureThreshold());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.AMBlackListingRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_AMBlackListingRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_AMBlackListingRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        blacklistingEnabled_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        blacklistingFailureThreshold_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_AMBlackListingRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.blacklistingEnabled_ = blacklistingEnabled_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.blacklistingFailureThreshold_ = blacklistingFailureThreshold_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto.getDefaultInstance()) return this;
        if (other.hasBlacklistingEnabled()) {
          setBlacklistingEnabled(other.getBlacklistingEnabled());
        }
        if (other.hasBlacklistingFailureThreshold()) {
          setBlacklistingFailureThreshold(other.getBlacklistingFailureThreshold());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.AMBlackListingRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional bool blacklisting_enabled = 1 [default = false];
      private boolean blacklistingEnabled_ ;
      /**
       * <code>optional bool blacklisting_enabled = 1 [default = false];</code>
       */
      public boolean hasBlacklistingEnabled() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bool blacklisting_enabled = 1 [default = false];</code>
       */
      public boolean getBlacklistingEnabled() {
        return blacklistingEnabled_;
      }
      /**
       * <code>optional bool blacklisting_enabled = 1 [default = false];</code>
       */
      public Builder setBlacklistingEnabled(boolean value) {
        bitField0_ |= 0x00000001;
        blacklistingEnabled_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool blacklisting_enabled = 1 [default = false];</code>
       */
      public Builder clearBlacklistingEnabled() {
        bitField0_ = (bitField0_ & ~0x00000001);
        blacklistingEnabled_ = false;
        onChanged();
        return this;
      }

      // optional float blacklisting_failure_threshold = 2;
      private float blacklistingFailureThreshold_ ;
      /**
       * <code>optional float blacklisting_failure_threshold = 2;</code>
       */
      public boolean hasBlacklistingFailureThreshold() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional float blacklisting_failure_threshold = 2;</code>
       */
      public float getBlacklistingFailureThreshold() {
        return blacklistingFailureThreshold_;
      }
      /**
       * <code>optional float blacklisting_failure_threshold = 2;</code>
       */
      public Builder setBlacklistingFailureThreshold(float value) {
        bitField0_ |= 0x00000002;
        blacklistingFailureThreshold_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float blacklisting_failure_threshold = 2;</code>
       */
      public Builder clearBlacklistingFailureThreshold() {
        bitField0_ = (bitField0_ & ~0x00000002);
        blacklistingFailureThreshold_ = 0F;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.AMBlackListingRequestProto)
    }

    static {
      defaultInstance = new AMBlackListingRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.AMBlackListingRequestProto)
  }

  public interface ResourceRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.PriorityProto priority = 1;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    // optional string resource_name = 2;
    /**
     * <code>optional string resource_name = 2;</code>
     */
    boolean hasResourceName();
    /**
     * <code>optional string resource_name = 2;</code>
     */
    java.lang.String getResourceName();
    /**
     * <code>optional string resource_name = 2;</code>
     */
    com.google.protobuf.ByteString
        getResourceNameBytes();

    // optional .hadoop.yarn.ResourceProto capability = 3;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    // optional int32 num_containers = 4;
    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    boolean hasNumContainers();
    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    int getNumContainers();

    // optional bool relax_locality = 5 [default = true];
    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    boolean hasRelaxLocality();
    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    boolean getRelaxLocality();

    // optional string node_label_expression = 6;
    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    boolean hasNodeLabelExpression();
    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    java.lang.String getNodeLabelExpression();
    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    com.google.protobuf.ByteString
        getNodeLabelExpressionBytes();

    // optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
     */
    boolean hasExecutionTypeRequest();
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto getExecutionTypeRequest();
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProtoOrBuilder getExecutionTypeRequestOrBuilder();

    // optional int64 allocation_request_id = 8 [default = 0];
    /**
     * <code>optional int64 allocation_request_id = 8 [default = 0];</code>
     */
    boolean hasAllocationRequestId();
    /**
     * <code>optional int64 allocation_request_id = 8 [default = 0];</code>
     */
    long getAllocationRequestId();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceRequestProto}
   *
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////
   * //// From AM_RM_Protocol /////////////////////////////////////////////
   * //////////////////////////////////////////////////////////////////////
   * </pre>
   */
  public static final class ResourceRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements ResourceRequestProtoOrBuilder {
    // Use ResourceRequestProto.newBuilder() to construct.
    private ResourceRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ResourceRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ResourceRequestProto defaultInstance;
    public static ResourceRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public ResourceRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              resourceName_ = input.readBytes();
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              numContainers_ = input.readInt32();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              relaxLocality_ = input.readBool();
              break;
            }
            case 50: {
              bitField0_ |= 0x00000020;
              nodeLabelExpression_ = input.readBytes();
              break;
            }
            case 58: {
              org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000040) == 0x00000040)) {
                subBuilder = executionTypeRequest_.toBuilder();
              }
              executionTypeRequest_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(executionTypeRequest_);
                executionTypeRequest_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000040;
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              allocationRequestId_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ResourceRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<ResourceRequestProto>() {
      public ResourceRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ResourceRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.PriorityProto priority = 1;
    public static final int PRIORITY_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_;
    }

    // optional string resource_name = 2;
    public static final int RESOURCE_NAME_FIELD_NUMBER = 2;
    private java.lang.Object resourceName_;
    /**
     * <code>optional string resource_name = 2;</code>
     */
    public boolean hasResourceName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string resource_name = 2;</code>
     */
    public java.lang.String getResourceName() {
      java.lang.Object ref = resourceName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          resourceName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string resource_name = 2;</code>
     */
    public com.google.protobuf.ByteString
        getResourceNameBytes() {
      java.lang.Object ref = resourceName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        resourceName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.ResourceProto capability = 3;
    public static final int CAPABILITY_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    // optional int32 num_containers = 4;
    public static final int NUM_CONTAINERS_FIELD_NUMBER = 4;
    private int numContainers_;
    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    public boolean hasNumContainers() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    public int getNumContainers() {
      return numContainers_;
    }

    // optional bool relax_locality = 5 [default = true];
    public static final int RELAX_LOCALITY_FIELD_NUMBER = 5;
    private boolean relaxLocality_;
    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    public boolean hasRelaxLocality() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    public boolean getRelaxLocality() {
      return relaxLocality_;
    }

    // optional string node_label_expression = 6;
    public static final int NODE_LABEL_EXPRESSION_FIELD_NUMBER = 6;
    private java.lang.Object nodeLabelExpression_;
    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    public boolean hasNodeLabelExpression() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    public java.lang.String getNodeLabelExpression() {
      java.lang.Object ref = nodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          nodeLabelExpression_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    public com.google.protobuf.ByteString
        getNodeLabelExpressionBytes() {
      java.lang.Object ref = nodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nodeLabelExpression_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;
    public static final int EXECUTION_TYPE_REQUEST_FIELD_NUMBER = 7;
    private org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto executionTypeRequest_;
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
     */
    public boolean hasExecutionTypeRequest() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto getExecutionTypeRequest() {
      return executionTypeRequest_;
    }
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProtoOrBuilder getExecutionTypeRequestOrBuilder() {
      return executionTypeRequest_;
    }

    // optional int64 allocation_request_id = 8 [default = 0];
    public static final int ALLOCATION_REQUEST_ID_FIELD_NUMBER = 8;
    private long allocationRequestId_;
    /**
     * <code>optional int64 allocation_request_id = 8 [default = 0];</code>
     */
    public boolean hasAllocationRequestId() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional int64 allocation_request_id = 8 [default = 0];</code>
     */
    public long getAllocationRequestId() {
      return allocationRequestId_;
    }

    private void initFields() {
      priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      resourceName_ = "";
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      numContainers_ = 0;
      relaxLocality_ = true;
      nodeLabelExpression_ = "";
      executionTypeRequest_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.getDefaultInstance();
      allocationRequestId_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, priority_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getResourceNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, capability_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt32(4, numContainers_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(5, relaxLocality_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBytes(6, getNodeLabelExpressionBytes());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeMessage(7, executionTypeRequest_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeInt64(8, allocationRequestId_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, priority_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getResourceNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, capability_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, numContainers_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, relaxLocality_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(6, getNodeLabelExpressionBytes());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, executionTypeRequest_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(8, allocationRequestId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto) obj;

      boolean result = true;
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasResourceName() == other.hasResourceName());
      if (hasResourceName()) {
        result = result && getResourceName()
            .equals(other.getResourceName());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasNumContainers() == other.hasNumContainers());
      if (hasNumContainers()) {
        result = result && (getNumContainers()
            == other.getNumContainers());
      }
      result = result && (hasRelaxLocality() == other.hasRelaxLocality());
      if (hasRelaxLocality()) {
        result = result && (getRelaxLocality()
            == other.getRelaxLocality());
      }
      result = result && (hasNodeLabelExpression() == other.hasNodeLabelExpression());
      if (hasNodeLabelExpression()) {
        result = result && getNodeLabelExpression()
            .equals(other.getNodeLabelExpression());
      }
      result = result && (hasExecutionTypeRequest() == other.hasExecutionTypeRequest());
      if (hasExecutionTypeRequest()) {
        result = result && getExecutionTypeRequest()
            .equals(other.getExecutionTypeRequest());
      }
      result = result && (hasAllocationRequestId() == other.hasAllocationRequestId());
      if (hasAllocationRequestId()) {
        result = result && (getAllocationRequestId()
            == other.getAllocationRequestId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasResourceName()) {
        hash = (37 * hash) + RESOURCE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getResourceName().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasNumContainers()) {
        hash = (37 * hash) + NUM_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumContainers();
      }
      if (hasRelaxLocality()) {
        hash = (37 * hash) + RELAX_LOCALITY_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getRelaxLocality());
      }
      if (hasNodeLabelExpression()) {
        hash = (37 * hash) + NODE_LABEL_EXPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelExpression().hashCode();
      }
      if (hasExecutionTypeRequest()) {
        hash = (37 * hash) + EXECUTION_TYPE_REQUEST_FIELD_NUMBER;
        hash = (53 * hash) + getExecutionTypeRequest().hashCode();
      }
      if (hasAllocationRequestId()) {
        hash = (37 * hash) + ALLOCATION_REQUEST_ID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getAllocationRequestId());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceRequestProto}
     *
     * <pre>
     *&#47;/////////////////////////////////////////////////////////////////////
     * //// From AM_RM_Protocol /////////////////////////////////////////////
     * //////////////////////////////////////////////////////////////////////
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getPriorityFieldBuilder();
          getCapabilityFieldBuilder();
          getExecutionTypeRequestFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        resourceName_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        numContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        relaxLocality_ = true;
        bitField0_ = (bitField0_ & ~0x00000010);
        nodeLabelExpression_ = "";
        bitField0_ = (bitField0_ & ~0x00000020);
        if (executionTypeRequestBuilder_ == null) {
          executionTypeRequest_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.getDefaultInstance();
        } else {
          executionTypeRequestBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        allocationRequestId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.resourceName_ = resourceName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.numContainers_ = numContainers_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.relaxLocality_ = relaxLocality_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.nodeLabelExpression_ = nodeLabelExpression_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        if (executionTypeRequestBuilder_ == null) {
          result.executionTypeRequest_ = executionTypeRequest_;
        } else {
          result.executionTypeRequest_ = executionTypeRequestBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.allocationRequestId_ = allocationRequestId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance()) return this;
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasResourceName()) {
          bitField0_ |= 0x00000002;
          resourceName_ = other.resourceName_;
          onChanged();
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasNumContainers()) {
          setNumContainers(other.getNumContainers());
        }
        if (other.hasRelaxLocality()) {
          setRelaxLocality(other.getRelaxLocality());
        }
        if (other.hasNodeLabelExpression()) {
          bitField0_ |= 0x00000020;
          nodeLabelExpression_ = other.nodeLabelExpression_;
          onChanged();
        }
        if (other.hasExecutionTypeRequest()) {
          mergeExecutionTypeRequest(other.getExecutionTypeRequest());
        }
        if (other.hasAllocationRequestId()) {
          setAllocationRequestId(other.getAllocationRequestId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.PriorityProto priority = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  priority_,
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      // optional string resource_name = 2;
      private java.lang.Object resourceName_ = "";
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public boolean hasResourceName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public java.lang.String getResourceName() {
        java.lang.Object ref = resourceName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          resourceName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public com.google.protobuf.ByteString
          getResourceNameBytes() {
        java.lang.Object ref = resourceName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          resourceName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public Builder setResourceName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        resourceName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public Builder clearResourceName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        resourceName_ = getDefaultInstance().getResourceName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public Builder setResourceNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        resourceName_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto capability = 3;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // optional int32 num_containers = 4;
      private int numContainers_ ;
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public boolean hasNumContainers() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public int getNumContainers() {
        return numContainers_;
      }
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public Builder setNumContainers(int value) {
        bitField0_ |= 0x00000008;
        numContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public Builder clearNumContainers() {
        bitField0_ = (bitField0_ & ~0x00000008);
        numContainers_ = 0;
        onChanged();
        return this;
      }

      // optional bool relax_locality = 5 [default = true];
      private boolean relaxLocality_ = true;
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public boolean hasRelaxLocality() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public boolean getRelaxLocality() {
        return relaxLocality_;
      }
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public Builder setRelaxLocality(boolean value) {
        bitField0_ |= 0x00000010;
        relaxLocality_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public Builder clearRelaxLocality() {
        bitField0_ = (bitField0_ & ~0x00000010);
        relaxLocality_ = true;
        onChanged();
        return this;
      }

      // optional string node_label_expression = 6;
      private java.lang.Object nodeLabelExpression_ = "";
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public boolean hasNodeLabelExpression() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public java.lang.String getNodeLabelExpression() {
        java.lang.Object ref = nodeLabelExpression_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          nodeLabelExpression_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public com.google.protobuf.ByteString
          getNodeLabelExpressionBytes() {
        java.lang.Object ref = nodeLabelExpression_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nodeLabelExpression_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public Builder setNodeLabelExpression(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        nodeLabelExpression_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public Builder clearNodeLabelExpression() {
        bitField0_ = (bitField0_ & ~0x00000020);
        nodeLabelExpression_ = getDefaultInstance().getNodeLabelExpression();
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public Builder setNodeLabelExpressionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        nodeLabelExpression_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;
      private org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto executionTypeRequest_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProtoOrBuilder> executionTypeRequestBuilder_;
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
       */
      public boolean hasExecutionTypeRequest() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto getExecutionTypeRequest() {
        if (executionTypeRequestBuilder_ == null) {
          return executionTypeRequest_;
        } else {
          return executionTypeRequestBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
       */
      public Builder setExecutionTypeRequest(org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto value) {
        if (executionTypeRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          executionTypeRequest_ = value;
          onChanged();
        } else {
          executionTypeRequestBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
       */
      public Builder setExecutionTypeRequest(
          org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.Builder builderForValue) {
        if (executionTypeRequestBuilder_ == null) {
          executionTypeRequest_ = builderForValue.build();
          onChanged();
        } else {
          executionTypeRequestBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
       */
      public Builder mergeExecutionTypeRequest(org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto value) {
        if (executionTypeRequestBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040) &&
              executionTypeRequest_ != org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.getDefaultInstance()) {
            executionTypeRequest_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.newBuilder(executionTypeRequest_).mergeFrom(value).buildPartial();
          } else {
            executionTypeRequest_ = value;
          }
          onChanged();
        } else {
          executionTypeRequestBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
       */
      public Builder clearExecutionTypeRequest() {
        if (executionTypeRequestBuilder_ == null) {
          executionTypeRequest_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.getDefaultInstance();
          onChanged();
        } else {
          executionTypeRequestBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.Builder getExecutionTypeRequestBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getExecutionTypeRequestFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProtoOrBuilder getExecutionTypeRequestOrBuilder() {
        if (executionTypeRequestBuilder_ != null) {
          return executionTypeRequestBuilder_.getMessageOrBuilder();
        } else {
          return executionTypeRequest_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeRequestProto execution_type_request = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProtoOrBuilder> 
          getExecutionTypeRequestFieldBuilder() {
        if (executionTypeRequestBuilder_ == null) {
          executionTypeRequestBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProtoOrBuilder>(
                  executionTypeRequest_,
                  getParentForChildren(),
                  isClean());
          executionTypeRequest_ = null;
        }
        return executionTypeRequestBuilder_;
      }

      // optional int64 allocation_request_id = 8 [default = 0];
      private long allocationRequestId_ ;
      /**
       * <code>optional int64 allocation_request_id = 8 [default = 0];</code>
       */
      public boolean hasAllocationRequestId() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional int64 allocation_request_id = 8 [default = 0];</code>
       */
      public long getAllocationRequestId() {
        return allocationRequestId_;
      }
      /**
       * <code>optional int64 allocation_request_id = 8 [default = 0];</code>
       */
      public Builder setAllocationRequestId(long value) {
        bitField0_ |= 0x00000080;
        allocationRequestId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 allocation_request_id = 8 [default = 0];</code>
       */
      public Builder clearAllocationRequestId() {
        bitField0_ = (bitField0_ & ~0x00000080);
        allocationRequestId_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceRequestProto)
    }

    static {
      defaultInstance = new ResourceRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceRequestProto)
  }

  public interface ExecutionTypeRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ExecutionTypeProto execution_type = 1 [default = GUARANTEED];
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 1 [default = GUARANTEED];</code>
     */
    boolean hasExecutionType();
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 1 [default = GUARANTEED];</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType();

    // optional bool enforce_execution_type = 2 [default = false];
    /**
     * <code>optional bool enforce_execution_type = 2 [default = false];</code>
     */
    boolean hasEnforceExecutionType();
    /**
     * <code>optional bool enforce_execution_type = 2 [default = false];</code>
     */
    boolean getEnforceExecutionType();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ExecutionTypeRequestProto}
   */
  public static final class ExecutionTypeRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements ExecutionTypeRequestProtoOrBuilder {
    // Use ExecutionTypeRequestProto.newBuilder() to construct.
    private ExecutionTypeRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ExecutionTypeRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ExecutionTypeRequestProto defaultInstance;
    public static ExecutionTypeRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public ExecutionTypeRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ExecutionTypeRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                executionType_ = value;
              }
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              enforceExecutionType_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ExecutionTypeRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ExecutionTypeRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ExecutionTypeRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<ExecutionTypeRequestProto>() {
      public ExecutionTypeRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ExecutionTypeRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ExecutionTypeRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ExecutionTypeProto execution_type = 1 [default = GUARANTEED];
    public static final int EXECUTION_TYPE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto executionType_;
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 1 [default = GUARANTEED];</code>
     */
    public boolean hasExecutionType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 1 [default = GUARANTEED];</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType() {
      return executionType_;
    }

    // optional bool enforce_execution_type = 2 [default = false];
    public static final int ENFORCE_EXECUTION_TYPE_FIELD_NUMBER = 2;
    private boolean enforceExecutionType_;
    /**
     * <code>optional bool enforce_execution_type = 2 [default = false];</code>
     */
    public boolean hasEnforceExecutionType() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool enforce_execution_type = 2 [default = false];</code>
     */
    public boolean getEnforceExecutionType() {
      return enforceExecutionType_;
    }

    private void initFields() {
      executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
      enforceExecutionType_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, executionType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, enforceExecutionType_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, executionType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, enforceExecutionType_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto) obj;

      boolean result = true;
      result = result && (hasExecutionType() == other.hasExecutionType());
      if (hasExecutionType()) {
        result = result &&
            (getExecutionType() == other.getExecutionType());
      }
      result = result && (hasEnforceExecutionType() == other.hasEnforceExecutionType());
      if (hasEnforceExecutionType()) {
        result = result && (getEnforceExecutionType()
            == other.getEnforceExecutionType());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasExecutionType()) {
        hash = (37 * hash) + EXECUTION_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getExecutionType());
      }
      if (hasEnforceExecutionType()) {
        hash = (37 * hash) + ENFORCE_EXECUTION_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getEnforceExecutionType());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ExecutionTypeRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ExecutionTypeRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ExecutionTypeRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
        bitField0_ = (bitField0_ & ~0x00000001);
        enforceExecutionType_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ExecutionTypeRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.executionType_ = executionType_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.enforceExecutionType_ = enforceExecutionType_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto.getDefaultInstance()) return this;
        if (other.hasExecutionType()) {
          setExecutionType(other.getExecutionType());
        }
        if (other.hasEnforceExecutionType()) {
          setEnforceExecutionType(other.getEnforceExecutionType());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ExecutionTypeProto execution_type = 1 [default = GUARANTEED];
      private org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 1 [default = GUARANTEED];</code>
       */
      public boolean hasExecutionType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 1 [default = GUARANTEED];</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType() {
        return executionType_;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 1 [default = GUARANTEED];</code>
       */
      public Builder setExecutionType(org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        executionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto execution_type = 1 [default = GUARANTEED];</code>
       */
      public Builder clearExecutionType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
        onChanged();
        return this;
      }

      // optional bool enforce_execution_type = 2 [default = false];
      private boolean enforceExecutionType_ ;
      /**
       * <code>optional bool enforce_execution_type = 2 [default = false];</code>
       */
      public boolean hasEnforceExecutionType() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bool enforce_execution_type = 2 [default = false];</code>
       */
      public boolean getEnforceExecutionType() {
        return enforceExecutionType_;
      }
      /**
       * <code>optional bool enforce_execution_type = 2 [default = false];</code>
       */
      public Builder setEnforceExecutionType(boolean value) {
        bitField0_ |= 0x00000002;
        enforceExecutionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool enforce_execution_type = 2 [default = false];</code>
       */
      public Builder clearEnforceExecutionType() {
        bitField0_ = (bitField0_ & ~0x00000002);
        enforceExecutionType_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ExecutionTypeRequestProto)
    }

    static {
      defaultInstance = new ExecutionTypeRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ExecutionTypeRequestProto)
  }

  public interface PreemptionMessageProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    boolean hasStrictContract();
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getStrictContract();
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder getStrictContractOrBuilder();

    // optional .hadoop.yarn.PreemptionContractProto contract = 2;
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    boolean hasContract();
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getContract();
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder getContractOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionMessageProto}
   */
  public static final class PreemptionMessageProto extends
      com.google.protobuf.GeneratedMessage
      implements PreemptionMessageProtoOrBuilder {
    // Use PreemptionMessageProto.newBuilder() to construct.
    private PreemptionMessageProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private PreemptionMessageProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final PreemptionMessageProto defaultInstance;
    public static PreemptionMessageProto getDefaultInstance() {
      return defaultInstance;
    }

    public PreemptionMessageProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionMessageProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = strictContract_.toBuilder();
              }
              strictContract_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(strictContract_);
                strictContract_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = contract_.toBuilder();
              }
              contract_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(contract_);
                contract_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder.class);
    }

    public static com.google.protobuf.Parser<PreemptionMessageProto> PARSER =
        new com.google.protobuf.AbstractParser<PreemptionMessageProto>() {
      public PreemptionMessageProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PreemptionMessageProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionMessageProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;
    public static final int STRICTCONTRACT_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto strictContract_;
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    public boolean hasStrictContract() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getStrictContract() {
      return strictContract_;
    }
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder getStrictContractOrBuilder() {
      return strictContract_;
    }

    // optional .hadoop.yarn.PreemptionContractProto contract = 2;
    public static final int CONTRACT_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto contract_;
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    public boolean hasContract() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getContract() {
      return contract_;
    }
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder getContractOrBuilder() {
      return contract_;
    }

    private void initFields() {
      strictContract_ = org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance();
      contract_ = org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, strictContract_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, contract_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, strictContract_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, contract_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto) obj;

      boolean result = true;
      result = result && (hasStrictContract() == other.hasStrictContract());
      if (hasStrictContract()) {
        result = result && getStrictContract()
            .equals(other.getStrictContract());
      }
      result = result && (hasContract() == other.hasContract());
      if (hasContract()) {
        result = result && getContract()
            .equals(other.getContract());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasStrictContract()) {
        hash = (37 * hash) + STRICTCONTRACT_FIELD_NUMBER;
        hash = (53 * hash) + getStrictContract().hashCode();
      }
      if (hasContract()) {
        hash = (37 * hash) + CONTRACT_FIELD_NUMBER;
        hash = (53 * hash) + getContract().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionMessageProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getStrictContractFieldBuilder();
          getContractFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (strictContractBuilder_ == null) {
          strictContract_ = org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance();
        } else {
          strictContractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (contractBuilder_ == null) {
          contract_ = org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance();
        } else {
          contractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (strictContractBuilder_ == null) {
          result.strictContract_ = strictContract_;
        } else {
          result.strictContract_ = strictContractBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (contractBuilder_ == null) {
          result.contract_ = contract_;
        } else {
          result.contract_ = contractBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.getDefaultInstance()) return this;
        if (other.hasStrictContract()) {
          mergeStrictContract(other.getStrictContract());
        }
        if (other.hasContract()) {
          mergeContract(other.getContract());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto strictContract_ = org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder> strictContractBuilder_;
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public boolean hasStrictContract() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getStrictContract() {
        if (strictContractBuilder_ == null) {
          return strictContract_;
        } else {
          return strictContractBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder setStrictContract(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto value) {
        if (strictContractBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          strictContract_ = value;
          onChanged();
        } else {
          strictContractBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder setStrictContract(
          org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder builderForValue) {
        if (strictContractBuilder_ == null) {
          strictContract_ = builderForValue.build();
          onChanged();
        } else {
          strictContractBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder mergeStrictContract(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto value) {
        if (strictContractBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              strictContract_ != org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance()) {
            strictContract_ =
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.newBuilder(strictContract_).mergeFrom(value).buildPartial();
          } else {
            strictContract_ = value;
          }
          onChanged();
        } else {
          strictContractBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder clearStrictContract() {
        if (strictContractBuilder_ == null) {
          strictContract_ = org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance();
          onChanged();
        } else {
          strictContractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder getStrictContractBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getStrictContractFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder getStrictContractOrBuilder() {
        if (strictContractBuilder_ != null) {
          return strictContractBuilder_.getMessageOrBuilder();
        } else {
          return strictContract_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder> 
          getStrictContractFieldBuilder() {
        if (strictContractBuilder_ == null) {
          strictContractBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder>(
                  strictContract_,
                  getParentForChildren(),
                  isClean());
          strictContract_ = null;
        }
        return strictContractBuilder_;
      }

      // optional .hadoop.yarn.PreemptionContractProto contract = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto contract_ = org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder> contractBuilder_;
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public boolean hasContract() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getContract() {
        if (contractBuilder_ == null) {
          return contract_;
        } else {
          return contractBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder setContract(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto value) {
        if (contractBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          contract_ = value;
          onChanged();
        } else {
          contractBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder setContract(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder builderForValue) {
        if (contractBuilder_ == null) {
          contract_ = builderForValue.build();
          onChanged();
        } else {
          contractBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder mergeContract(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto value) {
        if (contractBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              contract_ != org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance()) {
            contract_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.newBuilder(contract_).mergeFrom(value).buildPartial();
          } else {
            contract_ = value;
          }
          onChanged();
        } else {
          contractBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder clearContract() {
        if (contractBuilder_ == null) {
          contract_ = org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance();
          onChanged();
        } else {
          contractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder getContractBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getContractFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder getContractOrBuilder() {
        if (contractBuilder_ != null) {
          return contractBuilder_.getMessageOrBuilder();
        } else {
          return contract_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder> 
          getContractFieldBuilder() {
        if (contractBuilder_ == null) {
          contractBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder>(
                  contract_,
                  getParentForChildren(),
                  isClean());
          contract_ = null;
        }
        return contractBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionMessageProto)
    }

    static {
      defaultInstance = new PreemptionMessageProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionMessageProto)
  }

  public interface StrictPreemptionContractProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hadoop.yarn.PreemptionContainerProto container = 1;
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> 
        getContainerList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index);
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    int getContainerCount();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.StrictPreemptionContractProto}
   */
  public static final class StrictPreemptionContractProto extends
      com.google.protobuf.GeneratedMessage
      implements StrictPreemptionContractProtoOrBuilder {
    // Use StrictPreemptionContractProto.newBuilder() to construct.
    private StrictPreemptionContractProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private StrictPreemptionContractProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final StrictPreemptionContractProto defaultInstance;
    public static StrictPreemptionContractProto getDefaultInstance() {
      return defaultInstance;
    }

    public StrictPreemptionContractProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private StrictPreemptionContractProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              container_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          container_ = java.util.Collections.unmodifiableList(container_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder.class);
    }

    public static com.google.protobuf.Parser<StrictPreemptionContractProto> PARSER =
        new com.google.protobuf.AbstractParser<StrictPreemptionContractProto>() {
      public StrictPreemptionContractProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new StrictPreemptionContractProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<StrictPreemptionContractProto> getParserForType() {
      return PARSER;
    }

    // repeated .hadoop.yarn.PreemptionContainerProto container = 1;
    public static final int CONTAINER_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_;
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public int getContainerCount() {
      return container_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
      return container_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index) {
      return container_.get(index);
    }

    private void initFields() {
      container_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < container_.size(); i++) {
        output.writeMessage(1, container_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < container_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, container_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto) obj;

      boolean result = true;
      result = result && getContainerList()
          .equals(other.getContainerList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getContainerCount() > 0) {
        hash = (37 * hash) + CONTAINER_FIELD_NUMBER;
        hash = (53 * hash) + getContainerList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StrictPreemptionContractProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          containerBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto(this);
        int from_bitField0_ = bitField0_;
        if (containerBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            container_ = java.util.Collections.unmodifiableList(container_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.container_ = container_;
        } else {
          result.container_ = containerBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance()) return this;
        if (containerBuilder_ == null) {
          if (!other.container_.isEmpty()) {
            if (container_.isEmpty()) {
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureContainerIsMutable();
              container_.addAll(other.container_);
            }
            onChanged();
          }
        } else {
          if (!other.container_.isEmpty()) {
            if (containerBuilder_.isEmpty()) {
              containerBuilder_.dispose();
              containerBuilder_ = null;
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000001);
              containerBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getContainerFieldBuilder() : null;
            } else {
              containerBuilder_.addAllMessages(other.container_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hadoop.yarn.PreemptionContainerProto container = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_ =
        java.util.Collections.emptyList();
      private void ensureContainerIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>(container_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> containerBuilder_;

      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
        if (containerBuilder_ == null) {
          return java.util.Collections.unmodifiableList(container_);
        } else {
          return containerBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public int getContainerCount() {
        if (containerBuilder_ == null) {
          return container_.size();
        } else {
          return containerBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);
        } else {
          return containerBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.set(index, value);
          onChanged();
        } else {
          containerBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.set(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(value);
          onChanged();
        } else {
          containerBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(index, value);
          onChanged();
        } else {
          containerBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addAllContainer(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> values) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          super.addAll(values, container_);
          onChanged();
        } else {
          containerBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder clearContainer() {
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          containerBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder removeContainer(int index) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.remove(index);
          onChanged();
        } else {
          containerBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder getContainerBuilder(
          int index) {
        return getContainerFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
          int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);  } else {
          return containerBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
           getContainerOrBuilderList() {
        if (containerBuilder_ != null) {
          return containerBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(container_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder() {
        return getContainerFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder(
          int index) {
        return getContainerFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder> 
           getContainerBuilderList() {
        return getContainerFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
          getContainerFieldBuilder() {
        if (containerBuilder_ == null) {
          containerBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder>(
                  container_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          container_ = null;
        }
        return containerBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StrictPreemptionContractProto)
    }

    static {
      defaultInstance = new StrictPreemptionContractProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StrictPreemptionContractProto)
  }

  public interface PreemptionContractProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> 
        getResourceList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getResource(int index);
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    int getResourceCount();
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
        getResourceOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder getResourceOrBuilder(
        int index);

    // repeated .hadoop.yarn.PreemptionContainerProto container = 2;
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> 
        getContainerList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index);
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    int getContainerCount();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionContractProto}
   */
  public static final class PreemptionContractProto extends
      com.google.protobuf.GeneratedMessage
      implements PreemptionContractProtoOrBuilder {
    // Use PreemptionContractProto.newBuilder() to construct.
    private PreemptionContractProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private PreemptionContractProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final PreemptionContractProto defaultInstance;
    public static PreemptionContractProto getDefaultInstance() {
      return defaultInstance;
    }

    public PreemptionContractProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionContractProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                resource_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              resource_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              container_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          resource_ = java.util.Collections.unmodifiableList(resource_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          container_ = java.util.Collections.unmodifiableList(container_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder.class);
    }

    public static com.google.protobuf.Parser<PreemptionContractProto> PARSER =
        new com.google.protobuf.AbstractParser<PreemptionContractProto>() {
      public PreemptionContractProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PreemptionContractProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionContractProto> getParserForType() {
      return PARSER;
    }

    // repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;
    public static final int RESOURCE_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> resource_;
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> getResourceList() {
      return resource_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
        getResourceOrBuilderList() {
      return resource_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public int getResourceCount() {
      return resource_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getResource(int index) {
      return resource_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder getResourceOrBuilder(
        int index) {
      return resource_.get(index);
    }

    // repeated .hadoop.yarn.PreemptionContainerProto container = 2;
    public static final int CONTAINER_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_;
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public int getContainerCount() {
      return container_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
      return container_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index) {
      return container_.get(index);
    }

    private void initFields() {
      resource_ = java.util.Collections.emptyList();
      container_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < resource_.size(); i++) {
        output.writeMessage(1, resource_.get(i));
      }
      for (int i = 0; i < container_.size(); i++) {
        output.writeMessage(2, container_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < resource_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, resource_.get(i));
      }
      for (int i = 0; i < container_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, container_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto) obj;

      boolean result = true;
      result = result && getResourceList()
          .equals(other.getResourceList());
      result = result && getContainerList()
          .equals(other.getContainerList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getResourceCount() > 0) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResourceList().hashCode();
      }
      if (getContainerCount() > 0) {
        hash = (37 * hash) + CONTAINER_FIELD_NUMBER;
        hash = (53 * hash) + getContainerList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionContractProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
          getContainerFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          resourceBuilder_.clear();
        }
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          containerBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto(this);
        int from_bitField0_ = bitField0_;
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            resource_ = java.util.Collections.unmodifiableList(resource_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (containerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            container_ = java.util.Collections.unmodifiableList(container_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.container_ = container_;
        } else {
          result.container_ = containerBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance()) return this;
        if (resourceBuilder_ == null) {
          if (!other.resource_.isEmpty()) {
            if (resource_.isEmpty()) {
              resource_ = other.resource_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResourceIsMutable();
              resource_.addAll(other.resource_);
            }
            onChanged();
          }
        } else {
          if (!other.resource_.isEmpty()) {
            if (resourceBuilder_.isEmpty()) {
              resourceBuilder_.dispose();
              resourceBuilder_ = null;
              resource_ = other.resource_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resourceBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getResourceFieldBuilder() : null;
            } else {
              resourceBuilder_.addAllMessages(other.resource_);
            }
          }
        }
        if (containerBuilder_ == null) {
          if (!other.container_.isEmpty()) {
            if (container_.isEmpty()) {
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureContainerIsMutable();
              container_.addAll(other.container_);
            }
            onChanged();
          }
        } else {
          if (!other.container_.isEmpty()) {
            if (containerBuilder_.isEmpty()) {
              containerBuilder_.dispose();
              containerBuilder_ = null;
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000002);
              containerBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getContainerFieldBuilder() : null;
            } else {
              containerBuilder_.addAllMessages(other.container_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> resource_ =
        java.util.Collections.emptyList();
      private void ensureResourceIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          resource_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto>(resource_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> resourceBuilder_;

      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> getResourceList() {
        if (resourceBuilder_ == null) {
          return java.util.Collections.unmodifiableList(resource_);
        } else {
          return resourceBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public int getResourceCount() {
        if (resourceBuilder_ == null) {
          return resource_.size();
        } else {
          return resourceBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getResource(int index) {
        if (resourceBuilder_ == null) {
          return resource_.get(index);
        } else {
          return resourceBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResourceIsMutable();
          resource_.set(index, value);
          onChanged();
        } else {
          resourceBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.set(index, builderForValue.build());
          onChanged();
        } else {
          resourceBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResourceIsMutable();
          resource_.add(value);
          onChanged();
        } else {
          resourceBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResourceIsMutable();
          resource_.add(index, value);
          onChanged();
        } else {
          resourceBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.add(builderForValue.build());
          onChanged();
        } else {
          resourceBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.add(index, builderForValue.build());
          onChanged();
        } else {
          resourceBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addAllResource(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> values) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          super.addAll(values, resource_);
          onChanged();
        } else {
          resourceBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder removeResource(int index) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.remove(index);
          onChanged();
        } else {
          resourceBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder getResourceBuilder(
          int index) {
        return getResourceFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder getResourceOrBuilder(
          int index) {
        if (resourceBuilder_ == null) {
          return resource_.get(index);  } else {
          return resourceBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
           getResourceOrBuilderList() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(resource_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder addResourceBuilder() {
        return getResourceFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder addResourceBuilder(
          int index) {
        return getResourceFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder> 
           getResourceBuilderList() {
        return getResourceFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder>(
                  resource_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // repeated .hadoop.yarn.PreemptionContainerProto container = 2;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_ =
        java.util.Collections.emptyList();
      private void ensureContainerIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>(container_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> containerBuilder_;

      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
        if (containerBuilder_ == null) {
          return java.util.Collections.unmodifiableList(container_);
        } else {
          return containerBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public int getContainerCount() {
        if (containerBuilder_ == null) {
          return container_.size();
        } else {
          return containerBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);
        } else {
          return containerBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.set(index, value);
          onChanged();
        } else {
          containerBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.set(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(value);
          onChanged();
        } else {
          containerBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(index, value);
          onChanged();
        } else {
          containerBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addAllContainer(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> values) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          super.addAll(values, container_);
          onChanged();
        } else {
          containerBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder clearContainer() {
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          containerBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder removeContainer(int index) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.remove(index);
          onChanged();
        } else {
          containerBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder getContainerBuilder(
          int index) {
        return getContainerFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
          int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);  } else {
          return containerBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
           getContainerOrBuilderList() {
        if (containerBuilder_ != null) {
          return containerBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(container_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder() {
        return getContainerFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder(
          int index) {
        return getContainerFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder> 
           getContainerBuilderList() {
        return getContainerFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
          getContainerFieldBuilder() {
        if (containerBuilder_ == null) {
          containerBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder>(
                  container_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          container_ = null;
        }
        return containerBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionContractProto)
    }

    static {
      defaultInstance = new PreemptionContractProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionContractProto)
  }

  public interface PreemptionContainerProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    boolean hasId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionContainerProto}
   */
  public static final class PreemptionContainerProto extends
      com.google.protobuf.GeneratedMessage
      implements PreemptionContainerProtoOrBuilder {
    // Use PreemptionContainerProto.newBuilder() to construct.
    private PreemptionContainerProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private PreemptionContainerProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final PreemptionContainerProto defaultInstance;
    public static PreemptionContainerProto getDefaultInstance() {
      return defaultInstance;
    }

    public PreemptionContainerProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionContainerProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = id_.toBuilder();
              }
              id_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(id_);
                id_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder.class);
    }

    public static com.google.protobuf.Parser<PreemptionContainerProto> PARSER =
        new com.google.protobuf.AbstractParser<PreemptionContainerProto>() {
      public PreemptionContainerProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PreemptionContainerProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionContainerProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto id = 1;
    public static final int ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
      return id_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
      return id_;
    }

    private void initFields() {
      id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, id_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, id_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto) obj;

      boolean result = true;
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && getId()
            .equals(other.getId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + getId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionContainerProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (idBuilder_ == null) {
          id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (idBuilder_ == null) {
          result.id_ = id_;
        } else {
          result.id_ = idBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance()) return this;
        if (other.hasId()) {
          mergeId(other.getId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> idBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
        if (idBuilder_ == null) {
          return id_;
        } else {
          return idBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          id_ = value;
          onChanged();
        } else {
          idBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (idBuilder_ == null) {
          id_ = builderForValue.build();
          onChanged();
        } else {
          idBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder mergeId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              id_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            id_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(id_).mergeFrom(value).buildPartial();
          } else {
            id_ = value;
          }
          onChanged();
        } else {
          idBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder clearId() {
        if (idBuilder_ == null) {
          id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
        if (idBuilder_ != null) {
          return idBuilder_.getMessageOrBuilder();
        } else {
          return id_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getIdFieldBuilder() {
        if (idBuilder_ == null) {
          idBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  id_,
                  getParentForChildren(),
                  isClean());
          id_ = null;
        }
        return idBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionContainerProto)
    }

    static {
      defaultInstance = new PreemptionContainerProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionContainerProto)
  }

  public interface PreemptionResourceRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ResourceRequestProto resource = 1;
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getResourceOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionResourceRequestProto}
   */
  public static final class PreemptionResourceRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements PreemptionResourceRequestProtoOrBuilder {
    // Use PreemptionResourceRequestProto.newBuilder() to construct.
    private PreemptionResourceRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private PreemptionResourceRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final PreemptionResourceRequestProto defaultInstance;
    public static PreemptionResourceRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public PreemptionResourceRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionResourceRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<PreemptionResourceRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<PreemptionResourceRequestProto>() {
      public PreemptionResourceRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PreemptionResourceRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionResourceRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ResourceRequestProto resource = 1;
    public static final int RESOURCE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    private void initFields() {
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, resource_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, resource_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto) obj;

      boolean result = true;
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionResourceRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance()) return this;
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ResourceRequestProto resource = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionResourceRequestProto)
    }

    static {
      defaultInstance = new PreemptionResourceRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionResourceRequestProto)
  }

  public interface ResourceBlacklistRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated string blacklist_additions = 1;
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    java.util.List<java.lang.String>
    getBlacklistAdditionsList();
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    int getBlacklistAdditionsCount();
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    java.lang.String getBlacklistAdditions(int index);
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    com.google.protobuf.ByteString
        getBlacklistAdditionsBytes(int index);

    // repeated string blacklist_removals = 2;
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    java.util.List<java.lang.String>
    getBlacklistRemovalsList();
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    int getBlacklistRemovalsCount();
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    java.lang.String getBlacklistRemovals(int index);
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    com.google.protobuf.ByteString
        getBlacklistRemovalsBytes(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceBlacklistRequestProto}
   */
  public static final class ResourceBlacklistRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements ResourceBlacklistRequestProtoOrBuilder {
    // Use ResourceBlacklistRequestProto.newBuilder() to construct.
    private ResourceBlacklistRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ResourceBlacklistRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ResourceBlacklistRequestProto defaultInstance;
    public static ResourceBlacklistRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public ResourceBlacklistRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceBlacklistRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                blacklistAdditions_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              blacklistAdditions_.add(input.readBytes());
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                blacklistRemovals_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              blacklistRemovals_.add(input.readBytes());
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          blacklistAdditions_ = new com.google.protobuf.UnmodifiableLazyStringList(blacklistAdditions_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          blacklistRemovals_ = new com.google.protobuf.UnmodifiableLazyStringList(blacklistRemovals_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ResourceBlacklistRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<ResourceBlacklistRequestProto>() {
      public ResourceBlacklistRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ResourceBlacklistRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceBlacklistRequestProto> getParserForType() {
      return PARSER;
    }

    // repeated string blacklist_additions = 1;
    public static final int BLACKLIST_ADDITIONS_FIELD_NUMBER = 1;
    private com.google.protobuf.LazyStringList blacklistAdditions_;
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public java.util.List<java.lang.String>
        getBlacklistAdditionsList() {
      return blacklistAdditions_;
    }
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public int getBlacklistAdditionsCount() {
      return blacklistAdditions_.size();
    }
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public java.lang.String getBlacklistAdditions(int index) {
      return blacklistAdditions_.get(index);
    }
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public com.google.protobuf.ByteString
        getBlacklistAdditionsBytes(int index) {
      return blacklistAdditions_.getByteString(index);
    }

    // repeated string blacklist_removals = 2;
    public static final int BLACKLIST_REMOVALS_FIELD_NUMBER = 2;
    private com.google.protobuf.LazyStringList blacklistRemovals_;
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public java.util.List<java.lang.String>
        getBlacklistRemovalsList() {
      return blacklistRemovals_;
    }
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public int getBlacklistRemovalsCount() {
      return blacklistRemovals_.size();
    }
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public java.lang.String getBlacklistRemovals(int index) {
      return blacklistRemovals_.get(index);
    }
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public com.google.protobuf.ByteString
        getBlacklistRemovalsBytes(int index) {
      return blacklistRemovals_.getByteString(index);
    }

    private void initFields() {
      blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < blacklistAdditions_.size(); i++) {
        output.writeBytes(1, blacklistAdditions_.getByteString(i));
      }
      for (int i = 0; i < blacklistRemovals_.size(); i++) {
        output.writeBytes(2, blacklistRemovals_.getByteString(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < blacklistAdditions_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(blacklistAdditions_.getByteString(i));
        }
        size += dataSize;
        size += 1 * getBlacklistAdditionsList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < blacklistRemovals_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(blacklistRemovals_.getByteString(i));
        }
        size += dataSize;
        size += 1 * getBlacklistRemovalsList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto) obj;

      boolean result = true;
      result = result && getBlacklistAdditionsList()
          .equals(other.getBlacklistAdditionsList());
      result = result && getBlacklistRemovalsList()
          .equals(other.getBlacklistRemovalsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getBlacklistAdditionsCount() > 0) {
        hash = (37 * hash) + BLACKLIST_ADDITIONS_FIELD_NUMBER;
        hash = (53 * hash) + getBlacklistAdditionsList().hashCode();
      }
      if (getBlacklistRemovalsCount() > 0) {
        hash = (37 * hash) + BLACKLIST_REMOVALS_FIELD_NUMBER;
        hash = (53 * hash) + getBlacklistRemovalsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceBlacklistRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          blacklistAdditions_ = new com.google.protobuf.UnmodifiableLazyStringList(
              blacklistAdditions_);
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.blacklistAdditions_ = blacklistAdditions_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          blacklistRemovals_ = new com.google.protobuf.UnmodifiableLazyStringList(
              blacklistRemovals_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.blacklistRemovals_ = blacklistRemovals_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.getDefaultInstance()) return this;
        if (!other.blacklistAdditions_.isEmpty()) {
          if (blacklistAdditions_.isEmpty()) {
            blacklistAdditions_ = other.blacklistAdditions_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureBlacklistAdditionsIsMutable();
            blacklistAdditions_.addAll(other.blacklistAdditions_);
          }
          onChanged();
        }
        if (!other.blacklistRemovals_.isEmpty()) {
          if (blacklistRemovals_.isEmpty()) {
            blacklistRemovals_ = other.blacklistRemovals_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureBlacklistRemovalsIsMutable();
            blacklistRemovals_.addAll(other.blacklistRemovals_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated string blacklist_additions = 1;
      private com.google.protobuf.LazyStringList blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureBlacklistAdditionsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          blacklistAdditions_ = new com.google.protobuf.LazyStringArrayList(blacklistAdditions_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public java.util.List<java.lang.String>
          getBlacklistAdditionsList() {
        return java.util.Collections.unmodifiableList(blacklistAdditions_);
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public int getBlacklistAdditionsCount() {
        return blacklistAdditions_.size();
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public java.lang.String getBlacklistAdditions(int index) {
        return blacklistAdditions_.get(index);
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public com.google.protobuf.ByteString
          getBlacklistAdditionsBytes(int index) {
        return blacklistAdditions_.getByteString(index);
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder setBlacklistAdditions(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistAdditionsIsMutable();
        blacklistAdditions_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder addBlacklistAdditions(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistAdditionsIsMutable();
        blacklistAdditions_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder addAllBlacklistAdditions(
          java.lang.Iterable<java.lang.String> values) {
        ensureBlacklistAdditionsIsMutable();
        super.addAll(values, blacklistAdditions_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder clearBlacklistAdditions() {
        blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder addBlacklistAdditionsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistAdditionsIsMutable();
        blacklistAdditions_.add(value);
        onChanged();
        return this;
      }

      // repeated string blacklist_removals = 2;
      private com.google.protobuf.LazyStringList blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureBlacklistRemovalsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          blacklistRemovals_ = new com.google.protobuf.LazyStringArrayList(blacklistRemovals_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public java.util.List<java.lang.String>
          getBlacklistRemovalsList() {
        return java.util.Collections.unmodifiableList(blacklistRemovals_);
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public int getBlacklistRemovalsCount() {
        return blacklistRemovals_.size();
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public java.lang.String getBlacklistRemovals(int index) {
        return blacklistRemovals_.get(index);
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public com.google.protobuf.ByteString
          getBlacklistRemovalsBytes(int index) {
        return blacklistRemovals_.getByteString(index);
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder setBlacklistRemovals(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistRemovalsIsMutable();
        blacklistRemovals_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder addBlacklistRemovals(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistRemovalsIsMutable();
        blacklistRemovals_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder addAllBlacklistRemovals(
          java.lang.Iterable<java.lang.String> values) {
        ensureBlacklistRemovalsIsMutable();
        super.addAll(values, blacklistRemovals_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder clearBlacklistRemovals() {
        blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder addBlacklistRemovalsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistRemovalsIsMutable();
        blacklistRemovals_.add(value);
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceBlacklistRequestProto)
    }

    static {
      defaultInstance = new ResourceBlacklistRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceBlacklistRequestProto)
  }

  public interface ApplicationSubmissionContextProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    // optional string application_name = 2 [default = "N/A"];
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    boolean hasApplicationName();
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    java.lang.String getApplicationName();
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getApplicationNameBytes();

    // optional string queue = 3 [default = "default"];
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    boolean hasQueue();
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    java.lang.String getQueue();
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    com.google.protobuf.ByteString
        getQueueBytes();

    // optional .hadoop.yarn.PriorityProto priority = 4;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    // optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    boolean hasAmContainerSpec();
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getAmContainerSpec();
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getAmContainerSpecOrBuilder();

    // optional bool cancel_tokens_when_complete = 6 [default = true];
    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    boolean hasCancelTokensWhenComplete();
    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    boolean getCancelTokensWhenComplete();

    // optional bool unmanaged_am = 7 [default = false];
    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    boolean hasUnmanagedAm();
    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    boolean getUnmanagedAm();

    // optional int32 maxAppAttempts = 8 [default = 0];
    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    boolean hasMaxAppAttempts();
    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    int getMaxAppAttempts();

    // optional .hadoop.yarn.ResourceProto resource = 9;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    // optional string applicationType = 10 [default = "YARN"];
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    boolean hasApplicationType();
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    java.lang.String getApplicationType();
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    com.google.protobuf.ByteString
        getApplicationTypeBytes();

    // optional bool keep_containers_across_application_attempts = 11 [default = false];
    /**
     * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
     */
    boolean hasKeepContainersAcrossApplicationAttempts();
    /**
     * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
     */
    boolean getKeepContainersAcrossApplicationAttempts();

    // repeated string applicationTags = 12;
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    java.util.List<java.lang.String>
    getApplicationTagsList();
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    int getApplicationTagsCount();
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    java.lang.String getApplicationTags(int index);
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    com.google.protobuf.ByteString
        getApplicationTagsBytes(int index);

    // optional int64 attempt_failures_validity_interval = 13 [default = -1];
    /**
     * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
     */
    boolean hasAttemptFailuresValidityInterval();
    /**
     * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
     */
    long getAttemptFailuresValidityInterval();

    // optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;
    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    boolean hasLogAggregationContext();
    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto getLogAggregationContext();
    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder getLogAggregationContextOrBuilder();

    // optional .hadoop.yarn.ReservationIdProto reservation_id = 15;
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    boolean hasReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder();

    // optional string node_label_expression = 16;
    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    boolean hasNodeLabelExpression();
    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    java.lang.String getNodeLabelExpression();
    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    com.google.protobuf.ByteString
        getNodeLabelExpressionBytes();

    // repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> 
        getAmContainerResourceRequestList();
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAmContainerResourceRequest(int index);
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    int getAmContainerResourceRequestCount();
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
        getAmContainerResourceRequestOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAmContainerResourceRequestOrBuilder(
        int index);

    // repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;
    /**
     * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto> 
        getApplicationTimeoutsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto getApplicationTimeouts(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
     */
    int getApplicationTimeoutsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProtoOrBuilder> 
        getApplicationTimeoutsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProtoOrBuilder getApplicationTimeoutsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationSubmissionContextProto}
   *
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////
   * //// From client_RM_Protocol /////////////////////////////////////////
   * //////////////////////////////////////////////////////////////////////
   * </pre>
   */
  public static final class ApplicationSubmissionContextProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationSubmissionContextProtoOrBuilder {
    // Use ApplicationSubmissionContextProto.newBuilder() to construct.
    private ApplicationSubmissionContextProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationSubmissionContextProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationSubmissionContextProto defaultInstance;
    public static ApplicationSubmissionContextProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationSubmissionContextProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationSubmissionContextProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              applicationName_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              queue_ = input.readBytes();
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = amContainerSpec_.toBuilder();
              }
              amContainerSpec_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(amContainerSpec_);
                amContainerSpec_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              cancelTokensWhenComplete_ = input.readBool();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              unmanagedAm_ = input.readBool();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              maxAppAttempts_ = input.readInt32();
              break;
            }
            case 74: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000100) == 0x00000100)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000100;
              break;
            }
            case 82: {
              bitField0_ |= 0x00000200;
              applicationType_ = input.readBytes();
              break;
            }
            case 88: {
              bitField0_ |= 0x00000400;
              keepContainersAcrossApplicationAttempts_ = input.readBool();
              break;
            }
            case 98: {
              if (!((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
                applicationTags_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000800;
              }
              applicationTags_.add(input.readBytes());
              break;
            }
            case 104: {
              bitField0_ |= 0x00000800;
              attemptFailuresValidityInterval_ = input.readInt64();
              break;
            }
            case 114: {
              org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00001000) == 0x00001000)) {
                subBuilder = logAggregationContext_.toBuilder();
              }
              logAggregationContext_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logAggregationContext_);
                logAggregationContext_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00001000;
              break;
            }
            case 122: {
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00002000) == 0x00002000)) {
                subBuilder = reservationId_.toBuilder();
              }
              reservationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationId_);
                reservationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00002000;
              break;
            }
            case 130: {
              bitField0_ |= 0x00004000;
              nodeLabelExpression_ = input.readBytes();
              break;
            }
            case 138: {
              if (!((mutable_bitField0_ & 0x00010000) == 0x00010000)) {
                amContainerResourceRequest_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto>();
                mutable_bitField0_ |= 0x00010000;
              }
              amContainerResourceRequest_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.PARSER, extensionRegistry));
              break;
            }
            case 146: {
              if (!((mutable_bitField0_ & 0x00020000) == 0x00020000)) {
                applicationTimeouts_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto>();
                mutable_bitField0_ |= 0x00020000;
              }
              applicationTimeouts_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
          applicationTags_ = new com.google.protobuf.UnmodifiableLazyStringList(applicationTags_);
        }
        if (((mutable_bitField0_ & 0x00010000) == 0x00010000)) {
          amContainerResourceRequest_ = java.util.Collections.unmodifiableList(amContainerResourceRequest_);
        }
        if (((mutable_bitField0_ & 0x00020000) == 0x00020000)) {
          applicationTimeouts_ = java.util.Collections.unmodifiableList(applicationTimeouts_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationSubmissionContextProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationSubmissionContextProto>() {
      public ApplicationSubmissionContextProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationSubmissionContextProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationSubmissionContextProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_;
    }

    // optional string application_name = 2 [default = "N/A"];
    public static final int APPLICATION_NAME_FIELD_NUMBER = 2;
    private java.lang.Object applicationName_;
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    public boolean hasApplicationName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    public java.lang.String getApplicationName() {
      java.lang.Object ref = applicationName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          applicationName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getApplicationNameBytes() {
      java.lang.Object ref = applicationName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        applicationName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string queue = 3 [default = "default"];
    public static final int QUEUE_FIELD_NUMBER = 3;
    private java.lang.Object queue_;
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    public boolean hasQueue() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    public java.lang.String getQueue() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    public com.google.protobuf.ByteString
        getQueueBytes() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queue_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.PriorityProto priority = 4;
    public static final int PRIORITY_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_;
    }

    // optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;
    public static final int AM_CONTAINER_SPEC_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto amContainerSpec_;
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    public boolean hasAmContainerSpec() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getAmContainerSpec() {
      return amContainerSpec_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getAmContainerSpecOrBuilder() {
      return amContainerSpec_;
    }

    // optional bool cancel_tokens_when_complete = 6 [default = true];
    public static final int CANCEL_TOKENS_WHEN_COMPLETE_FIELD_NUMBER = 6;
    private boolean cancelTokensWhenComplete_;
    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    public boolean hasCancelTokensWhenComplete() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    public boolean getCancelTokensWhenComplete() {
      return cancelTokensWhenComplete_;
    }

    // optional bool unmanaged_am = 7 [default = false];
    public static final int UNMANAGED_AM_FIELD_NUMBER = 7;
    private boolean unmanagedAm_;
    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    public boolean hasUnmanagedAm() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    public boolean getUnmanagedAm() {
      return unmanagedAm_;
    }

    // optional int32 maxAppAttempts = 8 [default = 0];
    public static final int MAXAPPATTEMPTS_FIELD_NUMBER = 8;
    private int maxAppAttempts_;
    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    public boolean hasMaxAppAttempts() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    public int getMaxAppAttempts() {
      return maxAppAttempts_;
    }

    // optional .hadoop.yarn.ResourceProto resource = 9;
    public static final int RESOURCE_FIELD_NUMBER = 9;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional string applicationType = 10 [default = "YARN"];
    public static final int APPLICATIONTYPE_FIELD_NUMBER = 10;
    private java.lang.Object applicationType_;
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    public boolean hasApplicationType() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    public java.lang.String getApplicationType() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          applicationType_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTypeBytes() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        applicationType_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional bool keep_containers_across_application_attempts = 11 [default = false];
    public static final int KEEP_CONTAINERS_ACROSS_APPLICATION_ATTEMPTS_FIELD_NUMBER = 11;
    private boolean keepContainersAcrossApplicationAttempts_;
    /**
     * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
     */
    public boolean hasKeepContainersAcrossApplicationAttempts() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    /**
     * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
     */
    public boolean getKeepContainersAcrossApplicationAttempts() {
      return keepContainersAcrossApplicationAttempts_;
    }

    // repeated string applicationTags = 12;
    public static final int APPLICATIONTAGS_FIELD_NUMBER = 12;
    private com.google.protobuf.LazyStringList applicationTags_;
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    public java.util.List<java.lang.String>
        getApplicationTagsList() {
      return applicationTags_;
    }
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    public int getApplicationTagsCount() {
      return applicationTags_.size();
    }
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    public java.lang.String getApplicationTags(int index) {
      return applicationTags_.get(index);
    }
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTagsBytes(int index) {
      return applicationTags_.getByteString(index);
    }

    // optional int64 attempt_failures_validity_interval = 13 [default = -1];
    public static final int ATTEMPT_FAILURES_VALIDITY_INTERVAL_FIELD_NUMBER = 13;
    private long attemptFailuresValidityInterval_;
    /**
     * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
     */
    public boolean hasAttemptFailuresValidityInterval() {
      return ((bitField0_ & 0x00000800) == 0x00000800);
    }
    /**
     * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
     */
    public long getAttemptFailuresValidityInterval() {
      return attemptFailuresValidityInterval_;
    }

    // optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;
    public static final int LOG_AGGREGATION_CONTEXT_FIELD_NUMBER = 14;
    private org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto logAggregationContext_;
    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    public boolean hasLogAggregationContext() {
      return ((bitField0_ & 0x00001000) == 0x00001000);
    }
    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto getLogAggregationContext() {
      return logAggregationContext_;
    }
    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder getLogAggregationContextOrBuilder() {
      return logAggregationContext_;
    }

    // optional .hadoop.yarn.ReservationIdProto reservation_id = 15;
    public static final int RESERVATION_ID_FIELD_NUMBER = 15;
    private org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_;
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    public boolean hasReservationId() {
      return ((bitField0_ & 0x00002000) == 0x00002000);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
      return reservationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
      return reservationId_;
    }

    // optional string node_label_expression = 16;
    public static final int NODE_LABEL_EXPRESSION_FIELD_NUMBER = 16;
    private java.lang.Object nodeLabelExpression_;
    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    public boolean hasNodeLabelExpression() {
      return ((bitField0_ & 0x00004000) == 0x00004000);
    }
    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    public java.lang.String getNodeLabelExpression() {
      java.lang.Object ref = nodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          nodeLabelExpression_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    public com.google.protobuf.ByteString
        getNodeLabelExpressionBytes() {
      java.lang.Object ref = nodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nodeLabelExpression_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;
    public static final int AM_CONTAINER_RESOURCE_REQUEST_FIELD_NUMBER = 17;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> amContainerResourceRequest_;
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> getAmContainerResourceRequestList() {
      return amContainerResourceRequest_;
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
        getAmContainerResourceRequestOrBuilderList() {
      return amContainerResourceRequest_;
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    public int getAmContainerResourceRequestCount() {
      return amContainerResourceRequest_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAmContainerResourceRequest(int index) {
      return amContainerResourceRequest_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAmContainerResourceRequestOrBuilder(
        int index) {
      return amContainerResourceRequest_.get(index);
    }

    // repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;
    public static final int APPLICATION_TIMEOUTS_FIELD_NUMBER = 18;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto> applicationTimeouts_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto> getApplicationTimeoutsList() {
      return applicationTimeouts_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProtoOrBuilder> 
        getApplicationTimeoutsOrBuilderList() {
      return applicationTimeouts_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
     */
    public int getApplicationTimeoutsCount() {
      return applicationTimeouts_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto getApplicationTimeouts(int index) {
      return applicationTimeouts_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProtoOrBuilder getApplicationTimeoutsOrBuilder(
        int index) {
      return applicationTimeouts_.get(index);
    }

    private void initFields() {
      applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      applicationName_ = "N/A";
      queue_ = "default";
      priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      amContainerSpec_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
      cancelTokensWhenComplete_ = true;
      unmanagedAm_ = false;
      maxAppAttempts_ = 0;
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      applicationType_ = "YARN";
      keepContainersAcrossApplicationAttempts_ = false;
      applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      attemptFailuresValidityInterval_ = -1L;
      logAggregationContext_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance();
      reservationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance();
      nodeLabelExpression_ = "";
      amContainerResourceRequest_ = java.util.Collections.emptyList();
      applicationTimeouts_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getApplicationNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getQueueBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, priority_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, amContainerSpec_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBool(6, cancelTokensWhenComplete_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeBool(7, unmanagedAm_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeInt32(8, maxAppAttempts_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeMessage(9, resource_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeBytes(10, getApplicationTypeBytes());
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeBool(11, keepContainersAcrossApplicationAttempts_);
      }
      for (int i = 0; i < applicationTags_.size(); i++) {
        output.writeBytes(12, applicationTags_.getByteString(i));
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        output.writeInt64(13, attemptFailuresValidityInterval_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        output.writeMessage(14, logAggregationContext_);
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        output.writeMessage(15, reservationId_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        output.writeBytes(16, getNodeLabelExpressionBytes());
      }
      for (int i = 0; i < amContainerResourceRequest_.size(); i++) {
        output.writeMessage(17, amContainerResourceRequest_.get(i));
      }
      for (int i = 0; i < applicationTimeouts_.size(); i++) {
        output.writeMessage(18, applicationTimeouts_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getApplicationNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getQueueBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, priority_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, amContainerSpec_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, cancelTokensWhenComplete_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, unmanagedAm_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(8, maxAppAttempts_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, resource_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(10, getApplicationTypeBytes());
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(11, keepContainersAcrossApplicationAttempts_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < applicationTags_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(applicationTags_.getByteString(i));
        }
        size += dataSize;
        size += 1 * getApplicationTagsList().size();
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(13, attemptFailuresValidityInterval_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, logAggregationContext_);
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(15, reservationId_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(16, getNodeLabelExpressionBytes());
      }
      for (int i = 0; i < amContainerResourceRequest_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(17, amContainerResourceRequest_.get(i));
      }
      for (int i = 0; i < applicationTimeouts_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(18, applicationTimeouts_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasApplicationName() == other.hasApplicationName());
      if (hasApplicationName()) {
        result = result && getApplicationName()
            .equals(other.getApplicationName());
      }
      result = result && (hasQueue() == other.hasQueue());
      if (hasQueue()) {
        result = result && getQueue()
            .equals(other.getQueue());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasAmContainerSpec() == other.hasAmContainerSpec());
      if (hasAmContainerSpec()) {
        result = result && getAmContainerSpec()
            .equals(other.getAmContainerSpec());
      }
      result = result && (hasCancelTokensWhenComplete() == other.hasCancelTokensWhenComplete());
      if (hasCancelTokensWhenComplete()) {
        result = result && (getCancelTokensWhenComplete()
            == other.getCancelTokensWhenComplete());
      }
      result = result && (hasUnmanagedAm() == other.hasUnmanagedAm());
      if (hasUnmanagedAm()) {
        result = result && (getUnmanagedAm()
            == other.getUnmanagedAm());
      }
      result = result && (hasMaxAppAttempts() == other.hasMaxAppAttempts());
      if (hasMaxAppAttempts()) {
        result = result && (getMaxAppAttempts()
            == other.getMaxAppAttempts());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasApplicationType() == other.hasApplicationType());
      if (hasApplicationType()) {
        result = result && getApplicationType()
            .equals(other.getApplicationType());
      }
      result = result && (hasKeepContainersAcrossApplicationAttempts() == other.hasKeepContainersAcrossApplicationAttempts());
      if (hasKeepContainersAcrossApplicationAttempts()) {
        result = result && (getKeepContainersAcrossApplicationAttempts()
            == other.getKeepContainersAcrossApplicationAttempts());
      }
      result = result && getApplicationTagsList()
          .equals(other.getApplicationTagsList());
      result = result && (hasAttemptFailuresValidityInterval() == other.hasAttemptFailuresValidityInterval());
      if (hasAttemptFailuresValidityInterval()) {
        result = result && (getAttemptFailuresValidityInterval()
            == other.getAttemptFailuresValidityInterval());
      }
      result = result && (hasLogAggregationContext() == other.hasLogAggregationContext());
      if (hasLogAggregationContext()) {
        result = result && getLogAggregationContext()
            .equals(other.getLogAggregationContext());
      }
      result = result && (hasReservationId() == other.hasReservationId());
      if (hasReservationId()) {
        result = result && getReservationId()
            .equals(other.getReservationId());
      }
      result = result && (hasNodeLabelExpression() == other.hasNodeLabelExpression());
      if (hasNodeLabelExpression()) {
        result = result && getNodeLabelExpression()
            .equals(other.getNodeLabelExpression());
      }
      result = result && getAmContainerResourceRequestList()
          .equals(other.getAmContainerResourceRequestList());
      result = result && getApplicationTimeoutsList()
          .equals(other.getApplicationTimeoutsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasApplicationName()) {
        hash = (37 * hash) + APPLICATION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationName().hashCode();
      }
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasAmContainerSpec()) {
        hash = (37 * hash) + AM_CONTAINER_SPEC_FIELD_NUMBER;
        hash = (53 * hash) + getAmContainerSpec().hashCode();
      }
      if (hasCancelTokensWhenComplete()) {
        hash = (37 * hash) + CANCEL_TOKENS_WHEN_COMPLETE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getCancelTokensWhenComplete());
      }
      if (hasUnmanagedAm()) {
        hash = (37 * hash) + UNMANAGED_AM_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getUnmanagedAm());
      }
      if (hasMaxAppAttempts()) {
        hash = (37 * hash) + MAXAPPATTEMPTS_FIELD_NUMBER;
        hash = (53 * hash) + getMaxAppAttempts();
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasApplicationType()) {
        hash = (37 * hash) + APPLICATIONTYPE_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationType().hashCode();
      }
      if (hasKeepContainersAcrossApplicationAttempts()) {
        hash = (37 * hash) + KEEP_CONTAINERS_ACROSS_APPLICATION_ATTEMPTS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getKeepContainersAcrossApplicationAttempts());
      }
      if (getApplicationTagsCount() > 0) {
        hash = (37 * hash) + APPLICATIONTAGS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationTagsList().hashCode();
      }
      if (hasAttemptFailuresValidityInterval()) {
        hash = (37 * hash) + ATTEMPT_FAILURES_VALIDITY_INTERVAL_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getAttemptFailuresValidityInterval());
      }
      if (hasLogAggregationContext()) {
        hash = (37 * hash) + LOG_AGGREGATION_CONTEXT_FIELD_NUMBER;
        hash = (53 * hash) + getLogAggregationContext().hashCode();
      }
      if (hasReservationId()) {
        hash = (37 * hash) + RESERVATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getReservationId().hashCode();
      }
      if (hasNodeLabelExpression()) {
        hash = (37 * hash) + NODE_LABEL_EXPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelExpression().hashCode();
      }
      if (getAmContainerResourceRequestCount() > 0) {
        hash = (37 * hash) + AM_CONTAINER_RESOURCE_REQUEST_FIELD_NUMBER;
        hash = (53 * hash) + getAmContainerResourceRequestList().hashCode();
      }
      if (getApplicationTimeoutsCount() > 0) {
        hash = (37 * hash) + APPLICATION_TIMEOUTS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationTimeoutsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationSubmissionContextProto}
     *
     * <pre>
     *&#47;/////////////////////////////////////////////////////////////////////
     * //// From client_RM_Protocol /////////////////////////////////////////
     * //////////////////////////////////////////////////////////////////////
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
          getPriorityFieldBuilder();
          getAmContainerSpecFieldBuilder();
          getResourceFieldBuilder();
          getLogAggregationContextFieldBuilder();
          getReservationIdFieldBuilder();
          getAmContainerResourceRequestFieldBuilder();
          getApplicationTimeoutsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        applicationName_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000002);
        queue_ = "default";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (amContainerSpecBuilder_ == null) {
          amContainerSpec_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
        } else {
          amContainerSpecBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        cancelTokensWhenComplete_ = true;
        bitField0_ = (bitField0_ & ~0x00000020);
        unmanagedAm_ = false;
        bitField0_ = (bitField0_ & ~0x00000040);
        maxAppAttempts_ = 0;
        bitField0_ = (bitField0_ & ~0x00000080);
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000100);
        applicationType_ = "YARN";
        bitField0_ = (bitField0_ & ~0x00000200);
        keepContainersAcrossApplicationAttempts_ = false;
        bitField0_ = (bitField0_ & ~0x00000400);
        applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000800);
        attemptFailuresValidityInterval_ = -1L;
        bitField0_ = (bitField0_ & ~0x00001000);
        if (logAggregationContextBuilder_ == null) {
          logAggregationContext_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance();
        } else {
          logAggregationContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        if (reservationIdBuilder_ == null) {
          reservationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance();
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00004000);
        nodeLabelExpression_ = "";
        bitField0_ = (bitField0_ & ~0x00008000);
        if (amContainerResourceRequestBuilder_ == null) {
          amContainerResourceRequest_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00010000);
        } else {
          amContainerResourceRequestBuilder_.clear();
        }
        if (applicationTimeoutsBuilder_ == null) {
          applicationTimeouts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00020000);
        } else {
          applicationTimeoutsBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.applicationName_ = applicationName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.queue_ = queue_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (amContainerSpecBuilder_ == null) {
          result.amContainerSpec_ = amContainerSpec_;
        } else {
          result.amContainerSpec_ = amContainerSpecBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.cancelTokensWhenComplete_ = cancelTokensWhenComplete_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.unmanagedAm_ = unmanagedAm_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.maxAppAttempts_ = maxAppAttempts_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.applicationType_ = applicationType_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000400;
        }
        result.keepContainersAcrossApplicationAttempts_ = keepContainersAcrossApplicationAttempts_;
        if (((bitField0_ & 0x00000800) == 0x00000800)) {
          applicationTags_ = new com.google.protobuf.UnmodifiableLazyStringList(
              applicationTags_);
          bitField0_ = (bitField0_ & ~0x00000800);
        }
        result.applicationTags_ = applicationTags_;
        if (((from_bitField0_ & 0x00001000) == 0x00001000)) {
          to_bitField0_ |= 0x00000800;
        }
        result.attemptFailuresValidityInterval_ = attemptFailuresValidityInterval_;
        if (((from_bitField0_ & 0x00002000) == 0x00002000)) {
          to_bitField0_ |= 0x00001000;
        }
        if (logAggregationContextBuilder_ == null) {
          result.logAggregationContext_ = logAggregationContext_;
        } else {
          result.logAggregationContext_ = logAggregationContextBuilder_.build();
        }
        if (((from_bitField0_ & 0x00004000) == 0x00004000)) {
          to_bitField0_ |= 0x00002000;
        }
        if (reservationIdBuilder_ == null) {
          result.reservationId_ = reservationId_;
        } else {
          result.reservationId_ = reservationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00008000) == 0x00008000)) {
          to_bitField0_ |= 0x00004000;
        }
        result.nodeLabelExpression_ = nodeLabelExpression_;
        if (amContainerResourceRequestBuilder_ == null) {
          if (((bitField0_ & 0x00010000) == 0x00010000)) {
            amContainerResourceRequest_ = java.util.Collections.unmodifiableList(amContainerResourceRequest_);
            bitField0_ = (bitField0_ & ~0x00010000);
          }
          result.amContainerResourceRequest_ = amContainerResourceRequest_;
        } else {
          result.amContainerResourceRequest_ = amContainerResourceRequestBuilder_.build();
        }
        if (applicationTimeoutsBuilder_ == null) {
          if (((bitField0_ & 0x00020000) == 0x00020000)) {
            applicationTimeouts_ = java.util.Collections.unmodifiableList(applicationTimeouts_);
            bitField0_ = (bitField0_ & ~0x00020000);
          }
          result.applicationTimeouts_ = applicationTimeouts_;
        } else {
          result.applicationTimeouts_ = applicationTimeoutsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasApplicationName()) {
          bitField0_ |= 0x00000002;
          applicationName_ = other.applicationName_;
          onChanged();
        }
        if (other.hasQueue()) {
          bitField0_ |= 0x00000004;
          queue_ = other.queue_;
          onChanged();
        }
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasAmContainerSpec()) {
          mergeAmContainerSpec(other.getAmContainerSpec());
        }
        if (other.hasCancelTokensWhenComplete()) {
          setCancelTokensWhenComplete(other.getCancelTokensWhenComplete());
        }
        if (other.hasUnmanagedAm()) {
          setUnmanagedAm(other.getUnmanagedAm());
        }
        if (other.hasMaxAppAttempts()) {
          setMaxAppAttempts(other.getMaxAppAttempts());
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasApplicationType()) {
          bitField0_ |= 0x00000200;
          applicationType_ = other.applicationType_;
          onChanged();
        }
        if (other.hasKeepContainersAcrossApplicationAttempts()) {
          setKeepContainersAcrossApplicationAttempts(other.getKeepContainersAcrossApplicationAttempts());
        }
        if (!other.applicationTags_.isEmpty()) {
          if (applicationTags_.isEmpty()) {
            applicationTags_ = other.applicationTags_;
            bitField0_ = (bitField0_ & ~0x00000800);
          } else {
            ensureApplicationTagsIsMutable();
            applicationTags_.addAll(other.applicationTags_);
          }
          onChanged();
        }
        if (other.hasAttemptFailuresValidityInterval()) {
          setAttemptFailuresValidityInterval(other.getAttemptFailuresValidityInterval());
        }
        if (other.hasLogAggregationContext()) {
          mergeLogAggregationContext(other.getLogAggregationContext());
        }
        if (other.hasReservationId()) {
          mergeReservationId(other.getReservationId());
        }
        if (other.hasNodeLabelExpression()) {
          bitField0_ |= 0x00008000;
          nodeLabelExpression_ = other.nodeLabelExpression_;
          onChanged();
        }
        if (amContainerResourceRequestBuilder_ == null) {
          if (!other.amContainerResourceRequest_.isEmpty()) {
            if (amContainerResourceRequest_.isEmpty()) {
              amContainerResourceRequest_ = other.amContainerResourceRequest_;
              bitField0_ = (bitField0_ & ~0x00010000);
            } else {
              ensureAmContainerResourceRequestIsMutable();
              amContainerResourceRequest_.addAll(other.amContainerResourceRequest_);
            }
            onChanged();
          }
        } else {
          if (!other.amContainerResourceRequest_.isEmpty()) {
            if (amContainerResourceRequestBuilder_.isEmpty()) {
              amContainerResourceRequestBuilder_.dispose();
              amContainerResourceRequestBuilder_ = null;
              amContainerResourceRequest_ = other.amContainerResourceRequest_;
              bitField0_ = (bitField0_ & ~0x00010000);
              amContainerResourceRequestBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAmContainerResourceRequestFieldBuilder() : null;
            } else {
              amContainerResourceRequestBuilder_.addAllMessages(other.amContainerResourceRequest_);
            }
          }
        }
        if (applicationTimeoutsBuilder_ == null) {
          if (!other.applicationTimeouts_.isEmpty()) {
            if (applicationTimeouts_.isEmpty()) {
              applicationTimeouts_ = other.applicationTimeouts_;
              bitField0_ = (bitField0_ & ~0x00020000);
            } else {
              ensureApplicationTimeoutsIsMutable();
              applicationTimeouts_.addAll(other.applicationTimeouts_);
            }
            onChanged();
          }
        } else {
          if (!other.applicationTimeouts_.isEmpty()) {
            if (applicationTimeoutsBuilder_.isEmpty()) {
              applicationTimeoutsBuilder_.dispose();
              applicationTimeoutsBuilder_ = null;
              applicationTimeouts_ = other.applicationTimeouts_;
              bitField0_ = (bitField0_ & ~0x00020000);
              applicationTimeoutsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getApplicationTimeoutsFieldBuilder() : null;
            } else {
              applicationTimeoutsBuilder_.addAllMessages(other.applicationTimeouts_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  applicationId_,
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      // optional string application_name = 2 [default = "N/A"];
      private java.lang.Object applicationName_ = "N/A";
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public boolean hasApplicationName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public java.lang.String getApplicationName() {
        java.lang.Object ref = applicationName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          applicationName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getApplicationNameBytes() {
        java.lang.Object ref = applicationName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          applicationName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public Builder setApplicationName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        applicationName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public Builder clearApplicationName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        applicationName_ = getDefaultInstance().getApplicationName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public Builder setApplicationNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        applicationName_ = value;
        onChanged();
        return this;
      }

      // optional string queue = 3 [default = "default"];
      private java.lang.Object queue_ = "default";
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public boolean hasQueue() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public java.lang.String getQueue() {
        java.lang.Object ref = queue_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          queue_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public com.google.protobuf.ByteString
          getQueueBytes() {
        java.lang.Object ref = queue_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queue_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public Builder setQueue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public Builder clearQueue() {
        bitField0_ = (bitField0_ & ~0x00000004);
        queue_ = getDefaultInstance().getQueue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public Builder setQueueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.PriorityProto priority = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  priority_,
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      // optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto amContainerSpec_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder> amContainerSpecBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public boolean hasAmContainerSpec() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getAmContainerSpec() {
        if (amContainerSpecBuilder_ == null) {
          return amContainerSpec_;
        } else {
          return amContainerSpecBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder setAmContainerSpec(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto value) {
        if (amContainerSpecBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          amContainerSpec_ = value;
          onChanged();
        } else {
          amContainerSpecBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder setAmContainerSpec(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder builderForValue) {
        if (amContainerSpecBuilder_ == null) {
          amContainerSpec_ = builderForValue.build();
          onChanged();
        } else {
          amContainerSpecBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder mergeAmContainerSpec(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto value) {
        if (amContainerSpecBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              amContainerSpec_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance()) {
            amContainerSpec_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.newBuilder(amContainerSpec_).mergeFrom(value).buildPartial();
          } else {
            amContainerSpec_ = value;
          }
          onChanged();
        } else {
          amContainerSpecBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder clearAmContainerSpec() {
        if (amContainerSpecBuilder_ == null) {
          amContainerSpec_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
          onChanged();
        } else {
          amContainerSpecBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder getAmContainerSpecBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getAmContainerSpecFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getAmContainerSpecOrBuilder() {
        if (amContainerSpecBuilder_ != null) {
          return amContainerSpecBuilder_.getMessageOrBuilder();
        } else {
          return amContainerSpec_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder> 
          getAmContainerSpecFieldBuilder() {
        if (amContainerSpecBuilder_ == null) {
          amContainerSpecBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder>(
                  amContainerSpec_,
                  getParentForChildren(),
                  isClean());
          amContainerSpec_ = null;
        }
        return amContainerSpecBuilder_;
      }

      // optional bool cancel_tokens_when_complete = 6 [default = true];
      private boolean cancelTokensWhenComplete_ = true;
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public boolean hasCancelTokensWhenComplete() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public boolean getCancelTokensWhenComplete() {
        return cancelTokensWhenComplete_;
      }
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public Builder setCancelTokensWhenComplete(boolean value) {
        bitField0_ |= 0x00000020;
        cancelTokensWhenComplete_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public Builder clearCancelTokensWhenComplete() {
        bitField0_ = (bitField0_ & ~0x00000020);
        cancelTokensWhenComplete_ = true;
        onChanged();
        return this;
      }

      // optional bool unmanaged_am = 7 [default = false];
      private boolean unmanagedAm_ ;
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public boolean hasUnmanagedAm() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public boolean getUnmanagedAm() {
        return unmanagedAm_;
      }
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public Builder setUnmanagedAm(boolean value) {
        bitField0_ |= 0x00000040;
        unmanagedAm_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public Builder clearUnmanagedAm() {
        bitField0_ = (bitField0_ & ~0x00000040);
        unmanagedAm_ = false;
        onChanged();
        return this;
      }

      // optional int32 maxAppAttempts = 8 [default = 0];
      private int maxAppAttempts_ ;
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public boolean hasMaxAppAttempts() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public int getMaxAppAttempts() {
        return maxAppAttempts_;
      }
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public Builder setMaxAppAttempts(int value) {
        bitField0_ |= 0x00000080;
        maxAppAttempts_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public Builder clearMaxAppAttempts() {
        bitField0_ = (bitField0_ & ~0x00000080);
        maxAppAttempts_ = 0;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto resource = 9;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000100) == 0x00000100) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000100;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional string applicationType = 10 [default = "YARN"];
      private java.lang.Object applicationType_ = "YARN";
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public boolean hasApplicationType() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public java.lang.String getApplicationType() {
        java.lang.Object ref = applicationType_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          applicationType_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTypeBytes() {
        java.lang.Object ref = applicationType_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          applicationType_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public Builder setApplicationType(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        applicationType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public Builder clearApplicationType() {
        bitField0_ = (bitField0_ & ~0x00000200);
        applicationType_ = getDefaultInstance().getApplicationType();
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public Builder setApplicationTypeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        applicationType_ = value;
        onChanged();
        return this;
      }

      // optional bool keep_containers_across_application_attempts = 11 [default = false];
      private boolean keepContainersAcrossApplicationAttempts_ ;
      /**
       * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
       */
      public boolean hasKeepContainersAcrossApplicationAttempts() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
       */
      public boolean getKeepContainersAcrossApplicationAttempts() {
        return keepContainersAcrossApplicationAttempts_;
      }
      /**
       * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
       */
      public Builder setKeepContainersAcrossApplicationAttempts(boolean value) {
        bitField0_ |= 0x00000400;
        keepContainersAcrossApplicationAttempts_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
       */
      public Builder clearKeepContainersAcrossApplicationAttempts() {
        bitField0_ = (bitField0_ & ~0x00000400);
        keepContainersAcrossApplicationAttempts_ = false;
        onChanged();
        return this;
      }

      // repeated string applicationTags = 12;
      private com.google.protobuf.LazyStringList applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureApplicationTagsIsMutable() {
        if (!((bitField0_ & 0x00000800) == 0x00000800)) {
          applicationTags_ = new com.google.protobuf.LazyStringArrayList(applicationTags_);
          bitField0_ |= 0x00000800;
         }
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public java.util.List<java.lang.String>
          getApplicationTagsList() {
        return java.util.Collections.unmodifiableList(applicationTags_);
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public int getApplicationTagsCount() {
        return applicationTags_.size();
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public java.lang.String getApplicationTags(int index) {
        return applicationTags_.get(index);
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTagsBytes(int index) {
        return applicationTags_.getByteString(index);
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public Builder setApplicationTags(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public Builder addApplicationTags(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public Builder addAllApplicationTags(
          java.lang.Iterable<java.lang.String> values) {
        ensureApplicationTagsIsMutable();
        super.addAll(values, applicationTags_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public Builder clearApplicationTags() {
        applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000800);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public Builder addApplicationTagsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.add(value);
        onChanged();
        return this;
      }

      // optional int64 attempt_failures_validity_interval = 13 [default = -1];
      private long attemptFailuresValidityInterval_ = -1L;
      /**
       * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
       */
      public boolean hasAttemptFailuresValidityInterval() {
        return ((bitField0_ & 0x00001000) == 0x00001000);
      }
      /**
       * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
       */
      public long getAttemptFailuresValidityInterval() {
        return attemptFailuresValidityInterval_;
      }
      /**
       * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
       */
      public Builder setAttemptFailuresValidityInterval(long value) {
        bitField0_ |= 0x00001000;
        attemptFailuresValidityInterval_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
       */
      public Builder clearAttemptFailuresValidityInterval() {
        bitField0_ = (bitField0_ & ~0x00001000);
        attemptFailuresValidityInterval_ = -1L;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;
      private org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto logAggregationContext_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder> logAggregationContextBuilder_;
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public boolean hasLogAggregationContext() {
        return ((bitField0_ & 0x00002000) == 0x00002000);
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto getLogAggregationContext() {
        if (logAggregationContextBuilder_ == null) {
          return logAggregationContext_;
        } else {
          return logAggregationContextBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public Builder setLogAggregationContext(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto value) {
        if (logAggregationContextBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logAggregationContext_ = value;
          onChanged();
        } else {
          logAggregationContextBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public Builder setLogAggregationContext(
          org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder builderForValue) {
        if (logAggregationContextBuilder_ == null) {
          logAggregationContext_ = builderForValue.build();
          onChanged();
        } else {
          logAggregationContextBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public Builder mergeLogAggregationContext(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto value) {
        if (logAggregationContextBuilder_ == null) {
          if (((bitField0_ & 0x00002000) == 0x00002000) &&
              logAggregationContext_ != org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance()) {
            logAggregationContext_ =
              org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.newBuilder(logAggregationContext_).mergeFrom(value).buildPartial();
          } else {
            logAggregationContext_ = value;
          }
          onChanged();
        } else {
          logAggregationContextBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public Builder clearLogAggregationContext() {
        if (logAggregationContextBuilder_ == null) {
          logAggregationContext_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance();
          onChanged();
        } else {
          logAggregationContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder getLogAggregationContextBuilder() {
        bitField0_ |= 0x00002000;
        onChanged();
        return getLogAggregationContextFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder getLogAggregationContextOrBuilder() {
        if (logAggregationContextBuilder_ != null) {
          return logAggregationContextBuilder_.getMessageOrBuilder();
        } else {
          return logAggregationContext_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder> 
          getLogAggregationContextFieldBuilder() {
        if (logAggregationContextBuilder_ == null) {
          logAggregationContextBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder>(
                  logAggregationContext_,
                  getParentForChildren(),
                  isClean());
          logAggregationContext_ = null;
        }
        return logAggregationContextBuilder_;
      }

      // optional .hadoop.yarn.ReservationIdProto reservation_id = 15;
      private org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> reservationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public boolean hasReservationId() {
        return ((bitField0_ & 0x00004000) == 0x00004000);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
        if (reservationIdBuilder_ == null) {
          return reservationId_;
        } else {
          return reservationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public Builder setReservationId(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationId_ = value;
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public Builder setReservationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder builderForValue) {
        if (reservationIdBuilder_ == null) {
          reservationId_ = builderForValue.build();
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public Builder mergeReservationId(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (((bitField0_ & 0x00004000) == 0x00004000) &&
              reservationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance()) {
            reservationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.newBuilder(reservationId_).mergeFrom(value).buildPartial();
          } else {
            reservationId_ = value;
          }
          onChanged();
        } else {
          reservationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public Builder clearReservationId() {
        if (reservationIdBuilder_ == null) {
          reservationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance();
          onChanged();
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00004000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder getReservationIdBuilder() {
        bitField0_ |= 0x00004000;
        onChanged();
        return getReservationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
        if (reservationIdBuilder_ != null) {
          return reservationIdBuilder_.getMessageOrBuilder();
        } else {
          return reservationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> 
          getReservationIdFieldBuilder() {
        if (reservationIdBuilder_ == null) {
          reservationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder>(
                  reservationId_,
                  getParentForChildren(),
                  isClean());
          reservationId_ = null;
        }
        return reservationIdBuilder_;
      }

      // optional string node_label_expression = 16;
      private java.lang.Object nodeLabelExpression_ = "";
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public boolean hasNodeLabelExpression() {
        return ((bitField0_ & 0x00008000) == 0x00008000);
      }
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public java.lang.String getNodeLabelExpression() {
        java.lang.Object ref = nodeLabelExpression_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          nodeLabelExpression_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public com.google.protobuf.ByteString
          getNodeLabelExpressionBytes() {
        java.lang.Object ref = nodeLabelExpression_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nodeLabelExpression_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public Builder setNodeLabelExpression(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00008000;
        nodeLabelExpression_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public Builder clearNodeLabelExpression() {
        bitField0_ = (bitField0_ & ~0x00008000);
        nodeLabelExpression_ = getDefaultInstance().getNodeLabelExpression();
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public Builder setNodeLabelExpressionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00008000;
        nodeLabelExpression_ = value;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> amContainerResourceRequest_ =
        java.util.Collections.emptyList();
      private void ensureAmContainerResourceRequestIsMutable() {
        if (!((bitField0_ & 0x00010000) == 0x00010000)) {
          amContainerResourceRequest_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto>(amContainerResourceRequest_);
          bitField0_ |= 0x00010000;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> amContainerResourceRequestBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> getAmContainerResourceRequestList() {
        if (amContainerResourceRequestBuilder_ == null) {
          return java.util.Collections.unmodifiableList(amContainerResourceRequest_);
        } else {
          return amContainerResourceRequestBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public int getAmContainerResourceRequestCount() {
        if (amContainerResourceRequestBuilder_ == null) {
          return amContainerResourceRequest_.size();
        } else {
          return amContainerResourceRequestBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAmContainerResourceRequest(int index) {
        if (amContainerResourceRequestBuilder_ == null) {
          return amContainerResourceRequest_.get(index);
        } else {
          return amContainerResourceRequestBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder setAmContainerResourceRequest(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (amContainerResourceRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAmContainerResourceRequestIsMutable();
          amContainerResourceRequest_.set(index, value);
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder setAmContainerResourceRequest(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (amContainerResourceRequestBuilder_ == null) {
          ensureAmContainerResourceRequestIsMutable();
          amContainerResourceRequest_.set(index, builderForValue.build());
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder addAmContainerResourceRequest(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (amContainerResourceRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAmContainerResourceRequestIsMutable();
          amContainerResourceRequest_.add(value);
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder addAmContainerResourceRequest(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (amContainerResourceRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAmContainerResourceRequestIsMutable();
          amContainerResourceRequest_.add(index, value);
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder addAmContainerResourceRequest(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (amContainerResourceRequestBuilder_ == null) {
          ensureAmContainerResourceRequestIsMutable();
          amContainerResourceRequest_.add(builderForValue.build());
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder addAmContainerResourceRequest(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (amContainerResourceRequestBuilder_ == null) {
          ensureAmContainerResourceRequestIsMutable();
          amContainerResourceRequest_.add(index, builderForValue.build());
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder addAllAmContainerResourceRequest(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> values) {
        if (amContainerResourceRequestBuilder_ == null) {
          ensureAmContainerResourceRequestIsMutable();
          super.addAll(values, amContainerResourceRequest_);
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder clearAmContainerResourceRequest() {
        if (amContainerResourceRequestBuilder_ == null) {
          amContainerResourceRequest_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00010000);
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder removeAmContainerResourceRequest(int index) {
        if (amContainerResourceRequestBuilder_ == null) {
          ensureAmContainerResourceRequestIsMutable();
          amContainerResourceRequest_.remove(index);
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder getAmContainerResourceRequestBuilder(
          int index) {
        return getAmContainerResourceRequestFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAmContainerResourceRequestOrBuilder(
          int index) {
        if (amContainerResourceRequestBuilder_ == null) {
          return amContainerResourceRequest_.get(index);  } else {
          return amContainerResourceRequestBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
           getAmContainerResourceRequestOrBuilderList() {
        if (amContainerResourceRequestBuilder_ != null) {
          return amContainerResourceRequestBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(amContainerResourceRequest_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder addAmContainerResourceRequestBuilder() {
        return getAmContainerResourceRequestFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder addAmContainerResourceRequestBuilder(
          int index) {
        return getAmContainerResourceRequestFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder> 
           getAmContainerResourceRequestBuilderList() {
        return getAmContainerResourceRequestFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
          getAmContainerResourceRequestFieldBuilder() {
        if (amContainerResourceRequestBuilder_ == null) {
          amContainerResourceRequestBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder>(
                  amContainerResourceRequest_,
                  ((bitField0_ & 0x00010000) == 0x00010000),
                  getParentForChildren(),
                  isClean());
          amContainerResourceRequest_ = null;
        }
        return amContainerResourceRequestBuilder_;
      }

      // repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto> applicationTimeouts_ =
        java.util.Collections.emptyList();
      private void ensureApplicationTimeoutsIsMutable() {
        if (!((bitField0_ & 0x00020000) == 0x00020000)) {
          applicationTimeouts_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto>(applicationTimeouts_);
          bitField0_ |= 0x00020000;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProtoOrBuilder> applicationTimeoutsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto> getApplicationTimeoutsList() {
        if (applicationTimeoutsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applicationTimeouts_);
        } else {
          return applicationTimeoutsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public int getApplicationTimeoutsCount() {
        if (applicationTimeoutsBuilder_ == null) {
          return applicationTimeouts_.size();
        } else {
          return applicationTimeoutsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto getApplicationTimeouts(int index) {
        if (applicationTimeoutsBuilder_ == null) {
          return applicationTimeouts_.get(index);
        } else {
          return applicationTimeoutsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public Builder setApplicationTimeouts(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto value) {
        if (applicationTimeoutsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationTimeoutsIsMutable();
          applicationTimeouts_.set(index, value);
          onChanged();
        } else {
          applicationTimeoutsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public Builder setApplicationTimeouts(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder builderForValue) {
        if (applicationTimeoutsBuilder_ == null) {
          ensureApplicationTimeoutsIsMutable();
          applicationTimeouts_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationTimeoutsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public Builder addApplicationTimeouts(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto value) {
        if (applicationTimeoutsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationTimeoutsIsMutable();
          applicationTimeouts_.add(value);
          onChanged();
        } else {
          applicationTimeoutsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public Builder addApplicationTimeouts(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto value) {
        if (applicationTimeoutsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationTimeoutsIsMutable();
          applicationTimeouts_.add(index, value);
          onChanged();
        } else {
          applicationTimeoutsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public Builder addApplicationTimeouts(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder builderForValue) {
        if (applicationTimeoutsBuilder_ == null) {
          ensureApplicationTimeoutsIsMutable();
          applicationTimeouts_.add(builderForValue.build());
          onChanged();
        } else {
          applicationTimeoutsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public Builder addApplicationTimeouts(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder builderForValue) {
        if (applicationTimeoutsBuilder_ == null) {
          ensureApplicationTimeoutsIsMutable();
          applicationTimeouts_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationTimeoutsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public Builder addAllApplicationTimeouts(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto> values) {
        if (applicationTimeoutsBuilder_ == null) {
          ensureApplicationTimeoutsIsMutable();
          super.addAll(values, applicationTimeouts_);
          onChanged();
        } else {
          applicationTimeoutsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public Builder clearApplicationTimeouts() {
        if (applicationTimeoutsBuilder_ == null) {
          applicationTimeouts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00020000);
          onChanged();
        } else {
          applicationTimeoutsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public Builder removeApplicationTimeouts(int index) {
        if (applicationTimeoutsBuilder_ == null) {
          ensureApplicationTimeoutsIsMutable();
          applicationTimeouts_.remove(index);
          onChanged();
        } else {
          applicationTimeoutsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder getApplicationTimeoutsBuilder(
          int index) {
        return getApplicationTimeoutsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProtoOrBuilder getApplicationTimeoutsOrBuilder(
          int index) {
        if (applicationTimeoutsBuilder_ == null) {
          return applicationTimeouts_.get(index);  } else {
          return applicationTimeoutsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProtoOrBuilder> 
           getApplicationTimeoutsOrBuilderList() {
        if (applicationTimeoutsBuilder_ != null) {
          return applicationTimeoutsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applicationTimeouts_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder addApplicationTimeoutsBuilder() {
        return getApplicationTimeoutsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder addApplicationTimeoutsBuilder(
          int index) {
        return getApplicationTimeoutsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationTimeoutMapProto application_timeouts = 18;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder> 
           getApplicationTimeoutsBuilderList() {
        return getApplicationTimeoutsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProtoOrBuilder> 
          getApplicationTimeoutsFieldBuilder() {
        if (applicationTimeoutsBuilder_ == null) {
          applicationTimeoutsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProtoOrBuilder>(
                  applicationTimeouts_,
                  ((bitField0_ & 0x00020000) == 0x00020000),
                  getParentForChildren(),
                  isClean());
          applicationTimeouts_ = null;
        }
        return applicationTimeoutsBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationSubmissionContextProto)
    }

    static {
      defaultInstance = new ApplicationSubmissionContextProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationSubmissionContextProto)
  }

  public interface ApplicationTimeoutMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    boolean hasApplicationTimeoutType();
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType();

    // optional int64 timeout = 2;
    /**
     * <code>optional int64 timeout = 2;</code>
     */
    boolean hasTimeout();
    /**
     * <code>optional int64 timeout = 2;</code>
     */
    long getTimeout();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationTimeoutMapProto}
   */
  public static final class ApplicationTimeoutMapProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationTimeoutMapProtoOrBuilder {
    // Use ApplicationTimeoutMapProto.newBuilder() to construct.
    private ApplicationTimeoutMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationTimeoutMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationTimeoutMapProto defaultInstance;
    public static ApplicationTimeoutMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationTimeoutMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationTimeoutMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                applicationTimeoutType_ = value;
              }
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              timeout_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationTimeoutMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationTimeoutMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationTimeoutMapProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationTimeoutMapProto>() {
      public ApplicationTimeoutMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationTimeoutMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationTimeoutMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
    public static final int APPLICATION_TIMEOUT_TYPE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto applicationTimeoutType_;
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    public boolean hasApplicationTimeoutType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType() {
      return applicationTimeoutType_;
    }

    // optional int64 timeout = 2;
    public static final int TIMEOUT_FIELD_NUMBER = 2;
    private long timeout_;
    /**
     * <code>optional int64 timeout = 2;</code>
     */
    public boolean hasTimeout() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 timeout = 2;</code>
     */
    public long getTimeout() {
      return timeout_;
    }

    private void initFields() {
      applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
      timeout_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, applicationTimeoutType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, timeout_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, applicationTimeoutType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, timeout_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto) obj;

      boolean result = true;
      result = result && (hasApplicationTimeoutType() == other.hasApplicationTimeoutType());
      if (hasApplicationTimeoutType()) {
        result = result &&
            (getApplicationTimeoutType() == other.getApplicationTimeoutType());
      }
      result = result && (hasTimeout() == other.hasTimeout());
      if (hasTimeout()) {
        result = result && (getTimeout()
            == other.getTimeout());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationTimeoutType()) {
        hash = (37 * hash) + APPLICATION_TIMEOUT_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getApplicationTimeoutType());
      }
      if (hasTimeout()) {
        hash = (37 * hash) + TIMEOUT_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getTimeout());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationTimeoutMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationTimeoutMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationTimeoutMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
        bitField0_ = (bitField0_ & ~0x00000001);
        timeout_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationTimeoutMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.applicationTimeoutType_ = applicationTimeoutType_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.timeout_ = timeout_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto.getDefaultInstance()) return this;
        if (other.hasApplicationTimeoutType()) {
          setApplicationTimeoutType(other.getApplicationTimeoutType());
        }
        if (other.hasTimeout()) {
          setTimeout(other.getTimeout());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public boolean hasApplicationTimeoutType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType() {
        return applicationTimeoutType_;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public Builder setApplicationTimeoutType(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        applicationTimeoutType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public Builder clearApplicationTimeoutType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
        onChanged();
        return this;
      }

      // optional int64 timeout = 2;
      private long timeout_ ;
      /**
       * <code>optional int64 timeout = 2;</code>
       */
      public boolean hasTimeout() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 timeout = 2;</code>
       */
      public long getTimeout() {
        return timeout_;
      }
      /**
       * <code>optional int64 timeout = 2;</code>
       */
      public Builder setTimeout(long value) {
        bitField0_ |= 0x00000002;
        timeout_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 timeout = 2;</code>
       */
      public Builder clearTimeout() {
        bitField0_ = (bitField0_ & ~0x00000002);
        timeout_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationTimeoutMapProto)
    }

    static {
      defaultInstance = new ApplicationTimeoutMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationTimeoutMapProto)
  }

  public interface ApplicationUpdateTimeoutMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    boolean hasApplicationTimeoutType();
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType();

    // optional string expire_time = 2;
    /**
     * <code>optional string expire_time = 2;</code>
     */
    boolean hasExpireTime();
    /**
     * <code>optional string expire_time = 2;</code>
     */
    java.lang.String getExpireTime();
    /**
     * <code>optional string expire_time = 2;</code>
     */
    com.google.protobuf.ByteString
        getExpireTimeBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationUpdateTimeoutMapProto}
   */
  public static final class ApplicationUpdateTimeoutMapProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationUpdateTimeoutMapProtoOrBuilder {
    // Use ApplicationUpdateTimeoutMapProto.newBuilder() to construct.
    private ApplicationUpdateTimeoutMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationUpdateTimeoutMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationUpdateTimeoutMapProto defaultInstance;
    public static ApplicationUpdateTimeoutMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationUpdateTimeoutMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationUpdateTimeoutMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                applicationTimeoutType_ = value;
              }
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              expireTime_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationUpdateTimeoutMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationUpdateTimeoutMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationUpdateTimeoutMapProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationUpdateTimeoutMapProto>() {
      public ApplicationUpdateTimeoutMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationUpdateTimeoutMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationUpdateTimeoutMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
    public static final int APPLICATION_TIMEOUT_TYPE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto applicationTimeoutType_;
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    public boolean hasApplicationTimeoutType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType() {
      return applicationTimeoutType_;
    }

    // optional string expire_time = 2;
    public static final int EXPIRE_TIME_FIELD_NUMBER = 2;
    private java.lang.Object expireTime_;
    /**
     * <code>optional string expire_time = 2;</code>
     */
    public boolean hasExpireTime() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string expire_time = 2;</code>
     */
    public java.lang.String getExpireTime() {
      java.lang.Object ref = expireTime_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          expireTime_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string expire_time = 2;</code>
     */
    public com.google.protobuf.ByteString
        getExpireTimeBytes() {
      java.lang.Object ref = expireTime_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        expireTime_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
      expireTime_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, applicationTimeoutType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getExpireTimeBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, applicationTimeoutType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getExpireTimeBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto) obj;

      boolean result = true;
      result = result && (hasApplicationTimeoutType() == other.hasApplicationTimeoutType());
      if (hasApplicationTimeoutType()) {
        result = result &&
            (getApplicationTimeoutType() == other.getApplicationTimeoutType());
      }
      result = result && (hasExpireTime() == other.hasExpireTime());
      if (hasExpireTime()) {
        result = result && getExpireTime()
            .equals(other.getExpireTime());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationTimeoutType()) {
        hash = (37 * hash) + APPLICATION_TIMEOUT_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getApplicationTimeoutType());
      }
      if (hasExpireTime()) {
        hash = (37 * hash) + EXPIRE_TIME_FIELD_NUMBER;
        hash = (53 * hash) + getExpireTime().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationUpdateTimeoutMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationUpdateTimeoutMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationUpdateTimeoutMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
        bitField0_ = (bitField0_ & ~0x00000001);
        expireTime_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationUpdateTimeoutMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.applicationTimeoutType_ = applicationTimeoutType_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.expireTime_ = expireTime_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto.getDefaultInstance()) return this;
        if (other.hasApplicationTimeoutType()) {
          setApplicationTimeoutType(other.getApplicationTimeoutType());
        }
        if (other.hasExpireTime()) {
          bitField0_ |= 0x00000002;
          expireTime_ = other.expireTime_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationUpdateTimeoutMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public boolean hasApplicationTimeoutType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto getApplicationTimeoutType() {
        return applicationTimeoutType_;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public Builder setApplicationTimeoutType(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        applicationTimeoutType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationTimeoutTypeProto application_timeout_type = 1;</code>
       */
      public Builder clearApplicationTimeoutType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        applicationTimeoutType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationTimeoutTypeProto.APP_TIMEOUT_LIFETIME;
        onChanged();
        return this;
      }

      // optional string expire_time = 2;
      private java.lang.Object expireTime_ = "";
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public boolean hasExpireTime() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public java.lang.String getExpireTime() {
        java.lang.Object ref = expireTime_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          expireTime_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public com.google.protobuf.ByteString
          getExpireTimeBytes() {
        java.lang.Object ref = expireTime_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          expireTime_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public Builder setExpireTime(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        expireTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public Builder clearExpireTime() {
        bitField0_ = (bitField0_ & ~0x00000002);
        expireTime_ = getDefaultInstance().getExpireTime();
        onChanged();
        return this;
      }
      /**
       * <code>optional string expire_time = 2;</code>
       */
      public Builder setExpireTimeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        expireTime_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationUpdateTimeoutMapProto)
    }

    static {
      defaultInstance = new ApplicationUpdateTimeoutMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationUpdateTimeoutMapProto)
  }

  public interface LogAggregationContextProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string include_pattern = 1 [default = ".*"];
    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    boolean hasIncludePattern();
    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    java.lang.String getIncludePattern();
    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    com.google.protobuf.ByteString
        getIncludePatternBytes();

    // optional string exclude_pattern = 2 [default = ""];
    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    boolean hasExcludePattern();
    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    java.lang.String getExcludePattern();
    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    com.google.protobuf.ByteString
        getExcludePatternBytes();

    // optional string rolled_logs_include_pattern = 3 [default = ""];
    /**
     * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
     */
    boolean hasRolledLogsIncludePattern();
    /**
     * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
     */
    java.lang.String getRolledLogsIncludePattern();
    /**
     * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
     */
    com.google.protobuf.ByteString
        getRolledLogsIncludePatternBytes();

    // optional string rolled_logs_exclude_pattern = 4 [default = ".*"];
    /**
     * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
     */
    boolean hasRolledLogsExcludePattern();
    /**
     * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
     */
    java.lang.String getRolledLogsExcludePattern();
    /**
     * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
     */
    com.google.protobuf.ByteString
        getRolledLogsExcludePatternBytes();

    // optional string log_aggregation_policy_class_name = 5;
    /**
     * <code>optional string log_aggregation_policy_class_name = 5;</code>
     */
    boolean hasLogAggregationPolicyClassName();
    /**
     * <code>optional string log_aggregation_policy_class_name = 5;</code>
     */
    java.lang.String getLogAggregationPolicyClassName();
    /**
     * <code>optional string log_aggregation_policy_class_name = 5;</code>
     */
    com.google.protobuf.ByteString
        getLogAggregationPolicyClassNameBytes();

    // optional string log_aggregation_policy_parameters = 6;
    /**
     * <code>optional string log_aggregation_policy_parameters = 6;</code>
     */
    boolean hasLogAggregationPolicyParameters();
    /**
     * <code>optional string log_aggregation_policy_parameters = 6;</code>
     */
    java.lang.String getLogAggregationPolicyParameters();
    /**
     * <code>optional string log_aggregation_policy_parameters = 6;</code>
     */
    com.google.protobuf.ByteString
        getLogAggregationPolicyParametersBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.LogAggregationContextProto}
   */
  public static final class LogAggregationContextProto extends
      com.google.protobuf.GeneratedMessage
      implements LogAggregationContextProtoOrBuilder {
    // Use LogAggregationContextProto.newBuilder() to construct.
    private LogAggregationContextProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private LogAggregationContextProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final LogAggregationContextProto defaultInstance;
    public static LogAggregationContextProto getDefaultInstance() {
      return defaultInstance;
    }

    public LogAggregationContextProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private LogAggregationContextProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              includePattern_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              excludePattern_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              rolledLogsIncludePattern_ = input.readBytes();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              rolledLogsExcludePattern_ = input.readBytes();
              break;
            }
            case 42: {
              bitField0_ |= 0x00000010;
              logAggregationPolicyClassName_ = input.readBytes();
              break;
            }
            case 50: {
              bitField0_ |= 0x00000020;
              logAggregationPolicyParameters_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LogAggregationContextProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LogAggregationContextProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder.class);
    }

    public static com.google.protobuf.Parser<LogAggregationContextProto> PARSER =
        new com.google.protobuf.AbstractParser<LogAggregationContextProto>() {
      public LogAggregationContextProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new LogAggregationContextProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<LogAggregationContextProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string include_pattern = 1 [default = ".*"];
    public static final int INCLUDE_PATTERN_FIELD_NUMBER = 1;
    private java.lang.Object includePattern_;
    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    public boolean hasIncludePattern() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    public java.lang.String getIncludePattern() {
      java.lang.Object ref = includePattern_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          includePattern_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    public com.google.protobuf.ByteString
        getIncludePatternBytes() {
      java.lang.Object ref = includePattern_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        includePattern_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string exclude_pattern = 2 [default = ""];
    public static final int EXCLUDE_PATTERN_FIELD_NUMBER = 2;
    private java.lang.Object excludePattern_;
    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    public boolean hasExcludePattern() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    public java.lang.String getExcludePattern() {
      java.lang.Object ref = excludePattern_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          excludePattern_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    public com.google.protobuf.ByteString
        getExcludePatternBytes() {
      java.lang.Object ref = excludePattern_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        excludePattern_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string rolled_logs_include_pattern = 3 [default = ""];
    public static final int ROLLED_LOGS_INCLUDE_PATTERN_FIELD_NUMBER = 3;
    private java.lang.Object rolledLogsIncludePattern_;
    /**
     * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
     */
    public boolean hasRolledLogsIncludePattern() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
     */
    public java.lang.String getRolledLogsIncludePattern() {
      java.lang.Object ref = rolledLogsIncludePattern_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          rolledLogsIncludePattern_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
     */
    public com.google.protobuf.ByteString
        getRolledLogsIncludePatternBytes() {
      java.lang.Object ref = rolledLogsIncludePattern_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        rolledLogsIncludePattern_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string rolled_logs_exclude_pattern = 4 [default = ".*"];
    public static final int ROLLED_LOGS_EXCLUDE_PATTERN_FIELD_NUMBER = 4;
    private java.lang.Object rolledLogsExcludePattern_;
    /**
     * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
     */
    public boolean hasRolledLogsExcludePattern() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
     */
    public java.lang.String getRolledLogsExcludePattern() {
      java.lang.Object ref = rolledLogsExcludePattern_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          rolledLogsExcludePattern_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
     */
    public com.google.protobuf.ByteString
        getRolledLogsExcludePatternBytes() {
      java.lang.Object ref = rolledLogsExcludePattern_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        rolledLogsExcludePattern_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string log_aggregation_policy_class_name = 5;
    public static final int LOG_AGGREGATION_POLICY_CLASS_NAME_FIELD_NUMBER = 5;
    private java.lang.Object logAggregationPolicyClassName_;
    /**
     * <code>optional string log_aggregation_policy_class_name = 5;</code>
     */
    public boolean hasLogAggregationPolicyClassName() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string log_aggregation_policy_class_name = 5;</code>
     */
    public java.lang.String getLogAggregationPolicyClassName() {
      java.lang.Object ref = logAggregationPolicyClassName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          logAggregationPolicyClassName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string log_aggregation_policy_class_name = 5;</code>
     */
    public com.google.protobuf.ByteString
        getLogAggregationPolicyClassNameBytes() {
      java.lang.Object ref = logAggregationPolicyClassName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        logAggregationPolicyClassName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string log_aggregation_policy_parameters = 6;
    public static final int LOG_AGGREGATION_POLICY_PARAMETERS_FIELD_NUMBER = 6;
    private java.lang.Object logAggregationPolicyParameters_;
    /**
     * <code>optional string log_aggregation_policy_parameters = 6;</code>
     */
    public boolean hasLogAggregationPolicyParameters() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional string log_aggregation_policy_parameters = 6;</code>
     */
    public java.lang.String getLogAggregationPolicyParameters() {
      java.lang.Object ref = logAggregationPolicyParameters_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          logAggregationPolicyParameters_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string log_aggregation_policy_parameters = 6;</code>
     */
    public com.google.protobuf.ByteString
        getLogAggregationPolicyParametersBytes() {
      java.lang.Object ref = logAggregationPolicyParameters_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        logAggregationPolicyParameters_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      includePattern_ = ".*";
      excludePattern_ = "";
      rolledLogsIncludePattern_ = "";
      rolledLogsExcludePattern_ = ".*";
      logAggregationPolicyClassName_ = "";
      logAggregationPolicyParameters_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getIncludePatternBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getExcludePatternBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getRolledLogsIncludePatternBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(4, getRolledLogsExcludePatternBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBytes(5, getLogAggregationPolicyClassNameBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBytes(6, getLogAggregationPolicyParametersBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getIncludePatternBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getExcludePatternBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getRolledLogsIncludePatternBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, getRolledLogsExcludePatternBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(5, getLogAggregationPolicyClassNameBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(6, getLogAggregationPolicyParametersBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto other = (org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto) obj;

      boolean result = true;
      result = result && (hasIncludePattern() == other.hasIncludePattern());
      if (hasIncludePattern()) {
        result = result && getIncludePattern()
            .equals(other.getIncludePattern());
      }
      result = result && (hasExcludePattern() == other.hasExcludePattern());
      if (hasExcludePattern()) {
        result = result && getExcludePattern()
            .equals(other.getExcludePattern());
      }
      result = result && (hasRolledLogsIncludePattern() == other.hasRolledLogsIncludePattern());
      if (hasRolledLogsIncludePattern()) {
        result = result && getRolledLogsIncludePattern()
            .equals(other.getRolledLogsIncludePattern());
      }
      result = result && (hasRolledLogsExcludePattern() == other.hasRolledLogsExcludePattern());
      if (hasRolledLogsExcludePattern()) {
        result = result && getRolledLogsExcludePattern()
            .equals(other.getRolledLogsExcludePattern());
      }
      result = result && (hasLogAggregationPolicyClassName() == other.hasLogAggregationPolicyClassName());
      if (hasLogAggregationPolicyClassName()) {
        result = result && getLogAggregationPolicyClassName()
            .equals(other.getLogAggregationPolicyClassName());
      }
      result = result && (hasLogAggregationPolicyParameters() == other.hasLogAggregationPolicyParameters());
      if (hasLogAggregationPolicyParameters()) {
        result = result && getLogAggregationPolicyParameters()
            .equals(other.getLogAggregationPolicyParameters());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasIncludePattern()) {
        hash = (37 * hash) + INCLUDE_PATTERN_FIELD_NUMBER;
        hash = (53 * hash) + getIncludePattern().hashCode();
      }
      if (hasExcludePattern()) {
        hash = (37 * hash) + EXCLUDE_PATTERN_FIELD_NUMBER;
        hash = (53 * hash) + getExcludePattern().hashCode();
      }
      if (hasRolledLogsIncludePattern()) {
        hash = (37 * hash) + ROLLED_LOGS_INCLUDE_PATTERN_FIELD_NUMBER;
        hash = (53 * hash) + getRolledLogsIncludePattern().hashCode();
      }
      if (hasRolledLogsExcludePattern()) {
        hash = (37 * hash) + ROLLED_LOGS_EXCLUDE_PATTERN_FIELD_NUMBER;
        hash = (53 * hash) + getRolledLogsExcludePattern().hashCode();
      }
      if (hasLogAggregationPolicyClassName()) {
        hash = (37 * hash) + LOG_AGGREGATION_POLICY_CLASS_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getLogAggregationPolicyClassName().hashCode();
      }
      if (hasLogAggregationPolicyParameters()) {
        hash = (37 * hash) + LOG_AGGREGATION_POLICY_PARAMETERS_FIELD_NUMBER;
        hash = (53 * hash) + getLogAggregationPolicyParameters().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.LogAggregationContextProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LogAggregationContextProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LogAggregationContextProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        includePattern_ = ".*";
        bitField0_ = (bitField0_ & ~0x00000001);
        excludePattern_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        rolledLogsIncludePattern_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        rolledLogsExcludePattern_ = ".*";
        bitField0_ = (bitField0_ & ~0x00000008);
        logAggregationPolicyClassName_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        logAggregationPolicyParameters_ = "";
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LogAggregationContextProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto result = new org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.includePattern_ = includePattern_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.excludePattern_ = excludePattern_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.rolledLogsIncludePattern_ = rolledLogsIncludePattern_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.rolledLogsExcludePattern_ = rolledLogsExcludePattern_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.logAggregationPolicyClassName_ = logAggregationPolicyClassName_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.logAggregationPolicyParameters_ = logAggregationPolicyParameters_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance()) return this;
        if (other.hasIncludePattern()) {
          bitField0_ |= 0x00000001;
          includePattern_ = other.includePattern_;
          onChanged();
        }
        if (other.hasExcludePattern()) {
          bitField0_ |= 0x00000002;
          excludePattern_ = other.excludePattern_;
          onChanged();
        }
        if (other.hasRolledLogsIncludePattern()) {
          bitField0_ |= 0x00000004;
          rolledLogsIncludePattern_ = other.rolledLogsIncludePattern_;
          onChanged();
        }
        if (other.hasRolledLogsExcludePattern()) {
          bitField0_ |= 0x00000008;
          rolledLogsExcludePattern_ = other.rolledLogsExcludePattern_;
          onChanged();
        }
        if (other.hasLogAggregationPolicyClassName()) {
          bitField0_ |= 0x00000010;
          logAggregationPolicyClassName_ = other.logAggregationPolicyClassName_;
          onChanged();
        }
        if (other.hasLogAggregationPolicyParameters()) {
          bitField0_ |= 0x00000020;
          logAggregationPolicyParameters_ = other.logAggregationPolicyParameters_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string include_pattern = 1 [default = ".*"];
      private java.lang.Object includePattern_ = ".*";
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public boolean hasIncludePattern() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public java.lang.String getIncludePattern() {
        java.lang.Object ref = includePattern_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          includePattern_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public com.google.protobuf.ByteString
          getIncludePatternBytes() {
        java.lang.Object ref = includePattern_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          includePattern_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public Builder setIncludePattern(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        includePattern_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public Builder clearIncludePattern() {
        bitField0_ = (bitField0_ & ~0x00000001);
        includePattern_ = getDefaultInstance().getIncludePattern();
        onChanged();
        return this;
      }
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public Builder setIncludePatternBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        includePattern_ = value;
        onChanged();
        return this;
      }

      // optional string exclude_pattern = 2 [default = ""];
      private java.lang.Object excludePattern_ = "";
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public boolean hasExcludePattern() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public java.lang.String getExcludePattern() {
        java.lang.Object ref = excludePattern_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          excludePattern_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public com.google.protobuf.ByteString
          getExcludePatternBytes() {
        java.lang.Object ref = excludePattern_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          excludePattern_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public Builder setExcludePattern(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        excludePattern_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public Builder clearExcludePattern() {
        bitField0_ = (bitField0_ & ~0x00000002);
        excludePattern_ = getDefaultInstance().getExcludePattern();
        onChanged();
        return this;
      }
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public Builder setExcludePatternBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        excludePattern_ = value;
        onChanged();
        return this;
      }

      // optional string rolled_logs_include_pattern = 3 [default = ""];
      private java.lang.Object rolledLogsIncludePattern_ = "";
      /**
       * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
       */
      public boolean hasRolledLogsIncludePattern() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
       */
      public java.lang.String getRolledLogsIncludePattern() {
        java.lang.Object ref = rolledLogsIncludePattern_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          rolledLogsIncludePattern_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
       */
      public com.google.protobuf.ByteString
          getRolledLogsIncludePatternBytes() {
        java.lang.Object ref = rolledLogsIncludePattern_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          rolledLogsIncludePattern_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
       */
      public Builder setRolledLogsIncludePattern(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        rolledLogsIncludePattern_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
       */
      public Builder clearRolledLogsIncludePattern() {
        bitField0_ = (bitField0_ & ~0x00000004);
        rolledLogsIncludePattern_ = getDefaultInstance().getRolledLogsIncludePattern();
        onChanged();
        return this;
      }
      /**
       * <code>optional string rolled_logs_include_pattern = 3 [default = ""];</code>
       */
      public Builder setRolledLogsIncludePatternBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        rolledLogsIncludePattern_ = value;
        onChanged();
        return this;
      }

      // optional string rolled_logs_exclude_pattern = 4 [default = ".*"];
      private java.lang.Object rolledLogsExcludePattern_ = ".*";
      /**
       * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
       */
      public boolean hasRolledLogsExcludePattern() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
       */
      public java.lang.String getRolledLogsExcludePattern() {
        java.lang.Object ref = rolledLogsExcludePattern_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          rolledLogsExcludePattern_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
       */
      public com.google.protobuf.ByteString
          getRolledLogsExcludePatternBytes() {
        java.lang.Object ref = rolledLogsExcludePattern_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          rolledLogsExcludePattern_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
       */
      public Builder setRolledLogsExcludePattern(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        rolledLogsExcludePattern_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
       */
      public Builder clearRolledLogsExcludePattern() {
        bitField0_ = (bitField0_ & ~0x00000008);
        rolledLogsExcludePattern_ = getDefaultInstance().getRolledLogsExcludePattern();
        onChanged();
        return this;
      }
      /**
       * <code>optional string rolled_logs_exclude_pattern = 4 [default = ".*"];</code>
       */
      public Builder setRolledLogsExcludePatternBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        rolledLogsExcludePattern_ = value;
        onChanged();
        return this;
      }

      // optional string log_aggregation_policy_class_name = 5;
      private java.lang.Object logAggregationPolicyClassName_ = "";
      /**
       * <code>optional string log_aggregation_policy_class_name = 5;</code>
       */
      public boolean hasLogAggregationPolicyClassName() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string log_aggregation_policy_class_name = 5;</code>
       */
      public java.lang.String getLogAggregationPolicyClassName() {
        java.lang.Object ref = logAggregationPolicyClassName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          logAggregationPolicyClassName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string log_aggregation_policy_class_name = 5;</code>
       */
      public com.google.protobuf.ByteString
          getLogAggregationPolicyClassNameBytes() {
        java.lang.Object ref = logAggregationPolicyClassName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          logAggregationPolicyClassName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string log_aggregation_policy_class_name = 5;</code>
       */
      public Builder setLogAggregationPolicyClassName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        logAggregationPolicyClassName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string log_aggregation_policy_class_name = 5;</code>
       */
      public Builder clearLogAggregationPolicyClassName() {
        bitField0_ = (bitField0_ & ~0x00000010);
        logAggregationPolicyClassName_ = getDefaultInstance().getLogAggregationPolicyClassName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string log_aggregation_policy_class_name = 5;</code>
       */
      public Builder setLogAggregationPolicyClassNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        logAggregationPolicyClassName_ = value;
        onChanged();
        return this;
      }

      // optional string log_aggregation_policy_parameters = 6;
      private java.lang.Object logAggregationPolicyParameters_ = "";
      /**
       * <code>optional string log_aggregation_policy_parameters = 6;</code>
       */
      public boolean hasLogAggregationPolicyParameters() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional string log_aggregation_policy_parameters = 6;</code>
       */
      public java.lang.String getLogAggregationPolicyParameters() {
        java.lang.Object ref = logAggregationPolicyParameters_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          logAggregationPolicyParameters_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string log_aggregation_policy_parameters = 6;</code>
       */
      public com.google.protobuf.ByteString
          getLogAggregationPolicyParametersBytes() {
        java.lang.Object ref = logAggregationPolicyParameters_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          logAggregationPolicyParameters_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string log_aggregation_policy_parameters = 6;</code>
       */
      public Builder setLogAggregationPolicyParameters(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        logAggregationPolicyParameters_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string log_aggregation_policy_parameters = 6;</code>
       */
      public Builder clearLogAggregationPolicyParameters() {
        bitField0_ = (bitField0_ & ~0x00000020);
        logAggregationPolicyParameters_ = getDefaultInstance().getLogAggregationPolicyParameters();
        onChanged();
        return this;
      }
      /**
       * <code>optional string log_aggregation_policy_parameters = 6;</code>
       */
      public Builder setLogAggregationPolicyParametersBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        logAggregationPolicyParameters_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.LogAggregationContextProto)
    }

    static {
      defaultInstance = new LogAggregationContextProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.LogAggregationContextProto)
  }

  public interface ApplicationACLMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    boolean hasAccessType();
    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto getAccessType();

    // optional string acl = 2 [default = " "];
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    boolean hasAcl();
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    java.lang.String getAcl();
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    com.google.protobuf.ByteString
        getAclBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationACLMapProto}
   */
  public static final class ApplicationACLMapProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationACLMapProtoOrBuilder {
    // Use ApplicationACLMapProto.newBuilder() to construct.
    private ApplicationACLMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationACLMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationACLMapProto defaultInstance;
    public static ApplicationACLMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationACLMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationACLMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                accessType_ = value;
              }
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              acl_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationACLMapProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationACLMapProto>() {
      public ApplicationACLMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationACLMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationACLMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;
    public static final int ACCESSTYPE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto accessType_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    public boolean hasAccessType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto getAccessType() {
      return accessType_;
    }

    // optional string acl = 2 [default = " "];
    public static final int ACL_FIELD_NUMBER = 2;
    private java.lang.Object acl_;
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    public boolean hasAcl() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    public java.lang.String getAcl() {
      java.lang.Object ref = acl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          acl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    public com.google.protobuf.ByteString
        getAclBytes() {
      java.lang.Object ref = acl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        acl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      accessType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.APPACCESS_VIEW_APP;
      acl_ = " ";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, accessType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getAclBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, accessType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getAclBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto) obj;

      boolean result = true;
      result = result && (hasAccessType() == other.hasAccessType());
      if (hasAccessType()) {
        result = result &&
            (getAccessType() == other.getAccessType());
      }
      result = result && (hasAcl() == other.hasAcl());
      if (hasAcl()) {
        result = result && getAcl()
            .equals(other.getAcl());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAccessType()) {
        hash = (37 * hash) + ACCESSTYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getAccessType());
      }
      if (hasAcl()) {
        hash = (37 * hash) + ACL_FIELD_NUMBER;
        hash = (53 * hash) + getAcl().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationACLMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        accessType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.APPACCESS_VIEW_APP;
        bitField0_ = (bitField0_ & ~0x00000001);
        acl_ = " ";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.accessType_ = accessType_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.acl_ = acl_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance()) return this;
        if (other.hasAccessType()) {
          setAccessType(other.getAccessType());
        }
        if (other.hasAcl()) {
          bitField0_ |= 0x00000002;
          acl_ = other.acl_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto accessType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.APPACCESS_VIEW_APP;
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public boolean hasAccessType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto getAccessType() {
        return accessType_;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public Builder setAccessType(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        accessType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public Builder clearAccessType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        accessType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.APPACCESS_VIEW_APP;
        onChanged();
        return this;
      }

      // optional string acl = 2 [default = " "];
      private java.lang.Object acl_ = " ";
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public boolean hasAcl() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public java.lang.String getAcl() {
        java.lang.Object ref = acl_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          acl_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public com.google.protobuf.ByteString
          getAclBytes() {
        java.lang.Object ref = acl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          acl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public Builder setAcl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        acl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public Builder clearAcl() {
        bitField0_ = (bitField0_ & ~0x00000002);
        acl_ = getDefaultInstance().getAcl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public Builder setAclBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        acl_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationACLMapProto)
    }

    static {
      defaultInstance = new ApplicationACLMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationACLMapProto)
  }

  public interface YarnClusterMetricsProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 num_node_managers = 1;
    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    boolean hasNumNodeManagers();
    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    int getNumNodeManagers();

    // optional int32 num_decommissioned_nms = 2;
    /**
     * <code>optional int32 num_decommissioned_nms = 2;</code>
     */
    boolean hasNumDecommissionedNms();
    /**
     * <code>optional int32 num_decommissioned_nms = 2;</code>
     */
    int getNumDecommissionedNms();

    // optional int32 num_active_nms = 3;
    /**
     * <code>optional int32 num_active_nms = 3;</code>
     */
    boolean hasNumActiveNms();
    /**
     * <code>optional int32 num_active_nms = 3;</code>
     */
    int getNumActiveNms();

    // optional int32 num_lost_nms = 4;
    /**
     * <code>optional int32 num_lost_nms = 4;</code>
     */
    boolean hasNumLostNms();
    /**
     * <code>optional int32 num_lost_nms = 4;</code>
     */
    int getNumLostNms();

    // optional int32 num_unhealthy_nms = 5;
    /**
     * <code>optional int32 num_unhealthy_nms = 5;</code>
     */
    boolean hasNumUnhealthyNms();
    /**
     * <code>optional int32 num_unhealthy_nms = 5;</code>
     */
    int getNumUnhealthyNms();

    // optional int32 num_rebooted_nms = 6;
    /**
     * <code>optional int32 num_rebooted_nms = 6;</code>
     */
    boolean hasNumRebootedNms();
    /**
     * <code>optional int32 num_rebooted_nms = 6;</code>
     */
    int getNumRebootedNms();
  }
  /**
   * Protobuf type {@code hadoop.yarn.YarnClusterMetricsProto}
   */
  public static final class YarnClusterMetricsProto extends
      com.google.protobuf.GeneratedMessage
      implements YarnClusterMetricsProtoOrBuilder {
    // Use YarnClusterMetricsProto.newBuilder() to construct.
    private YarnClusterMetricsProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private YarnClusterMetricsProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final YarnClusterMetricsProto defaultInstance;
    public static YarnClusterMetricsProto getDefaultInstance() {
      return defaultInstance;
    }

    public YarnClusterMetricsProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private YarnClusterMetricsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              numNodeManagers_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              numDecommissionedNms_ = input.readInt32();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              numActiveNms_ = input.readInt32();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              numLostNms_ = input.readInt32();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              numUnhealthyNms_ = input.readInt32();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              numRebootedNms_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder.class);
    }

    public static com.google.protobuf.Parser<YarnClusterMetricsProto> PARSER =
        new com.google.protobuf.AbstractParser<YarnClusterMetricsProto>() {
      public YarnClusterMetricsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new YarnClusterMetricsProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<YarnClusterMetricsProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 num_node_managers = 1;
    public static final int NUM_NODE_MANAGERS_FIELD_NUMBER = 1;
    private int numNodeManagers_;
    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    public boolean hasNumNodeManagers() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    public int getNumNodeManagers() {
      return numNodeManagers_;
    }

    // optional int32 num_decommissioned_nms = 2;
    public static final int NUM_DECOMMISSIONED_NMS_FIELD_NUMBER = 2;
    private int numDecommissionedNms_;
    /**
     * <code>optional int32 num_decommissioned_nms = 2;</code>
     */
    public boolean hasNumDecommissionedNms() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 num_decommissioned_nms = 2;</code>
     */
    public int getNumDecommissionedNms() {
      return numDecommissionedNms_;
    }

    // optional int32 num_active_nms = 3;
    public static final int NUM_ACTIVE_NMS_FIELD_NUMBER = 3;
    private int numActiveNms_;
    /**
     * <code>optional int32 num_active_nms = 3;</code>
     */
    public boolean hasNumActiveNms() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int32 num_active_nms = 3;</code>
     */
    public int getNumActiveNms() {
      return numActiveNms_;
    }

    // optional int32 num_lost_nms = 4;
    public static final int NUM_LOST_NMS_FIELD_NUMBER = 4;
    private int numLostNms_;
    /**
     * <code>optional int32 num_lost_nms = 4;</code>
     */
    public boolean hasNumLostNms() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int32 num_lost_nms = 4;</code>
     */
    public int getNumLostNms() {
      return numLostNms_;
    }

    // optional int32 num_unhealthy_nms = 5;
    public static final int NUM_UNHEALTHY_NMS_FIELD_NUMBER = 5;
    private int numUnhealthyNms_;
    /**
     * <code>optional int32 num_unhealthy_nms = 5;</code>
     */
    public boolean hasNumUnhealthyNms() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional int32 num_unhealthy_nms = 5;</code>
     */
    public int getNumUnhealthyNms() {
      return numUnhealthyNms_;
    }

    // optional int32 num_rebooted_nms = 6;
    public static final int NUM_REBOOTED_NMS_FIELD_NUMBER = 6;
    private int numRebootedNms_;
    /**
     * <code>optional int32 num_rebooted_nms = 6;</code>
     */
    public boolean hasNumRebootedNms() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int32 num_rebooted_nms = 6;</code>
     */
    public int getNumRebootedNms() {
      return numRebootedNms_;
    }

    private void initFields() {
      numNodeManagers_ = 0;
      numDecommissionedNms_ = 0;
      numActiveNms_ = 0;
      numLostNms_ = 0;
      numUnhealthyNms_ = 0;
      numRebootedNms_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, numNodeManagers_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, numDecommissionedNms_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(3, numActiveNms_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt32(4, numLostNms_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeInt32(5, numUnhealthyNms_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt32(6, numRebootedNms_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, numNodeManagers_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, numDecommissionedNms_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, numActiveNms_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, numLostNms_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(5, numUnhealthyNms_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(6, numRebootedNms_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto other = (org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto) obj;

      boolean result = true;
      result = result && (hasNumNodeManagers() == other.hasNumNodeManagers());
      if (hasNumNodeManagers()) {
        result = result && (getNumNodeManagers()
            == other.getNumNodeManagers());
      }
      result = result && (hasNumDecommissionedNms() == other.hasNumDecommissionedNms());
      if (hasNumDecommissionedNms()) {
        result = result && (getNumDecommissionedNms()
            == other.getNumDecommissionedNms());
      }
      result = result && (hasNumActiveNms() == other.hasNumActiveNms());
      if (hasNumActiveNms()) {
        result = result && (getNumActiveNms()
            == other.getNumActiveNms());
      }
      result = result && (hasNumLostNms() == other.hasNumLostNms());
      if (hasNumLostNms()) {
        result = result && (getNumLostNms()
            == other.getNumLostNms());
      }
      result = result && (hasNumUnhealthyNms() == other.hasNumUnhealthyNms());
      if (hasNumUnhealthyNms()) {
        result = result && (getNumUnhealthyNms()
            == other.getNumUnhealthyNms());
      }
      result = result && (hasNumRebootedNms() == other.hasNumRebootedNms());
      if (hasNumRebootedNms()) {
        result = result && (getNumRebootedNms()
            == other.getNumRebootedNms());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNumNodeManagers()) {
        hash = (37 * hash) + NUM_NODE_MANAGERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumNodeManagers();
      }
      if (hasNumDecommissionedNms()) {
        hash = (37 * hash) + NUM_DECOMMISSIONED_NMS_FIELD_NUMBER;
        hash = (53 * hash) + getNumDecommissionedNms();
      }
      if (hasNumActiveNms()) {
        hash = (37 * hash) + NUM_ACTIVE_NMS_FIELD_NUMBER;
        hash = (53 * hash) + getNumActiveNms();
      }
      if (hasNumLostNms()) {
        hash = (37 * hash) + NUM_LOST_NMS_FIELD_NUMBER;
        hash = (53 * hash) + getNumLostNms();
      }
      if (hasNumUnhealthyNms()) {
        hash = (37 * hash) + NUM_UNHEALTHY_NMS_FIELD_NUMBER;
        hash = (53 * hash) + getNumUnhealthyNms();
      }
      if (hasNumRebootedNms()) {
        hash = (37 * hash) + NUM_REBOOTED_NMS_FIELD_NUMBER;
        hash = (53 * hash) + getNumRebootedNms();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.YarnClusterMetricsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        numNodeManagers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        numDecommissionedNms_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        numActiveNms_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        numLostNms_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        numUnhealthyNms_ = 0;
        bitField0_ = (bitField0_ & ~0x00000010);
        numRebootedNms_ = 0;
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto result = new org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.numNodeManagers_ = numNodeManagers_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.numDecommissionedNms_ = numDecommissionedNms_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.numActiveNms_ = numActiveNms_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.numLostNms_ = numLostNms_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.numUnhealthyNms_ = numUnhealthyNms_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.numRebootedNms_ = numRebootedNms_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance()) return this;
        if (other.hasNumNodeManagers()) {
          setNumNodeManagers(other.getNumNodeManagers());
        }
        if (other.hasNumDecommissionedNms()) {
          setNumDecommissionedNms(other.getNumDecommissionedNms());
        }
        if (other.hasNumActiveNms()) {
          setNumActiveNms(other.getNumActiveNms());
        }
        if (other.hasNumLostNms()) {
          setNumLostNms(other.getNumLostNms());
        }
        if (other.hasNumUnhealthyNms()) {
          setNumUnhealthyNms(other.getNumUnhealthyNms());
        }
        if (other.hasNumRebootedNms()) {
          setNumRebootedNms(other.getNumRebootedNms());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 num_node_managers = 1;
      private int numNodeManagers_ ;
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public boolean hasNumNodeManagers() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public int getNumNodeManagers() {
        return numNodeManagers_;
      }
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public Builder setNumNodeManagers(int value) {
        bitField0_ |= 0x00000001;
        numNodeManagers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public Builder clearNumNodeManagers() {
        bitField0_ = (bitField0_ & ~0x00000001);
        numNodeManagers_ = 0;
        onChanged();
        return this;
      }

      // optional int32 num_decommissioned_nms = 2;
      private int numDecommissionedNms_ ;
      /**
       * <code>optional int32 num_decommissioned_nms = 2;</code>
       */
      public boolean hasNumDecommissionedNms() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 num_decommissioned_nms = 2;</code>
       */
      public int getNumDecommissionedNms() {
        return numDecommissionedNms_;
      }
      /**
       * <code>optional int32 num_decommissioned_nms = 2;</code>
       */
      public Builder setNumDecommissionedNms(int value) {
        bitField0_ |= 0x00000002;
        numDecommissionedNms_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_decommissioned_nms = 2;</code>
       */
      public Builder clearNumDecommissionedNms() {
        bitField0_ = (bitField0_ & ~0x00000002);
        numDecommissionedNms_ = 0;
        onChanged();
        return this;
      }

      // optional int32 num_active_nms = 3;
      private int numActiveNms_ ;
      /**
       * <code>optional int32 num_active_nms = 3;</code>
       */
      public boolean hasNumActiveNms() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int32 num_active_nms = 3;</code>
       */
      public int getNumActiveNms() {
        return numActiveNms_;
      }
      /**
       * <code>optional int32 num_active_nms = 3;</code>
       */
      public Builder setNumActiveNms(int value) {
        bitField0_ |= 0x00000004;
        numActiveNms_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_active_nms = 3;</code>
       */
      public Builder clearNumActiveNms() {
        bitField0_ = (bitField0_ & ~0x00000004);
        numActiveNms_ = 0;
        onChanged();
        return this;
      }

      // optional int32 num_lost_nms = 4;
      private int numLostNms_ ;
      /**
       * <code>optional int32 num_lost_nms = 4;</code>
       */
      public boolean hasNumLostNms() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int32 num_lost_nms = 4;</code>
       */
      public int getNumLostNms() {
        return numLostNms_;
      }
      /**
       * <code>optional int32 num_lost_nms = 4;</code>
       */
      public Builder setNumLostNms(int value) {
        bitField0_ |= 0x00000008;
        numLostNms_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_lost_nms = 4;</code>
       */
      public Builder clearNumLostNms() {
        bitField0_ = (bitField0_ & ~0x00000008);
        numLostNms_ = 0;
        onChanged();
        return this;
      }

      // optional int32 num_unhealthy_nms = 5;
      private int numUnhealthyNms_ ;
      /**
       * <code>optional int32 num_unhealthy_nms = 5;</code>
       */
      public boolean hasNumUnhealthyNms() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional int32 num_unhealthy_nms = 5;</code>
       */
      public int getNumUnhealthyNms() {
        return numUnhealthyNms_;
      }
      /**
       * <code>optional int32 num_unhealthy_nms = 5;</code>
       */
      public Builder setNumUnhealthyNms(int value) {
        bitField0_ |= 0x00000010;
        numUnhealthyNms_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_unhealthy_nms = 5;</code>
       */
      public Builder clearNumUnhealthyNms() {
        bitField0_ = (bitField0_ & ~0x00000010);
        numUnhealthyNms_ = 0;
        onChanged();
        return this;
      }

      // optional int32 num_rebooted_nms = 6;
      private int numRebootedNms_ ;
      /**
       * <code>optional int32 num_rebooted_nms = 6;</code>
       */
      public boolean hasNumRebootedNms() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int32 num_rebooted_nms = 6;</code>
       */
      public int getNumRebootedNms() {
        return numRebootedNms_;
      }
      /**
       * <code>optional int32 num_rebooted_nms = 6;</code>
       */
      public Builder setNumRebootedNms(int value) {
        bitField0_ |= 0x00000020;
        numRebootedNms_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_rebooted_nms = 6;</code>
       */
      public Builder clearNumRebootedNms() {
        bitField0_ = (bitField0_ & ~0x00000020);
        numRebootedNms_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.YarnClusterMetricsProto)
    }

    static {
      defaultInstance = new YarnClusterMetricsProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.YarnClusterMetricsProto)
  }

  public interface QueueStatisticsProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int64 numAppsSubmitted = 1;
    /**
     * <code>optional int64 numAppsSubmitted = 1;</code>
     */
    boolean hasNumAppsSubmitted();
    /**
     * <code>optional int64 numAppsSubmitted = 1;</code>
     */
    long getNumAppsSubmitted();

    // optional int64 numAppsRunning = 2;
    /**
     * <code>optional int64 numAppsRunning = 2;</code>
     */
    boolean hasNumAppsRunning();
    /**
     * <code>optional int64 numAppsRunning = 2;</code>
     */
    long getNumAppsRunning();

    // optional int64 numAppsPending = 3;
    /**
     * <code>optional int64 numAppsPending = 3;</code>
     */
    boolean hasNumAppsPending();
    /**
     * <code>optional int64 numAppsPending = 3;</code>
     */
    long getNumAppsPending();

    // optional int64 numAppsCompleted = 4;
    /**
     * <code>optional int64 numAppsCompleted = 4;</code>
     */
    boolean hasNumAppsCompleted();
    /**
     * <code>optional int64 numAppsCompleted = 4;</code>
     */
    long getNumAppsCompleted();

    // optional int64 numAppsKilled = 5;
    /**
     * <code>optional int64 numAppsKilled = 5;</code>
     */
    boolean hasNumAppsKilled();
    /**
     * <code>optional int64 numAppsKilled = 5;</code>
     */
    long getNumAppsKilled();

    // optional int64 numAppsFailed = 6;
    /**
     * <code>optional int64 numAppsFailed = 6;</code>
     */
    boolean hasNumAppsFailed();
    /**
     * <code>optional int64 numAppsFailed = 6;</code>
     */
    long getNumAppsFailed();

    // optional int64 numActiveUsers = 7;
    /**
     * <code>optional int64 numActiveUsers = 7;</code>
     */
    boolean hasNumActiveUsers();
    /**
     * <code>optional int64 numActiveUsers = 7;</code>
     */
    long getNumActiveUsers();

    // optional int64 availableMemoryMB = 8;
    /**
     * <code>optional int64 availableMemoryMB = 8;</code>
     */
    boolean hasAvailableMemoryMB();
    /**
     * <code>optional int64 availableMemoryMB = 8;</code>
     */
    long getAvailableMemoryMB();

    // optional int64 allocatedMemoryMB = 9;
    /**
     * <code>optional int64 allocatedMemoryMB = 9;</code>
     */
    boolean hasAllocatedMemoryMB();
    /**
     * <code>optional int64 allocatedMemoryMB = 9;</code>
     */
    long getAllocatedMemoryMB();

    // optional int64 pendingMemoryMB = 10;
    /**
     * <code>optional int64 pendingMemoryMB = 10;</code>
     */
    boolean hasPendingMemoryMB();
    /**
     * <code>optional int64 pendingMemoryMB = 10;</code>
     */
    long getPendingMemoryMB();

    // optional int64 reservedMemoryMB = 11;
    /**
     * <code>optional int64 reservedMemoryMB = 11;</code>
     */
    boolean hasReservedMemoryMB();
    /**
     * <code>optional int64 reservedMemoryMB = 11;</code>
     */
    long getReservedMemoryMB();

    // optional int64 availableVCores = 12;
    /**
     * <code>optional int64 availableVCores = 12;</code>
     */
    boolean hasAvailableVCores();
    /**
     * <code>optional int64 availableVCores = 12;</code>
     */
    long getAvailableVCores();

    // optional int64 allocatedVCores = 13;
    /**
     * <code>optional int64 allocatedVCores = 13;</code>
     */
    boolean hasAllocatedVCores();
    /**
     * <code>optional int64 allocatedVCores = 13;</code>
     */
    long getAllocatedVCores();

    // optional int64 pendingVCores = 14;
    /**
     * <code>optional int64 pendingVCores = 14;</code>
     */
    boolean hasPendingVCores();
    /**
     * <code>optional int64 pendingVCores = 14;</code>
     */
    long getPendingVCores();

    // optional int64 reservedVCores = 15;
    /**
     * <code>optional int64 reservedVCores = 15;</code>
     */
    boolean hasReservedVCores();
    /**
     * <code>optional int64 reservedVCores = 15;</code>
     */
    long getReservedVCores();

    // optional int64 allocatedContainers = 16;
    /**
     * <code>optional int64 allocatedContainers = 16;</code>
     */
    boolean hasAllocatedContainers();
    /**
     * <code>optional int64 allocatedContainers = 16;</code>
     */
    long getAllocatedContainers();

    // optional int64 pendingContainers = 17;
    /**
     * <code>optional int64 pendingContainers = 17;</code>
     */
    boolean hasPendingContainers();
    /**
     * <code>optional int64 pendingContainers = 17;</code>
     */
    long getPendingContainers();

    // optional int64 reservedContainers = 18;
    /**
     * <code>optional int64 reservedContainers = 18;</code>
     */
    boolean hasReservedContainers();
    /**
     * <code>optional int64 reservedContainers = 18;</code>
     */
    long getReservedContainers();
  }
  /**
   * Protobuf type {@code hadoop.yarn.QueueStatisticsProto}
   */
  public static final class QueueStatisticsProto extends
      com.google.protobuf.GeneratedMessage
      implements QueueStatisticsProtoOrBuilder {
    // Use QueueStatisticsProto.newBuilder() to construct.
    private QueueStatisticsProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private QueueStatisticsProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final QueueStatisticsProto defaultInstance;
    public static QueueStatisticsProto getDefaultInstance() {
      return defaultInstance;
    }

    public QueueStatisticsProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private QueueStatisticsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              numAppsSubmitted_ = input.readInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              numAppsRunning_ = input.readInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              numAppsPending_ = input.readInt64();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              numAppsCompleted_ = input.readInt64();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              numAppsKilled_ = input.readInt64();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              numAppsFailed_ = input.readInt64();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              numActiveUsers_ = input.readInt64();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              availableMemoryMB_ = input.readInt64();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              allocatedMemoryMB_ = input.readInt64();
              break;
            }
            case 80: {
              bitField0_ |= 0x00000200;
              pendingMemoryMB_ = input.readInt64();
              break;
            }
            case 88: {
              bitField0_ |= 0x00000400;
              reservedMemoryMB_ = input.readInt64();
              break;
            }
            case 96: {
              bitField0_ |= 0x00000800;
              availableVCores_ = input.readInt64();
              break;
            }
            case 104: {
              bitField0_ |= 0x00001000;
              allocatedVCores_ = input.readInt64();
              break;
            }
            case 112: {
              bitField0_ |= 0x00002000;
              pendingVCores_ = input.readInt64();
              break;
            }
            case 120: {
              bitField0_ |= 0x00004000;
              reservedVCores_ = input.readInt64();
              break;
            }
            case 128: {
              bitField0_ |= 0x00008000;
              allocatedContainers_ = input.readInt64();
              break;
            }
            case 136: {
              bitField0_ |= 0x00010000;
              pendingContainers_ = input.readInt64();
              break;
            }
            case 144: {
              bitField0_ |= 0x00020000;
              reservedContainers_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueStatisticsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueStatisticsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.Builder.class);
    }

    public static com.google.protobuf.Parser<QueueStatisticsProto> PARSER =
        new com.google.protobuf.AbstractParser<QueueStatisticsProto>() {
      public QueueStatisticsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new QueueStatisticsProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<QueueStatisticsProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int64 numAppsSubmitted = 1;
    public static final int NUMAPPSSUBMITTED_FIELD_NUMBER = 1;
    private long numAppsSubmitted_;
    /**
     * <code>optional int64 numAppsSubmitted = 1;</code>
     */
    public boolean hasNumAppsSubmitted() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int64 numAppsSubmitted = 1;</code>
     */
    public long getNumAppsSubmitted() {
      return numAppsSubmitted_;
    }

    // optional int64 numAppsRunning = 2;
    public static final int NUMAPPSRUNNING_FIELD_NUMBER = 2;
    private long numAppsRunning_;
    /**
     * <code>optional int64 numAppsRunning = 2;</code>
     */
    public boolean hasNumAppsRunning() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 numAppsRunning = 2;</code>
     */
    public long getNumAppsRunning() {
      return numAppsRunning_;
    }

    // optional int64 numAppsPending = 3;
    public static final int NUMAPPSPENDING_FIELD_NUMBER = 3;
    private long numAppsPending_;
    /**
     * <code>optional int64 numAppsPending = 3;</code>
     */
    public boolean hasNumAppsPending() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 numAppsPending = 3;</code>
     */
    public long getNumAppsPending() {
      return numAppsPending_;
    }

    // optional int64 numAppsCompleted = 4;
    public static final int NUMAPPSCOMPLETED_FIELD_NUMBER = 4;
    private long numAppsCompleted_;
    /**
     * <code>optional int64 numAppsCompleted = 4;</code>
     */
    public boolean hasNumAppsCompleted() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int64 numAppsCompleted = 4;</code>
     */
    public long getNumAppsCompleted() {
      return numAppsCompleted_;
    }

    // optional int64 numAppsKilled = 5;
    public static final int NUMAPPSKILLED_FIELD_NUMBER = 5;
    private long numAppsKilled_;
    /**
     * <code>optional int64 numAppsKilled = 5;</code>
     */
    public boolean hasNumAppsKilled() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional int64 numAppsKilled = 5;</code>
     */
    public long getNumAppsKilled() {
      return numAppsKilled_;
    }

    // optional int64 numAppsFailed = 6;
    public static final int NUMAPPSFAILED_FIELD_NUMBER = 6;
    private long numAppsFailed_;
    /**
     * <code>optional int64 numAppsFailed = 6;</code>
     */
    public boolean hasNumAppsFailed() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int64 numAppsFailed = 6;</code>
     */
    public long getNumAppsFailed() {
      return numAppsFailed_;
    }

    // optional int64 numActiveUsers = 7;
    public static final int NUMACTIVEUSERS_FIELD_NUMBER = 7;
    private long numActiveUsers_;
    /**
     * <code>optional int64 numActiveUsers = 7;</code>
     */
    public boolean hasNumActiveUsers() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional int64 numActiveUsers = 7;</code>
     */
    public long getNumActiveUsers() {
      return numActiveUsers_;
    }

    // optional int64 availableMemoryMB = 8;
    public static final int AVAILABLEMEMORYMB_FIELD_NUMBER = 8;
    private long availableMemoryMB_;
    /**
     * <code>optional int64 availableMemoryMB = 8;</code>
     */
    public boolean hasAvailableMemoryMB() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional int64 availableMemoryMB = 8;</code>
     */
    public long getAvailableMemoryMB() {
      return availableMemoryMB_;
    }

    // optional int64 allocatedMemoryMB = 9;
    public static final int ALLOCATEDMEMORYMB_FIELD_NUMBER = 9;
    private long allocatedMemoryMB_;
    /**
     * <code>optional int64 allocatedMemoryMB = 9;</code>
     */
    public boolean hasAllocatedMemoryMB() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional int64 allocatedMemoryMB = 9;</code>
     */
    public long getAllocatedMemoryMB() {
      return allocatedMemoryMB_;
    }

    // optional int64 pendingMemoryMB = 10;
    public static final int PENDINGMEMORYMB_FIELD_NUMBER = 10;
    private long pendingMemoryMB_;
    /**
     * <code>optional int64 pendingMemoryMB = 10;</code>
     */
    public boolean hasPendingMemoryMB() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional int64 pendingMemoryMB = 10;</code>
     */
    public long getPendingMemoryMB() {
      return pendingMemoryMB_;
    }

    // optional int64 reservedMemoryMB = 11;
    public static final int RESERVEDMEMORYMB_FIELD_NUMBER = 11;
    private long reservedMemoryMB_;
    /**
     * <code>optional int64 reservedMemoryMB = 11;</code>
     */
    public boolean hasReservedMemoryMB() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    /**
     * <code>optional int64 reservedMemoryMB = 11;</code>
     */
    public long getReservedMemoryMB() {
      return reservedMemoryMB_;
    }

    // optional int64 availableVCores = 12;
    public static final int AVAILABLEVCORES_FIELD_NUMBER = 12;
    private long availableVCores_;
    /**
     * <code>optional int64 availableVCores = 12;</code>
     */
    public boolean hasAvailableVCores() {
      return ((bitField0_ & 0x00000800) == 0x00000800);
    }
    /**
     * <code>optional int64 availableVCores = 12;</code>
     */
    public long getAvailableVCores() {
      return availableVCores_;
    }

    // optional int64 allocatedVCores = 13;
    public static final int ALLOCATEDVCORES_FIELD_NUMBER = 13;
    private long allocatedVCores_;
    /**
     * <code>optional int64 allocatedVCores = 13;</code>
     */
    public boolean hasAllocatedVCores() {
      return ((bitField0_ & 0x00001000) == 0x00001000);
    }
    /**
     * <code>optional int64 allocatedVCores = 13;</code>
     */
    public long getAllocatedVCores() {
      return allocatedVCores_;
    }

    // optional int64 pendingVCores = 14;
    public static final int PENDINGVCORES_FIELD_NUMBER = 14;
    private long pendingVCores_;
    /**
     * <code>optional int64 pendingVCores = 14;</code>
     */
    public boolean hasPendingVCores() {
      return ((bitField0_ & 0x00002000) == 0x00002000);
    }
    /**
     * <code>optional int64 pendingVCores = 14;</code>
     */
    public long getPendingVCores() {
      return pendingVCores_;
    }

    // optional int64 reservedVCores = 15;
    public static final int RESERVEDVCORES_FIELD_NUMBER = 15;
    private long reservedVCores_;
    /**
     * <code>optional int64 reservedVCores = 15;</code>
     */
    public boolean hasReservedVCores() {
      return ((bitField0_ & 0x00004000) == 0x00004000);
    }
    /**
     * <code>optional int64 reservedVCores = 15;</code>
     */
    public long getReservedVCores() {
      return reservedVCores_;
    }

    // optional int64 allocatedContainers = 16;
    public static final int ALLOCATEDCONTAINERS_FIELD_NUMBER = 16;
    private long allocatedContainers_;
    /**
     * <code>optional int64 allocatedContainers = 16;</code>
     */
    public boolean hasAllocatedContainers() {
      return ((bitField0_ & 0x00008000) == 0x00008000);
    }
    /**
     * <code>optional int64 allocatedContainers = 16;</code>
     */
    public long getAllocatedContainers() {
      return allocatedContainers_;
    }

    // optional int64 pendingContainers = 17;
    public static final int PENDINGCONTAINERS_FIELD_NUMBER = 17;
    private long pendingContainers_;
    /**
     * <code>optional int64 pendingContainers = 17;</code>
     */
    public boolean hasPendingContainers() {
      return ((bitField0_ & 0x00010000) == 0x00010000);
    }
    /**
     * <code>optional int64 pendingContainers = 17;</code>
     */
    public long getPendingContainers() {
      return pendingContainers_;
    }

    // optional int64 reservedContainers = 18;
    public static final int RESERVEDCONTAINERS_FIELD_NUMBER = 18;
    private long reservedContainers_;
    /**
     * <code>optional int64 reservedContainers = 18;</code>
     */
    public boolean hasReservedContainers() {
      return ((bitField0_ & 0x00020000) == 0x00020000);
    }
    /**
     * <code>optional int64 reservedContainers = 18;</code>
     */
    public long getReservedContainers() {
      return reservedContainers_;
    }

    private void initFields() {
      numAppsSubmitted_ = 0L;
      numAppsRunning_ = 0L;
      numAppsPending_ = 0L;
      numAppsCompleted_ = 0L;
      numAppsKilled_ = 0L;
      numAppsFailed_ = 0L;
      numActiveUsers_ = 0L;
      availableMemoryMB_ = 0L;
      allocatedMemoryMB_ = 0L;
      pendingMemoryMB_ = 0L;
      reservedMemoryMB_ = 0L;
      availableVCores_ = 0L;
      allocatedVCores_ = 0L;
      pendingVCores_ = 0L;
      reservedVCores_ = 0L;
      allocatedContainers_ = 0L;
      pendingContainers_ = 0L;
      reservedContainers_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt64(1, numAppsSubmitted_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, numAppsRunning_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, numAppsPending_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt64(4, numAppsCompleted_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeInt64(5, numAppsKilled_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt64(6, numAppsFailed_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeInt64(7, numActiveUsers_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeInt64(8, availableMemoryMB_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeInt64(9, allocatedMemoryMB_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeInt64(10, pendingMemoryMB_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeInt64(11, reservedMemoryMB_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        output.writeInt64(12, availableVCores_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        output.writeInt64(13, allocatedVCores_);
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        output.writeInt64(14, pendingVCores_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        output.writeInt64(15, reservedVCores_);
      }
      if (((bitField0_ & 0x00008000) == 0x00008000)) {
        output.writeInt64(16, allocatedContainers_);
      }
      if (((bitField0_ & 0x00010000) == 0x00010000)) {
        output.writeInt64(17, pendingContainers_);
      }
      if (((bitField0_ & 0x00020000) == 0x00020000)) {
        output.writeInt64(18, reservedContainers_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, numAppsSubmitted_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, numAppsRunning_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, numAppsPending_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(4, numAppsCompleted_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(5, numAppsKilled_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(6, numAppsFailed_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(7, numActiveUsers_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(8, availableMemoryMB_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(9, allocatedMemoryMB_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(10, pendingMemoryMB_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(11, reservedMemoryMB_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(12, availableVCores_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(13, allocatedVCores_);
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(14, pendingVCores_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(15, reservedVCores_);
      }
      if (((bitField0_ & 0x00008000) == 0x00008000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(16, allocatedContainers_);
      }
      if (((bitField0_ & 0x00010000) == 0x00010000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(17, pendingContainers_);
      }
      if (((bitField0_ & 0x00020000) == 0x00020000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(18, reservedContainers_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto other = (org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto) obj;

      boolean result = true;
      result = result && (hasNumAppsSubmitted() == other.hasNumAppsSubmitted());
      if (hasNumAppsSubmitted()) {
        result = result && (getNumAppsSubmitted()
            == other.getNumAppsSubmitted());
      }
      result = result && (hasNumAppsRunning() == other.hasNumAppsRunning());
      if (hasNumAppsRunning()) {
        result = result && (getNumAppsRunning()
            == other.getNumAppsRunning());
      }
      result = result && (hasNumAppsPending() == other.hasNumAppsPending());
      if (hasNumAppsPending()) {
        result = result && (getNumAppsPending()
            == other.getNumAppsPending());
      }
      result = result && (hasNumAppsCompleted() == other.hasNumAppsCompleted());
      if (hasNumAppsCompleted()) {
        result = result && (getNumAppsCompleted()
            == other.getNumAppsCompleted());
      }
      result = result && (hasNumAppsKilled() == other.hasNumAppsKilled());
      if (hasNumAppsKilled()) {
        result = result && (getNumAppsKilled()
            == other.getNumAppsKilled());
      }
      result = result && (hasNumAppsFailed() == other.hasNumAppsFailed());
      if (hasNumAppsFailed()) {
        result = result && (getNumAppsFailed()
            == other.getNumAppsFailed());
      }
      result = result && (hasNumActiveUsers() == other.hasNumActiveUsers());
      if (hasNumActiveUsers()) {
        result = result && (getNumActiveUsers()
            == other.getNumActiveUsers());
      }
      result = result && (hasAvailableMemoryMB() == other.hasAvailableMemoryMB());
      if (hasAvailableMemoryMB()) {
        result = result && (getAvailableMemoryMB()
            == other.getAvailableMemoryMB());
      }
      result = result && (hasAllocatedMemoryMB() == other.hasAllocatedMemoryMB());
      if (hasAllocatedMemoryMB()) {
        result = result && (getAllocatedMemoryMB()
            == other.getAllocatedMemoryMB());
      }
      result = result && (hasPendingMemoryMB() == other.hasPendingMemoryMB());
      if (hasPendingMemoryMB()) {
        result = result && (getPendingMemoryMB()
            == other.getPendingMemoryMB());
      }
      result = result && (hasReservedMemoryMB() == other.hasReservedMemoryMB());
      if (hasReservedMemoryMB()) {
        result = result && (getReservedMemoryMB()
            == other.getReservedMemoryMB());
      }
      result = result && (hasAvailableVCores() == other.hasAvailableVCores());
      if (hasAvailableVCores()) {
        result = result && (getAvailableVCores()
            == other.getAvailableVCores());
      }
      result = result && (hasAllocatedVCores() == other.hasAllocatedVCores());
      if (hasAllocatedVCores()) {
        result = result && (getAllocatedVCores()
            == other.getAllocatedVCores());
      }
      result = result && (hasPendingVCores() == other.hasPendingVCores());
      if (hasPendingVCores()) {
        result = result && (getPendingVCores()
            == other.getPendingVCores());
      }
      result = result && (hasReservedVCores() == other.hasReservedVCores());
      if (hasReservedVCores()) {
        result = result && (getReservedVCores()
            == other.getReservedVCores());
      }
      result = result && (hasAllocatedContainers() == other.hasAllocatedContainers());
      if (hasAllocatedContainers()) {
        result = result && (getAllocatedContainers()
            == other.getAllocatedContainers());
      }
      result = result && (hasPendingContainers() == other.hasPendingContainers());
      if (hasPendingContainers()) {
        result = result && (getPendingContainers()
            == other.getPendingContainers());
      }
      result = result && (hasReservedContainers() == other.hasReservedContainers());
      if (hasReservedContainers()) {
        result = result && (getReservedContainers()
            == other.getReservedContainers());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNumAppsSubmitted()) {
        hash = (37 * hash) + NUMAPPSSUBMITTED_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getNumAppsSubmitted());
      }
      if (hasNumAppsRunning()) {
        hash = (37 * hash) + NUMAPPSRUNNING_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getNumAppsRunning());
      }
      if (hasNumAppsPending()) {
        hash = (37 * hash) + NUMAPPSPENDING_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getNumAppsPending());
      }
      if (hasNumAppsCompleted()) {
        hash = (37 * hash) + NUMAPPSCOMPLETED_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getNumAppsCompleted());
      }
      if (hasNumAppsKilled()) {
        hash = (37 * hash) + NUMAPPSKILLED_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getNumAppsKilled());
      }
      if (hasNumAppsFailed()) {
        hash = (37 * hash) + NUMAPPSFAILED_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getNumAppsFailed());
      }
      if (hasNumActiveUsers()) {
        hash = (37 * hash) + NUMACTIVEUSERS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getNumActiveUsers());
      }
      if (hasAvailableMemoryMB()) {
        hash = (37 * hash) + AVAILABLEMEMORYMB_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getAvailableMemoryMB());
      }
      if (hasAllocatedMemoryMB()) {
        hash = (37 * hash) + ALLOCATEDMEMORYMB_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getAllocatedMemoryMB());
      }
      if (hasPendingMemoryMB()) {
        hash = (37 * hash) + PENDINGMEMORYMB_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getPendingMemoryMB());
      }
      if (hasReservedMemoryMB()) {
        hash = (37 * hash) + RESERVEDMEMORYMB_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getReservedMemoryMB());
      }
      if (hasAvailableVCores()) {
        hash = (37 * hash) + AVAILABLEVCORES_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getAvailableVCores());
      }
      if (hasAllocatedVCores()) {
        hash = (37 * hash) + ALLOCATEDVCORES_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getAllocatedVCores());
      }
      if (hasPendingVCores()) {
        hash = (37 * hash) + PENDINGVCORES_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getPendingVCores());
      }
      if (hasReservedVCores()) {
        hash = (37 * hash) + RESERVEDVCORES_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getReservedVCores());
      }
      if (hasAllocatedContainers()) {
        hash = (37 * hash) + ALLOCATEDCONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getAllocatedContainers());
      }
      if (hasPendingContainers()) {
        hash = (37 * hash) + PENDINGCONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getPendingContainers());
      }
      if (hasReservedContainers()) {
        hash = (37 * hash) + RESERVEDCONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getReservedContainers());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.QueueStatisticsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueStatisticsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueStatisticsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        numAppsSubmitted_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        numAppsRunning_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        numAppsPending_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        numAppsCompleted_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        numAppsKilled_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000010);
        numAppsFailed_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000020);
        numActiveUsers_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000040);
        availableMemoryMB_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000080);
        allocatedMemoryMB_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000100);
        pendingMemoryMB_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000200);
        reservedMemoryMB_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000400);
        availableVCores_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000800);
        allocatedVCores_ = 0L;
        bitField0_ = (bitField0_ & ~0x00001000);
        pendingVCores_ = 0L;
        bitField0_ = (bitField0_ & ~0x00002000);
        reservedVCores_ = 0L;
        bitField0_ = (bitField0_ & ~0x00004000);
        allocatedContainers_ = 0L;
        bitField0_ = (bitField0_ & ~0x00008000);
        pendingContainers_ = 0L;
        bitField0_ = (bitField0_ & ~0x00010000);
        reservedContainers_ = 0L;
        bitField0_ = (bitField0_ & ~0x00020000);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueStatisticsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto result = new org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.numAppsSubmitted_ = numAppsSubmitted_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.numAppsRunning_ = numAppsRunning_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.numAppsPending_ = numAppsPending_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.numAppsCompleted_ = numAppsCompleted_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.numAppsKilled_ = numAppsKilled_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.numAppsFailed_ = numAppsFailed_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.numActiveUsers_ = numActiveUsers_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.availableMemoryMB_ = availableMemoryMB_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.allocatedMemoryMB_ = allocatedMemoryMB_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.pendingMemoryMB_ = pendingMemoryMB_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000400;
        }
        result.reservedMemoryMB_ = reservedMemoryMB_;
        if (((from_bitField0_ & 0x00000800) == 0x00000800)) {
          to_bitField0_ |= 0x00000800;
        }
        result.availableVCores_ = availableVCores_;
        if (((from_bitField0_ & 0x00001000) == 0x00001000)) {
          to_bitField0_ |= 0x00001000;
        }
        result.allocatedVCores_ = allocatedVCores_;
        if (((from_bitField0_ & 0x00002000) == 0x00002000)) {
          to_bitField0_ |= 0x00002000;
        }
        result.pendingVCores_ = pendingVCores_;
        if (((from_bitField0_ & 0x00004000) == 0x00004000)) {
          to_bitField0_ |= 0x00004000;
        }
        result.reservedVCores_ = reservedVCores_;
        if (((from_bitField0_ & 0x00008000) == 0x00008000)) {
          to_bitField0_ |= 0x00008000;
        }
        result.allocatedContainers_ = allocatedContainers_;
        if (((from_bitField0_ & 0x00010000) == 0x00010000)) {
          to_bitField0_ |= 0x00010000;
        }
        result.pendingContainers_ = pendingContainers_;
        if (((from_bitField0_ & 0x00020000) == 0x00020000)) {
          to_bitField0_ |= 0x00020000;
        }
        result.reservedContainers_ = reservedContainers_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.getDefaultInstance()) return this;
        if (other.hasNumAppsSubmitted()) {
          setNumAppsSubmitted(other.getNumAppsSubmitted());
        }
        if (other.hasNumAppsRunning()) {
          setNumAppsRunning(other.getNumAppsRunning());
        }
        if (other.hasNumAppsPending()) {
          setNumAppsPending(other.getNumAppsPending());
        }
        if (other.hasNumAppsCompleted()) {
          setNumAppsCompleted(other.getNumAppsCompleted());
        }
        if (other.hasNumAppsKilled()) {
          setNumAppsKilled(other.getNumAppsKilled());
        }
        if (other.hasNumAppsFailed()) {
          setNumAppsFailed(other.getNumAppsFailed());
        }
        if (other.hasNumActiveUsers()) {
          setNumActiveUsers(other.getNumActiveUsers());
        }
        if (other.hasAvailableMemoryMB()) {
          setAvailableMemoryMB(other.getAvailableMemoryMB());
        }
        if (other.hasAllocatedMemoryMB()) {
          setAllocatedMemoryMB(other.getAllocatedMemoryMB());
        }
        if (other.hasPendingMemoryMB()) {
          setPendingMemoryMB(other.getPendingMemoryMB());
        }
        if (other.hasReservedMemoryMB()) {
          setReservedMemoryMB(other.getReservedMemoryMB());
        }
        if (other.hasAvailableVCores()) {
          setAvailableVCores(other.getAvailableVCores());
        }
        if (other.hasAllocatedVCores()) {
          setAllocatedVCores(other.getAllocatedVCores());
        }
        if (other.hasPendingVCores()) {
          setPendingVCores(other.getPendingVCores());
        }
        if (other.hasReservedVCores()) {
          setReservedVCores(other.getReservedVCores());
        }
        if (other.hasAllocatedContainers()) {
          setAllocatedContainers(other.getAllocatedContainers());
        }
        if (other.hasPendingContainers()) {
          setPendingContainers(other.getPendingContainers());
        }
        if (other.hasReservedContainers()) {
          setReservedContainers(other.getReservedContainers());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int64 numAppsSubmitted = 1;
      private long numAppsSubmitted_ ;
      /**
       * <code>optional int64 numAppsSubmitted = 1;</code>
       */
      public boolean hasNumAppsSubmitted() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int64 numAppsSubmitted = 1;</code>
       */
      public long getNumAppsSubmitted() {
        return numAppsSubmitted_;
      }
      /**
       * <code>optional int64 numAppsSubmitted = 1;</code>
       */
      public Builder setNumAppsSubmitted(long value) {
        bitField0_ |= 0x00000001;
        numAppsSubmitted_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 numAppsSubmitted = 1;</code>
       */
      public Builder clearNumAppsSubmitted() {
        bitField0_ = (bitField0_ & ~0x00000001);
        numAppsSubmitted_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 numAppsRunning = 2;
      private long numAppsRunning_ ;
      /**
       * <code>optional int64 numAppsRunning = 2;</code>
       */
      public boolean hasNumAppsRunning() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 numAppsRunning = 2;</code>
       */
      public long getNumAppsRunning() {
        return numAppsRunning_;
      }
      /**
       * <code>optional int64 numAppsRunning = 2;</code>
       */
      public Builder setNumAppsRunning(long value) {
        bitField0_ |= 0x00000002;
        numAppsRunning_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 numAppsRunning = 2;</code>
       */
      public Builder clearNumAppsRunning() {
        bitField0_ = (bitField0_ & ~0x00000002);
        numAppsRunning_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 numAppsPending = 3;
      private long numAppsPending_ ;
      /**
       * <code>optional int64 numAppsPending = 3;</code>
       */
      public boolean hasNumAppsPending() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 numAppsPending = 3;</code>
       */
      public long getNumAppsPending() {
        return numAppsPending_;
      }
      /**
       * <code>optional int64 numAppsPending = 3;</code>
       */
      public Builder setNumAppsPending(long value) {
        bitField0_ |= 0x00000004;
        numAppsPending_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 numAppsPending = 3;</code>
       */
      public Builder clearNumAppsPending() {
        bitField0_ = (bitField0_ & ~0x00000004);
        numAppsPending_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 numAppsCompleted = 4;
      private long numAppsCompleted_ ;
      /**
       * <code>optional int64 numAppsCompleted = 4;</code>
       */
      public boolean hasNumAppsCompleted() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int64 numAppsCompleted = 4;</code>
       */
      public long getNumAppsCompleted() {
        return numAppsCompleted_;
      }
      /**
       * <code>optional int64 numAppsCompleted = 4;</code>
       */
      public Builder setNumAppsCompleted(long value) {
        bitField0_ |= 0x00000008;
        numAppsCompleted_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 numAppsCompleted = 4;</code>
       */
      public Builder clearNumAppsCompleted() {
        bitField0_ = (bitField0_ & ~0x00000008);
        numAppsCompleted_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 numAppsKilled = 5;
      private long numAppsKilled_ ;
      /**
       * <code>optional int64 numAppsKilled = 5;</code>
       */
      public boolean hasNumAppsKilled() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional int64 numAppsKilled = 5;</code>
       */
      public long getNumAppsKilled() {
        return numAppsKilled_;
      }
      /**
       * <code>optional int64 numAppsKilled = 5;</code>
       */
      public Builder setNumAppsKilled(long value) {
        bitField0_ |= 0x00000010;
        numAppsKilled_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 numAppsKilled = 5;</code>
       */
      public Builder clearNumAppsKilled() {
        bitField0_ = (bitField0_ & ~0x00000010);
        numAppsKilled_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 numAppsFailed = 6;
      private long numAppsFailed_ ;
      /**
       * <code>optional int64 numAppsFailed = 6;</code>
       */
      public boolean hasNumAppsFailed() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int64 numAppsFailed = 6;</code>
       */
      public long getNumAppsFailed() {
        return numAppsFailed_;
      }
      /**
       * <code>optional int64 numAppsFailed = 6;</code>
       */
      public Builder setNumAppsFailed(long value) {
        bitField0_ |= 0x00000020;
        numAppsFailed_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 numAppsFailed = 6;</code>
       */
      public Builder clearNumAppsFailed() {
        bitField0_ = (bitField0_ & ~0x00000020);
        numAppsFailed_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 numActiveUsers = 7;
      private long numActiveUsers_ ;
      /**
       * <code>optional int64 numActiveUsers = 7;</code>
       */
      public boolean hasNumActiveUsers() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional int64 numActiveUsers = 7;</code>
       */
      public long getNumActiveUsers() {
        return numActiveUsers_;
      }
      /**
       * <code>optional int64 numActiveUsers = 7;</code>
       */
      public Builder setNumActiveUsers(long value) {
        bitField0_ |= 0x00000040;
        numActiveUsers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 numActiveUsers = 7;</code>
       */
      public Builder clearNumActiveUsers() {
        bitField0_ = (bitField0_ & ~0x00000040);
        numActiveUsers_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 availableMemoryMB = 8;
      private long availableMemoryMB_ ;
      /**
       * <code>optional int64 availableMemoryMB = 8;</code>
       */
      public boolean hasAvailableMemoryMB() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional int64 availableMemoryMB = 8;</code>
       */
      public long getAvailableMemoryMB() {
        return availableMemoryMB_;
      }
      /**
       * <code>optional int64 availableMemoryMB = 8;</code>
       */
      public Builder setAvailableMemoryMB(long value) {
        bitField0_ |= 0x00000080;
        availableMemoryMB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 availableMemoryMB = 8;</code>
       */
      public Builder clearAvailableMemoryMB() {
        bitField0_ = (bitField0_ & ~0x00000080);
        availableMemoryMB_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 allocatedMemoryMB = 9;
      private long allocatedMemoryMB_ ;
      /**
       * <code>optional int64 allocatedMemoryMB = 9;</code>
       */
      public boolean hasAllocatedMemoryMB() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional int64 allocatedMemoryMB = 9;</code>
       */
      public long getAllocatedMemoryMB() {
        return allocatedMemoryMB_;
      }
      /**
       * <code>optional int64 allocatedMemoryMB = 9;</code>
       */
      public Builder setAllocatedMemoryMB(long value) {
        bitField0_ |= 0x00000100;
        allocatedMemoryMB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 allocatedMemoryMB = 9;</code>
       */
      public Builder clearAllocatedMemoryMB() {
        bitField0_ = (bitField0_ & ~0x00000100);
        allocatedMemoryMB_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 pendingMemoryMB = 10;
      private long pendingMemoryMB_ ;
      /**
       * <code>optional int64 pendingMemoryMB = 10;</code>
       */
      public boolean hasPendingMemoryMB() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional int64 pendingMemoryMB = 10;</code>
       */
      public long getPendingMemoryMB() {
        return pendingMemoryMB_;
      }
      /**
       * <code>optional int64 pendingMemoryMB = 10;</code>
       */
      public Builder setPendingMemoryMB(long value) {
        bitField0_ |= 0x00000200;
        pendingMemoryMB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 pendingMemoryMB = 10;</code>
       */
      public Builder clearPendingMemoryMB() {
        bitField0_ = (bitField0_ & ~0x00000200);
        pendingMemoryMB_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 reservedMemoryMB = 11;
      private long reservedMemoryMB_ ;
      /**
       * <code>optional int64 reservedMemoryMB = 11;</code>
       */
      public boolean hasReservedMemoryMB() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional int64 reservedMemoryMB = 11;</code>
       */
      public long getReservedMemoryMB() {
        return reservedMemoryMB_;
      }
      /**
       * <code>optional int64 reservedMemoryMB = 11;</code>
       */
      public Builder setReservedMemoryMB(long value) {
        bitField0_ |= 0x00000400;
        reservedMemoryMB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 reservedMemoryMB = 11;</code>
       */
      public Builder clearReservedMemoryMB() {
        bitField0_ = (bitField0_ & ~0x00000400);
        reservedMemoryMB_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 availableVCores = 12;
      private long availableVCores_ ;
      /**
       * <code>optional int64 availableVCores = 12;</code>
       */
      public boolean hasAvailableVCores() {
        return ((bitField0_ & 0x00000800) == 0x00000800);
      }
      /**
       * <code>optional int64 availableVCores = 12;</code>
       */
      public long getAvailableVCores() {
        return availableVCores_;
      }
      /**
       * <code>optional int64 availableVCores = 12;</code>
       */
      public Builder setAvailableVCores(long value) {
        bitField0_ |= 0x00000800;
        availableVCores_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 availableVCores = 12;</code>
       */
      public Builder clearAvailableVCores() {
        bitField0_ = (bitField0_ & ~0x00000800);
        availableVCores_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 allocatedVCores = 13;
      private long allocatedVCores_ ;
      /**
       * <code>optional int64 allocatedVCores = 13;</code>
       */
      public boolean hasAllocatedVCores() {
        return ((bitField0_ & 0x00001000) == 0x00001000);
      }
      /**
       * <code>optional int64 allocatedVCores = 13;</code>
       */
      public long getAllocatedVCores() {
        return allocatedVCores_;
      }
      /**
       * <code>optional int64 allocatedVCores = 13;</code>
       */
      public Builder setAllocatedVCores(long value) {
        bitField0_ |= 0x00001000;
        allocatedVCores_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 allocatedVCores = 13;</code>
       */
      public Builder clearAllocatedVCores() {
        bitField0_ = (bitField0_ & ~0x00001000);
        allocatedVCores_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 pendingVCores = 14;
      private long pendingVCores_ ;
      /**
       * <code>optional int64 pendingVCores = 14;</code>
       */
      public boolean hasPendingVCores() {
        return ((bitField0_ & 0x00002000) == 0x00002000);
      }
      /**
       * <code>optional int64 pendingVCores = 14;</code>
       */
      public long getPendingVCores() {
        return pendingVCores_;
      }
      /**
       * <code>optional int64 pendingVCores = 14;</code>
       */
      public Builder setPendingVCores(long value) {
        bitField0_ |= 0x00002000;
        pendingVCores_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 pendingVCores = 14;</code>
       */
      public Builder clearPendingVCores() {
        bitField0_ = (bitField0_ & ~0x00002000);
        pendingVCores_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 reservedVCores = 15;
      private long reservedVCores_ ;
      /**
       * <code>optional int64 reservedVCores = 15;</code>
       */
      public boolean hasReservedVCores() {
        return ((bitField0_ & 0x00004000) == 0x00004000);
      }
      /**
       * <code>optional int64 reservedVCores = 15;</code>
       */
      public long getReservedVCores() {
        return reservedVCores_;
      }
      /**
       * <code>optional int64 reservedVCores = 15;</code>
       */
      public Builder setReservedVCores(long value) {
        bitField0_ |= 0x00004000;
        reservedVCores_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 reservedVCores = 15;</code>
       */
      public Builder clearReservedVCores() {
        bitField0_ = (bitField0_ & ~0x00004000);
        reservedVCores_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 allocatedContainers = 16;
      private long allocatedContainers_ ;
      /**
       * <code>optional int64 allocatedContainers = 16;</code>
       */
      public boolean hasAllocatedContainers() {
        return ((bitField0_ & 0x00008000) == 0x00008000);
      }
      /**
       * <code>optional int64 allocatedContainers = 16;</code>
       */
      public long getAllocatedContainers() {
        return allocatedContainers_;
      }
      /**
       * <code>optional int64 allocatedContainers = 16;</code>
       */
      public Builder setAllocatedContainers(long value) {
        bitField0_ |= 0x00008000;
        allocatedContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 allocatedContainers = 16;</code>
       */
      public Builder clearAllocatedContainers() {
        bitField0_ = (bitField0_ & ~0x00008000);
        allocatedContainers_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 pendingContainers = 17;
      private long pendingContainers_ ;
      /**
       * <code>optional int64 pendingContainers = 17;</code>
       */
      public boolean hasPendingContainers() {
        return ((bitField0_ & 0x00010000) == 0x00010000);
      }
      /**
       * <code>optional int64 pendingContainers = 17;</code>
       */
      public long getPendingContainers() {
        return pendingContainers_;
      }
      /**
       * <code>optional int64 pendingContainers = 17;</code>
       */
      public Builder setPendingContainers(long value) {
        bitField0_ |= 0x00010000;
        pendingContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 pendingContainers = 17;</code>
       */
      public Builder clearPendingContainers() {
        bitField0_ = (bitField0_ & ~0x00010000);
        pendingContainers_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 reservedContainers = 18;
      private long reservedContainers_ ;
      /**
       * <code>optional int64 reservedContainers = 18;</code>
       */
      public boolean hasReservedContainers() {
        return ((bitField0_ & 0x00020000) == 0x00020000);
      }
      /**
       * <code>optional int64 reservedContainers = 18;</code>
       */
      public long getReservedContainers() {
        return reservedContainers_;
      }
      /**
       * <code>optional int64 reservedContainers = 18;</code>
       */
      public Builder setReservedContainers(long value) {
        bitField0_ |= 0x00020000;
        reservedContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 reservedContainers = 18;</code>
       */
      public Builder clearReservedContainers() {
        bitField0_ = (bitField0_ & ~0x00020000);
        reservedContainers_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.QueueStatisticsProto)
    }

    static {
      defaultInstance = new QueueStatisticsProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.QueueStatisticsProto)
  }

  public interface QueueInfoProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string queueName = 1;
    /**
     * <code>optional string queueName = 1;</code>
     */
    boolean hasQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    java.lang.String getQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    com.google.protobuf.ByteString
        getQueueNameBytes();

    // optional float capacity = 2;
    /**
     * <code>optional float capacity = 2;</code>
     */
    boolean hasCapacity();
    /**
     * <code>optional float capacity = 2;</code>
     */
    float getCapacity();

    // optional float maximumCapacity = 3;
    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    boolean hasMaximumCapacity();
    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    float getMaximumCapacity();

    // optional float currentCapacity = 4;
    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    boolean hasCurrentCapacity();
    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    float getCurrentCapacity();

    // optional .hadoop.yarn.QueueStateProto state = 5;
    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    boolean hasState();
    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto getState();

    // repeated .hadoop.yarn.QueueInfoProto childQueues = 6;
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> 
        getChildQueuesList();
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getChildQueues(int index);
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    int getChildQueuesCount();
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
        getChildQueuesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getChildQueuesOrBuilder(
        int index);

    // repeated .hadoop.yarn.ApplicationReportProto applications = 7;
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> 
        getApplicationsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    int getApplicationsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
        getApplicationsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
        int index);

    // repeated string accessibleNodeLabels = 8;
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    java.util.List<java.lang.String>
    getAccessibleNodeLabelsList();
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    int getAccessibleNodeLabelsCount();
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    java.lang.String getAccessibleNodeLabels(int index);
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    com.google.protobuf.ByteString
        getAccessibleNodeLabelsBytes(int index);

    // optional string defaultNodeLabelExpression = 9;
    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    boolean hasDefaultNodeLabelExpression();
    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    java.lang.String getDefaultNodeLabelExpression();
    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    com.google.protobuf.ByteString
        getDefaultNodeLabelExpressionBytes();

    // optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;
    /**
     * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
     */
    boolean hasQueueStatistics();
    /**
     * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto getQueueStatistics();
    /**
     * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProtoOrBuilder getQueueStatisticsOrBuilder();

    // optional bool preemptionDisabled = 11;
    /**
     * <code>optional bool preemptionDisabled = 11;</code>
     */
    boolean hasPreemptionDisabled();
    /**
     * <code>optional bool preemptionDisabled = 11;</code>
     */
    boolean getPreemptionDisabled();

    // repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;
    /**
     * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto> 
        getQueueConfigurationsMapList();
    /**
     * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto getQueueConfigurationsMap(int index);
    /**
     * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
     */
    int getQueueConfigurationsMapCount();
    /**
     * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProtoOrBuilder> 
        getQueueConfigurationsMapOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProtoOrBuilder getQueueConfigurationsMapOrBuilder(
        int index);

    // optional bool intraQueuePreemptionDisabled = 13;
    /**
     * <code>optional bool intraQueuePreemptionDisabled = 13;</code>
     */
    boolean hasIntraQueuePreemptionDisabled();
    /**
     * <code>optional bool intraQueuePreemptionDisabled = 13;</code>
     */
    boolean getIntraQueuePreemptionDisabled();
  }
  /**
   * Protobuf type {@code hadoop.yarn.QueueInfoProto}
   */
  public static final class QueueInfoProto extends
      com.google.protobuf.GeneratedMessage
      implements QueueInfoProtoOrBuilder {
    // Use QueueInfoProto.newBuilder() to construct.
    private QueueInfoProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private QueueInfoProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final QueueInfoProto defaultInstance;
    public static QueueInfoProto getDefaultInstance() {
      return defaultInstance;
    }

    public QueueInfoProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private QueueInfoProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              queueName_ = input.readBytes();
              break;
            }
            case 21: {
              bitField0_ |= 0x00000002;
              capacity_ = input.readFloat();
              break;
            }
            case 29: {
              bitField0_ |= 0x00000004;
              maximumCapacity_ = input.readFloat();
              break;
            }
            case 37: {
              bitField0_ |= 0x00000008;
              currentCapacity_ = input.readFloat();
              break;
            }
            case 40: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(5, rawValue);
              } else {
                bitField0_ |= 0x00000010;
                state_ = value;
              }
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                childQueues_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              childQueues_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.PARSER, extensionRegistry));
              break;
            }
            case 58: {
              if (!((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
                applications_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto>();
                mutable_bitField0_ |= 0x00000040;
              }
              applications_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.PARSER, extensionRegistry));
              break;
            }
            case 66: {
              if (!((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
                accessibleNodeLabels_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000080;
              }
              accessibleNodeLabels_.add(input.readBytes());
              break;
            }
            case 74: {
              bitField0_ |= 0x00000020;
              defaultNodeLabelExpression_ = input.readBytes();
              break;
            }
            case 82: {
              org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000040) == 0x00000040)) {
                subBuilder = queueStatistics_.toBuilder();
              }
              queueStatistics_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(queueStatistics_);
                queueStatistics_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000040;
              break;
            }
            case 88: {
              bitField0_ |= 0x00000080;
              preemptionDisabled_ = input.readBool();
              break;
            }
            case 98: {
              if (!((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
                queueConfigurationsMap_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto>();
                mutable_bitField0_ |= 0x00000800;
              }
              queueConfigurationsMap_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.PARSER, extensionRegistry));
              break;
            }
            case 104: {
              bitField0_ |= 0x00000100;
              intraQueuePreemptionDisabled_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          childQueues_ = java.util.Collections.unmodifiableList(childQueues_);
        }
        if (((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
          applications_ = java.util.Collections.unmodifiableList(applications_);
        }
        if (((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
          accessibleNodeLabels_ = new com.google.protobuf.UnmodifiableLazyStringList(accessibleNodeLabels_);
        }
        if (((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
          queueConfigurationsMap_ = java.util.Collections.unmodifiableList(queueConfigurationsMap_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder.class);
    }

    public static com.google.protobuf.Parser<QueueInfoProto> PARSER =
        new com.google.protobuf.AbstractParser<QueueInfoProto>() {
      public QueueInfoProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new QueueInfoProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<QueueInfoProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string queueName = 1;
    public static final int QUEUENAME_FIELD_NUMBER = 1;
    private java.lang.Object queueName_;
    /**
     * <code>optional string queueName = 1;</code>
     */
    public boolean hasQueueName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public java.lang.String getQueueName() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queueName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public com.google.protobuf.ByteString
        getQueueNameBytes() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queueName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional float capacity = 2;
    public static final int CAPACITY_FIELD_NUMBER = 2;
    private float capacity_;
    /**
     * <code>optional float capacity = 2;</code>
     */
    public boolean hasCapacity() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional float capacity = 2;</code>
     */
    public float getCapacity() {
      return capacity_;
    }

    // optional float maximumCapacity = 3;
    public static final int MAXIMUMCAPACITY_FIELD_NUMBER = 3;
    private float maximumCapacity_;
    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    public boolean hasMaximumCapacity() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    public float getMaximumCapacity() {
      return maximumCapacity_;
    }

    // optional float currentCapacity = 4;
    public static final int CURRENTCAPACITY_FIELD_NUMBER = 4;
    private float currentCapacity_;
    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    public boolean hasCurrentCapacity() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    public float getCurrentCapacity() {
      return currentCapacity_;
    }

    // optional .hadoop.yarn.QueueStateProto state = 5;
    public static final int STATE_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto state_;
    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    public boolean hasState() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto getState() {
      return state_;
    }

    // repeated .hadoop.yarn.QueueInfoProto childQueues = 6;
    public static final int CHILDQUEUES_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> childQueues_;
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> getChildQueuesList() {
      return childQueues_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
        getChildQueuesOrBuilderList() {
      return childQueues_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public int getChildQueuesCount() {
      return childQueues_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getChildQueues(int index) {
      return childQueues_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getChildQueuesOrBuilder(
        int index) {
      return childQueues_.get(index);
    }

    // repeated .hadoop.yarn.ApplicationReportProto applications = 7;
    public static final int APPLICATIONS_FIELD_NUMBER = 7;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> applications_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> getApplicationsList() {
      return applications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
        getApplicationsOrBuilderList() {
      return applications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public int getApplicationsCount() {
      return applications_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index) {
      return applications_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
        int index) {
      return applications_.get(index);
    }

    // repeated string accessibleNodeLabels = 8;
    public static final int ACCESSIBLENODELABELS_FIELD_NUMBER = 8;
    private com.google.protobuf.LazyStringList accessibleNodeLabels_;
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    public java.util.List<java.lang.String>
        getAccessibleNodeLabelsList() {
      return accessibleNodeLabels_;
    }
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    public int getAccessibleNodeLabelsCount() {
      return accessibleNodeLabels_.size();
    }
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    public java.lang.String getAccessibleNodeLabels(int index) {
      return accessibleNodeLabels_.get(index);
    }
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    public com.google.protobuf.ByteString
        getAccessibleNodeLabelsBytes(int index) {
      return accessibleNodeLabels_.getByteString(index);
    }

    // optional string defaultNodeLabelExpression = 9;
    public static final int DEFAULTNODELABELEXPRESSION_FIELD_NUMBER = 9;
    private java.lang.Object defaultNodeLabelExpression_;
    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    public boolean hasDefaultNodeLabelExpression() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    public java.lang.String getDefaultNodeLabelExpression() {
      java.lang.Object ref = defaultNodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          defaultNodeLabelExpression_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    public com.google.protobuf.ByteString
        getDefaultNodeLabelExpressionBytes() {
      java.lang.Object ref = defaultNodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        defaultNodeLabelExpression_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;
    public static final int QUEUESTATISTICS_FIELD_NUMBER = 10;
    private org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto queueStatistics_;
    /**
     * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
     */
    public boolean hasQueueStatistics() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto getQueueStatistics() {
      return queueStatistics_;
    }
    /**
     * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProtoOrBuilder getQueueStatisticsOrBuilder() {
      return queueStatistics_;
    }

    // optional bool preemptionDisabled = 11;
    public static final int PREEMPTIONDISABLED_FIELD_NUMBER = 11;
    private boolean preemptionDisabled_;
    /**
     * <code>optional bool preemptionDisabled = 11;</code>
     */
    public boolean hasPreemptionDisabled() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional bool preemptionDisabled = 11;</code>
     */
    public boolean getPreemptionDisabled() {
      return preemptionDisabled_;
    }

    // repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;
    public static final int QUEUECONFIGURATIONSMAP_FIELD_NUMBER = 12;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto> queueConfigurationsMap_;
    /**
     * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto> getQueueConfigurationsMapList() {
      return queueConfigurationsMap_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProtoOrBuilder> 
        getQueueConfigurationsMapOrBuilderList() {
      return queueConfigurationsMap_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
     */
    public int getQueueConfigurationsMapCount() {
      return queueConfigurationsMap_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto getQueueConfigurationsMap(int index) {
      return queueConfigurationsMap_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProtoOrBuilder getQueueConfigurationsMapOrBuilder(
        int index) {
      return queueConfigurationsMap_.get(index);
    }

    // optional bool intraQueuePreemptionDisabled = 13;
    public static final int INTRAQUEUEPREEMPTIONDISABLED_FIELD_NUMBER = 13;
    private boolean intraQueuePreemptionDisabled_;
    /**
     * <code>optional bool intraQueuePreemptionDisabled = 13;</code>
     */
    public boolean hasIntraQueuePreemptionDisabled() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional bool intraQueuePreemptionDisabled = 13;</code>
     */
    public boolean getIntraQueuePreemptionDisabled() {
      return intraQueuePreemptionDisabled_;
    }

    private void initFields() {
      queueName_ = "";
      capacity_ = 0F;
      maximumCapacity_ = 0F;
      currentCapacity_ = 0F;
      state_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.Q_STOPPED;
      childQueues_ = java.util.Collections.emptyList();
      applications_ = java.util.Collections.emptyList();
      accessibleNodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      defaultNodeLabelExpression_ = "";
      queueStatistics_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.getDefaultInstance();
      preemptionDisabled_ = false;
      queueConfigurationsMap_ = java.util.Collections.emptyList();
      intraQueuePreemptionDisabled_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getChildQueuesCount(); i++) {
        if (!getChildQueues(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getApplicationsCount(); i++) {
        if (!getApplications(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getQueueConfigurationsMapCount(); i++) {
        if (!getQueueConfigurationsMap(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getQueueNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeFloat(2, capacity_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeFloat(3, maximumCapacity_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeFloat(4, currentCapacity_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeEnum(5, state_.getNumber());
      }
      for (int i = 0; i < childQueues_.size(); i++) {
        output.writeMessage(6, childQueues_.get(i));
      }
      for (int i = 0; i < applications_.size(); i++) {
        output.writeMessage(7, applications_.get(i));
      }
      for (int i = 0; i < accessibleNodeLabels_.size(); i++) {
        output.writeBytes(8, accessibleNodeLabels_.getByteString(i));
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBytes(9, getDefaultNodeLabelExpressionBytes());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeMessage(10, queueStatistics_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeBool(11, preemptionDisabled_);
      }
      for (int i = 0; i < queueConfigurationsMap_.size(); i++) {
        output.writeMessage(12, queueConfigurationsMap_.get(i));
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeBool(13, intraQueuePreemptionDisabled_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getQueueNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(2, capacity_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(3, maximumCapacity_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(4, currentCapacity_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(5, state_.getNumber());
      }
      for (int i = 0; i < childQueues_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, childQueues_.get(i));
      }
      for (int i = 0; i < applications_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, applications_.get(i));
      }
      {
        int dataSize = 0;
        for (int i = 0; i < accessibleNodeLabels_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(accessibleNodeLabels_.getByteString(i));
        }
        size += dataSize;
        size += 1 * getAccessibleNodeLabelsList().size();
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(9, getDefaultNodeLabelExpressionBytes());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, queueStatistics_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(11, preemptionDisabled_);
      }
      for (int i = 0; i < queueConfigurationsMap_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, queueConfigurationsMap_.get(i));
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(13, intraQueuePreemptionDisabled_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto other = (org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto) obj;

      boolean result = true;
      result = result && (hasQueueName() == other.hasQueueName());
      if (hasQueueName()) {
        result = result && getQueueName()
            .equals(other.getQueueName());
      }
      result = result && (hasCapacity() == other.hasCapacity());
      if (hasCapacity()) {
        result = result && (Float.floatToIntBits(getCapacity())    == Float.floatToIntBits(other.getCapacity()));
      }
      result = result && (hasMaximumCapacity() == other.hasMaximumCapacity());
      if (hasMaximumCapacity()) {
        result = result && (Float.floatToIntBits(getMaximumCapacity())    == Float.floatToIntBits(other.getMaximumCapacity()));
      }
      result = result && (hasCurrentCapacity() == other.hasCurrentCapacity());
      if (hasCurrentCapacity()) {
        result = result && (Float.floatToIntBits(getCurrentCapacity())    == Float.floatToIntBits(other.getCurrentCapacity()));
      }
      result = result && (hasState() == other.hasState());
      if (hasState()) {
        result = result &&
            (getState() == other.getState());
      }
      result = result && getChildQueuesList()
          .equals(other.getChildQueuesList());
      result = result && getApplicationsList()
          .equals(other.getApplicationsList());
      result = result && getAccessibleNodeLabelsList()
          .equals(other.getAccessibleNodeLabelsList());
      result = result && (hasDefaultNodeLabelExpression() == other.hasDefaultNodeLabelExpression());
      if (hasDefaultNodeLabelExpression()) {
        result = result && getDefaultNodeLabelExpression()
            .equals(other.getDefaultNodeLabelExpression());
      }
      result = result && (hasQueueStatistics() == other.hasQueueStatistics());
      if (hasQueueStatistics()) {
        result = result && getQueueStatistics()
            .equals(other.getQueueStatistics());
      }
      result = result && (hasPreemptionDisabled() == other.hasPreemptionDisabled());
      if (hasPreemptionDisabled()) {
        result = result && (getPreemptionDisabled()
            == other.getPreemptionDisabled());
      }
      result = result && getQueueConfigurationsMapList()
          .equals(other.getQueueConfigurationsMapList());
      result = result && (hasIntraQueuePreemptionDisabled() == other.hasIntraQueuePreemptionDisabled());
      if (hasIntraQueuePreemptionDisabled()) {
        result = result && (getIntraQueuePreemptionDisabled()
            == other.getIntraQueuePreemptionDisabled());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQueueName()) {
        hash = (37 * hash) + QUEUENAME_FIELD_NUMBER;
        hash = (53 * hash) + getQueueName().hashCode();
      }
      if (hasCapacity()) {
        hash = (37 * hash) + CAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getCapacity());
      }
      if (hasMaximumCapacity()) {
        hash = (37 * hash) + MAXIMUMCAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getMaximumCapacity());
      }
      if (hasCurrentCapacity()) {
        hash = (37 * hash) + CURRENTCAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getCurrentCapacity());
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getState());
      }
      if (getChildQueuesCount() > 0) {
        hash = (37 * hash) + CHILDQUEUES_FIELD_NUMBER;
        hash = (53 * hash) + getChildQueuesList().hashCode();
      }
      if (getApplicationsCount() > 0) {
        hash = (37 * hash) + APPLICATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationsList().hashCode();
      }
      if (getAccessibleNodeLabelsCount() > 0) {
        hash = (37 * hash) + ACCESSIBLENODELABELS_FIELD_NUMBER;
        hash = (53 * hash) + getAccessibleNodeLabelsList().hashCode();
      }
      if (hasDefaultNodeLabelExpression()) {
        hash = (37 * hash) + DEFAULTNODELABELEXPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + getDefaultNodeLabelExpression().hashCode();
      }
      if (hasQueueStatistics()) {
        hash = (37 * hash) + QUEUESTATISTICS_FIELD_NUMBER;
        hash = (53 * hash) + getQueueStatistics().hashCode();
      }
      if (hasPreemptionDisabled()) {
        hash = (37 * hash) + PREEMPTIONDISABLED_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getPreemptionDisabled());
      }
      if (getQueueConfigurationsMapCount() > 0) {
        hash = (37 * hash) + QUEUECONFIGURATIONSMAP_FIELD_NUMBER;
        hash = (53 * hash) + getQueueConfigurationsMapList().hashCode();
      }
      if (hasIntraQueuePreemptionDisabled()) {
        hash = (37 * hash) + INTRAQUEUEPREEMPTIONDISABLED_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getIntraQueuePreemptionDisabled());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.QueueInfoProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getChildQueuesFieldBuilder();
          getApplicationsFieldBuilder();
          getQueueStatisticsFieldBuilder();
          getQueueConfigurationsMapFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        queueName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        capacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000002);
        maximumCapacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000004);
        currentCapacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000008);
        state_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.Q_STOPPED;
        bitField0_ = (bitField0_ & ~0x00000010);
        if (childQueuesBuilder_ == null) {
          childQueues_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          childQueuesBuilder_.clear();
        }
        if (applicationsBuilder_ == null) {
          applications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
        } else {
          applicationsBuilder_.clear();
        }
        accessibleNodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000080);
        defaultNodeLabelExpression_ = "";
        bitField0_ = (bitField0_ & ~0x00000100);
        if (queueStatisticsBuilder_ == null) {
          queueStatistics_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.getDefaultInstance();
        } else {
          queueStatisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000200);
        preemptionDisabled_ = false;
        bitField0_ = (bitField0_ & ~0x00000400);
        if (queueConfigurationsMapBuilder_ == null) {
          queueConfigurationsMap_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000800);
        } else {
          queueConfigurationsMapBuilder_.clear();
        }
        intraQueuePreemptionDisabled_ = false;
        bitField0_ = (bitField0_ & ~0x00001000);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto result = new org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.queueName_ = queueName_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.capacity_ = capacity_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.maximumCapacity_ = maximumCapacity_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.currentCapacity_ = currentCapacity_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.state_ = state_;
        if (childQueuesBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            childQueues_ = java.util.Collections.unmodifiableList(childQueues_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.childQueues_ = childQueues_;
        } else {
          result.childQueues_ = childQueuesBuilder_.build();
        }
        if (applicationsBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040)) {
            applications_ = java.util.Collections.unmodifiableList(applications_);
            bitField0_ = (bitField0_ & ~0x00000040);
          }
          result.applications_ = applications_;
        } else {
          result.applications_ = applicationsBuilder_.build();
        }
        if (((bitField0_ & 0x00000080) == 0x00000080)) {
          accessibleNodeLabels_ = new com.google.protobuf.UnmodifiableLazyStringList(
              accessibleNodeLabels_);
          bitField0_ = (bitField0_ & ~0x00000080);
        }
        result.accessibleNodeLabels_ = accessibleNodeLabels_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000020;
        }
        result.defaultNodeLabelExpression_ = defaultNodeLabelExpression_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000040;
        }
        if (queueStatisticsBuilder_ == null) {
          result.queueStatistics_ = queueStatistics_;
        } else {
          result.queueStatistics_ = queueStatisticsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000080;
        }
        result.preemptionDisabled_ = preemptionDisabled_;
        if (queueConfigurationsMapBuilder_ == null) {
          if (((bitField0_ & 0x00000800) == 0x00000800)) {
            queueConfigurationsMap_ = java.util.Collections.unmodifiableList(queueConfigurationsMap_);
            bitField0_ = (bitField0_ & ~0x00000800);
          }
          result.queueConfigurationsMap_ = queueConfigurationsMap_;
        } else {
          result.queueConfigurationsMap_ = queueConfigurationsMapBuilder_.build();
        }
        if (((from_bitField0_ & 0x00001000) == 0x00001000)) {
          to_bitField0_ |= 0x00000100;
        }
        result.intraQueuePreemptionDisabled_ = intraQueuePreemptionDisabled_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance()) return this;
        if (other.hasQueueName()) {
          bitField0_ |= 0x00000001;
          queueName_ = other.queueName_;
          onChanged();
        }
        if (other.hasCapacity()) {
          setCapacity(other.getCapacity());
        }
        if (other.hasMaximumCapacity()) {
          setMaximumCapacity(other.getMaximumCapacity());
        }
        if (other.hasCurrentCapacity()) {
          setCurrentCapacity(other.getCurrentCapacity());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (childQueuesBuilder_ == null) {
          if (!other.childQueues_.isEmpty()) {
            if (childQueues_.isEmpty()) {
              childQueues_ = other.childQueues_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureChildQueuesIsMutable();
              childQueues_.addAll(other.childQueues_);
            }
            onChanged();
          }
        } else {
          if (!other.childQueues_.isEmpty()) {
            if (childQueuesBuilder_.isEmpty()) {
              childQueuesBuilder_.dispose();
              childQueuesBuilder_ = null;
              childQueues_ = other.childQueues_;
              bitField0_ = (bitField0_ & ~0x00000020);
              childQueuesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getChildQueuesFieldBuilder() : null;
            } else {
              childQueuesBuilder_.addAllMessages(other.childQueues_);
            }
          }
        }
        if (applicationsBuilder_ == null) {
          if (!other.applications_.isEmpty()) {
            if (applications_.isEmpty()) {
              applications_ = other.applications_;
              bitField0_ = (bitField0_ & ~0x00000040);
            } else {
              ensureApplicationsIsMutable();
              applications_.addAll(other.applications_);
            }
            onChanged();
          }
        } else {
          if (!other.applications_.isEmpty()) {
            if (applicationsBuilder_.isEmpty()) {
              applicationsBuilder_.dispose();
              applicationsBuilder_ = null;
              applications_ = other.applications_;
              bitField0_ = (bitField0_ & ~0x00000040);
              applicationsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getApplicationsFieldBuilder() : null;
            } else {
              applicationsBuilder_.addAllMessages(other.applications_);
            }
          }
        }
        if (!other.accessibleNodeLabels_.isEmpty()) {
          if (accessibleNodeLabels_.isEmpty()) {
            accessibleNodeLabels_ = other.accessibleNodeLabels_;
            bitField0_ = (bitField0_ & ~0x00000080);
          } else {
            ensureAccessibleNodeLabelsIsMutable();
            accessibleNodeLabels_.addAll(other.accessibleNodeLabels_);
          }
          onChanged();
        }
        if (other.hasDefaultNodeLabelExpression()) {
          bitField0_ |= 0x00000100;
          defaultNodeLabelExpression_ = other.defaultNodeLabelExpression_;
          onChanged();
        }
        if (other.hasQueueStatistics()) {
          mergeQueueStatistics(other.getQueueStatistics());
        }
        if (other.hasPreemptionDisabled()) {
          setPreemptionDisabled(other.getPreemptionDisabled());
        }
        if (queueConfigurationsMapBuilder_ == null) {
          if (!other.queueConfigurationsMap_.isEmpty()) {
            if (queueConfigurationsMap_.isEmpty()) {
              queueConfigurationsMap_ = other.queueConfigurationsMap_;
              bitField0_ = (bitField0_ & ~0x00000800);
            } else {
              ensureQueueConfigurationsMapIsMutable();
              queueConfigurationsMap_.addAll(other.queueConfigurationsMap_);
            }
            onChanged();
          }
        } else {
          if (!other.queueConfigurationsMap_.isEmpty()) {
            if (queueConfigurationsMapBuilder_.isEmpty()) {
              queueConfigurationsMapBuilder_.dispose();
              queueConfigurationsMapBuilder_ = null;
              queueConfigurationsMap_ = other.queueConfigurationsMap_;
              bitField0_ = (bitField0_ & ~0x00000800);
              queueConfigurationsMapBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getQueueConfigurationsMapFieldBuilder() : null;
            } else {
              queueConfigurationsMapBuilder_.addAllMessages(other.queueConfigurationsMap_);
            }
          }
        }
        if (other.hasIntraQueuePreemptionDisabled()) {
          setIntraQueuePreemptionDisabled(other.getIntraQueuePreemptionDisabled());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getChildQueuesCount(); i++) {
          if (!getChildQueues(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getApplicationsCount(); i++) {
          if (!getApplications(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getQueueConfigurationsMapCount(); i++) {
          if (!getQueueConfigurationsMap(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string queueName = 1;
      private java.lang.Object queueName_ = "";
      /**
       * <code>optional string queueName = 1;</code>
       */
      public boolean hasQueueName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public java.lang.String getQueueName() {
        java.lang.Object ref = queueName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          queueName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public com.google.protobuf.ByteString
          getQueueNameBytes() {
        java.lang.Object ref = queueName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queueName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder clearQueueName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        queueName_ = getDefaultInstance().getQueueName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }

      // optional float capacity = 2;
      private float capacity_ ;
      /**
       * <code>optional float capacity = 2;</code>
       */
      public boolean hasCapacity() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional float capacity = 2;</code>
       */
      public float getCapacity() {
        return capacity_;
      }
      /**
       * <code>optional float capacity = 2;</code>
       */
      public Builder setCapacity(float value) {
        bitField0_ |= 0x00000002;
        capacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float capacity = 2;</code>
       */
      public Builder clearCapacity() {
        bitField0_ = (bitField0_ & ~0x00000002);
        capacity_ = 0F;
        onChanged();
        return this;
      }

      // optional float maximumCapacity = 3;
      private float maximumCapacity_ ;
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public boolean hasMaximumCapacity() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public float getMaximumCapacity() {
        return maximumCapacity_;
      }
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public Builder setMaximumCapacity(float value) {
        bitField0_ |= 0x00000004;
        maximumCapacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public Builder clearMaximumCapacity() {
        bitField0_ = (bitField0_ & ~0x00000004);
        maximumCapacity_ = 0F;
        onChanged();
        return this;
      }

      // optional float currentCapacity = 4;
      private float currentCapacity_ ;
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public boolean hasCurrentCapacity() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public float getCurrentCapacity() {
        return currentCapacity_;
      }
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public Builder setCurrentCapacity(float value) {
        bitField0_ |= 0x00000008;
        currentCapacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public Builder clearCurrentCapacity() {
        bitField0_ = (bitField0_ & ~0x00000008);
        currentCapacity_ = 0F;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.QueueStateProto state = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto state_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.Q_STOPPED;
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public boolean hasState() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto getState() {
        return state_;
      }
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public Builder setState(org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000010;
        state_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000010);
        state_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.Q_STOPPED;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.QueueInfoProto childQueues = 6;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> childQueues_ =
        java.util.Collections.emptyList();
      private void ensureChildQueuesIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          childQueues_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto>(childQueues_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> childQueuesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> getChildQueuesList() {
        if (childQueuesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(childQueues_);
        } else {
          return childQueuesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public int getChildQueuesCount() {
        if (childQueuesBuilder_ == null) {
          return childQueues_.size();
        } else {
          return childQueuesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getChildQueues(int index) {
        if (childQueuesBuilder_ == null) {
          return childQueues_.get(index);
        } else {
          return childQueuesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder setChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (childQueuesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildQueuesIsMutable();
          childQueues_.set(index, value);
          onChanged();
        } else {
          childQueuesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder setChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder builderForValue) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.set(index, builderForValue.build());
          onChanged();
        } else {
          childQueuesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (childQueuesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildQueuesIsMutable();
          childQueues_.add(value);
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (childQueuesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildQueuesIsMutable();
          childQueues_.add(index, value);
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder builderForValue) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.add(builderForValue.build());
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder builderForValue) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.add(index, builderForValue.build());
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addAllChildQueues(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> values) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          super.addAll(values, childQueues_);
          onChanged();
        } else {
          childQueuesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder clearChildQueues() {
        if (childQueuesBuilder_ == null) {
          childQueues_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          childQueuesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder removeChildQueues(int index) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.remove(index);
          onChanged();
        } else {
          childQueuesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder getChildQueuesBuilder(
          int index) {
        return getChildQueuesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getChildQueuesOrBuilder(
          int index) {
        if (childQueuesBuilder_ == null) {
          return childQueues_.get(index);  } else {
          return childQueuesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
           getChildQueuesOrBuilderList() {
        if (childQueuesBuilder_ != null) {
          return childQueuesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(childQueues_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder addChildQueuesBuilder() {
        return getChildQueuesFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder addChildQueuesBuilder(
          int index) {
        return getChildQueuesFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder> 
           getChildQueuesBuilderList() {
        return getChildQueuesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
          getChildQueuesFieldBuilder() {
        if (childQueuesBuilder_ == null) {
          childQueuesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder>(
                  childQueues_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          childQueues_ = null;
        }
        return childQueuesBuilder_;
      }

      // repeated .hadoop.yarn.ApplicationReportProto applications = 7;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> applications_ =
        java.util.Collections.emptyList();
      private void ensureApplicationsIsMutable() {
        if (!((bitField0_ & 0x00000040) == 0x00000040)) {
          applications_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto>(applications_);
          bitField0_ |= 0x00000040;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> applicationsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> getApplicationsList() {
        if (applicationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applications_);
        } else {
          return applicationsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public int getApplicationsCount() {
        if (applicationsBuilder_ == null) {
          return applications_.size();
        } else {
          return applicationsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index) {
        if (applicationsBuilder_ == null) {
          return applications_.get(index);
        } else {
          return applicationsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder setApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.set(index, value);
          onChanged();
        } else {
          applicationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder setApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.add(value);
          onChanged();
        } else {
          applicationsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.add(index, value);
          onChanged();
        } else {
          applicationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.add(builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addAllApplications(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> values) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          super.addAll(values, applications_);
          onChanged();
        } else {
          applicationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder clearApplications() {
        if (applicationsBuilder_ == null) {
          applications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
          onChanged();
        } else {
          applicationsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder removeApplications(int index) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.remove(index);
          onChanged();
        } else {
          applicationsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder getApplicationsBuilder(
          int index) {
        return getApplicationsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
          int index) {
        if (applicationsBuilder_ == null) {
          return applications_.get(index);  } else {
          return applicationsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
           getApplicationsOrBuilderList() {
        if (applicationsBuilder_ != null) {
          return applicationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applications_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder addApplicationsBuilder() {
        return getApplicationsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder addApplicationsBuilder(
          int index) {
        return getApplicationsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder> 
           getApplicationsBuilderList() {
        return getApplicationsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
          getApplicationsFieldBuilder() {
        if (applicationsBuilder_ == null) {
          applicationsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder>(
                  applications_,
                  ((bitField0_ & 0x00000040) == 0x00000040),
                  getParentForChildren(),
                  isClean());
          applications_ = null;
        }
        return applicationsBuilder_;
      }

      // repeated string accessibleNodeLabels = 8;
      private com.google.protobuf.LazyStringList accessibleNodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureAccessibleNodeLabelsIsMutable() {
        if (!((bitField0_ & 0x00000080) == 0x00000080)) {
          accessibleNodeLabels_ = new com.google.protobuf.LazyStringArrayList(accessibleNodeLabels_);
          bitField0_ |= 0x00000080;
         }
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public java.util.List<java.lang.String>
          getAccessibleNodeLabelsList() {
        return java.util.Collections.unmodifiableList(accessibleNodeLabels_);
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public int getAccessibleNodeLabelsCount() {
        return accessibleNodeLabels_.size();
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public java.lang.String getAccessibleNodeLabels(int index) {
        return accessibleNodeLabels_.get(index);
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public com.google.protobuf.ByteString
          getAccessibleNodeLabelsBytes(int index) {
        return accessibleNodeLabels_.getByteString(index);
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public Builder setAccessibleNodeLabels(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureAccessibleNodeLabelsIsMutable();
        accessibleNodeLabels_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public Builder addAccessibleNodeLabels(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureAccessibleNodeLabelsIsMutable();
        accessibleNodeLabels_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public Builder addAllAccessibleNodeLabels(
          java.lang.Iterable<java.lang.String> values) {
        ensureAccessibleNodeLabelsIsMutable();
        super.addAll(values, accessibleNodeLabels_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public Builder clearAccessibleNodeLabels() {
        accessibleNodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000080);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public Builder addAccessibleNodeLabelsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureAccessibleNodeLabelsIsMutable();
        accessibleNodeLabels_.add(value);
        onChanged();
        return this;
      }

      // optional string defaultNodeLabelExpression = 9;
      private java.lang.Object defaultNodeLabelExpression_ = "";
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public boolean hasDefaultNodeLabelExpression() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public java.lang.String getDefaultNodeLabelExpression() {
        java.lang.Object ref = defaultNodeLabelExpression_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          defaultNodeLabelExpression_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public com.google.protobuf.ByteString
          getDefaultNodeLabelExpressionBytes() {
        java.lang.Object ref = defaultNodeLabelExpression_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          defaultNodeLabelExpression_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public Builder setDefaultNodeLabelExpression(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000100;
        defaultNodeLabelExpression_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public Builder clearDefaultNodeLabelExpression() {
        bitField0_ = (bitField0_ & ~0x00000100);
        defaultNodeLabelExpression_ = getDefaultInstance().getDefaultNodeLabelExpression();
        onChanged();
        return this;
      }
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public Builder setDefaultNodeLabelExpressionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000100;
        defaultNodeLabelExpression_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;
      private org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto queueStatistics_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProtoOrBuilder> queueStatisticsBuilder_;
      /**
       * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
       */
      public boolean hasQueueStatistics() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto getQueueStatistics() {
        if (queueStatisticsBuilder_ == null) {
          return queueStatistics_;
        } else {
          return queueStatisticsBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
       */
      public Builder setQueueStatistics(org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto value) {
        if (queueStatisticsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          queueStatistics_ = value;
          onChanged();
        } else {
          queueStatisticsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000200;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
       */
      public Builder setQueueStatistics(
          org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.Builder builderForValue) {
        if (queueStatisticsBuilder_ == null) {
          queueStatistics_ = builderForValue.build();
          onChanged();
        } else {
          queueStatisticsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000200;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
       */
      public Builder mergeQueueStatistics(org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto value) {
        if (queueStatisticsBuilder_ == null) {
          if (((bitField0_ & 0x00000200) == 0x00000200) &&
              queueStatistics_ != org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.getDefaultInstance()) {
            queueStatistics_ =
              org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.newBuilder(queueStatistics_).mergeFrom(value).buildPartial();
          } else {
            queueStatistics_ = value;
          }
          onChanged();
        } else {
          queueStatisticsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000200;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
       */
      public Builder clearQueueStatistics() {
        if (queueStatisticsBuilder_ == null) {
          queueStatistics_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.getDefaultInstance();
          onChanged();
        } else {
          queueStatisticsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000200);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.Builder getQueueStatisticsBuilder() {
        bitField0_ |= 0x00000200;
        onChanged();
        return getQueueStatisticsFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProtoOrBuilder getQueueStatisticsOrBuilder() {
        if (queueStatisticsBuilder_ != null) {
          return queueStatisticsBuilder_.getMessageOrBuilder();
        } else {
          return queueStatistics_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.QueueStatisticsProto queueStatistics = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProtoOrBuilder> 
          getQueueStatisticsFieldBuilder() {
        if (queueStatisticsBuilder_ == null) {
          queueStatisticsBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueStatisticsProtoOrBuilder>(
                  queueStatistics_,
                  getParentForChildren(),
                  isClean());
          queueStatistics_ = null;
        }
        return queueStatisticsBuilder_;
      }

      // optional bool preemptionDisabled = 11;
      private boolean preemptionDisabled_ ;
      /**
       * <code>optional bool preemptionDisabled = 11;</code>
       */
      public boolean hasPreemptionDisabled() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional bool preemptionDisabled = 11;</code>
       */
      public boolean getPreemptionDisabled() {
        return preemptionDisabled_;
      }
      /**
       * <code>optional bool preemptionDisabled = 11;</code>
       */
      public Builder setPreemptionDisabled(boolean value) {
        bitField0_ |= 0x00000400;
        preemptionDisabled_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool preemptionDisabled = 11;</code>
       */
      public Builder clearPreemptionDisabled() {
        bitField0_ = (bitField0_ & ~0x00000400);
        preemptionDisabled_ = false;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto> queueConfigurationsMap_ =
        java.util.Collections.emptyList();
      private void ensureQueueConfigurationsMapIsMutable() {
        if (!((bitField0_ & 0x00000800) == 0x00000800)) {
          queueConfigurationsMap_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto>(queueConfigurationsMap_);
          bitField0_ |= 0x00000800;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProtoOrBuilder> queueConfigurationsMapBuilder_;

      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto> getQueueConfigurationsMapList() {
        if (queueConfigurationsMapBuilder_ == null) {
          return java.util.Collections.unmodifiableList(queueConfigurationsMap_);
        } else {
          return queueConfigurationsMapBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public int getQueueConfigurationsMapCount() {
        if (queueConfigurationsMapBuilder_ == null) {
          return queueConfigurationsMap_.size();
        } else {
          return queueConfigurationsMapBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto getQueueConfigurationsMap(int index) {
        if (queueConfigurationsMapBuilder_ == null) {
          return queueConfigurationsMap_.get(index);
        } else {
          return queueConfigurationsMapBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public Builder setQueueConfigurationsMap(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto value) {
        if (queueConfigurationsMapBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureQueueConfigurationsMapIsMutable();
          queueConfigurationsMap_.set(index, value);
          onChanged();
        } else {
          queueConfigurationsMapBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public Builder setQueueConfigurationsMap(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder builderForValue) {
        if (queueConfigurationsMapBuilder_ == null) {
          ensureQueueConfigurationsMapIsMutable();
          queueConfigurationsMap_.set(index, builderForValue.build());
          onChanged();
        } else {
          queueConfigurationsMapBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public Builder addQueueConfigurationsMap(org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto value) {
        if (queueConfigurationsMapBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureQueueConfigurationsMapIsMutable();
          queueConfigurationsMap_.add(value);
          onChanged();
        } else {
          queueConfigurationsMapBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public Builder addQueueConfigurationsMap(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto value) {
        if (queueConfigurationsMapBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureQueueConfigurationsMapIsMutable();
          queueConfigurationsMap_.add(index, value);
          onChanged();
        } else {
          queueConfigurationsMapBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public Builder addQueueConfigurationsMap(
          org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder builderForValue) {
        if (queueConfigurationsMapBuilder_ == null) {
          ensureQueueConfigurationsMapIsMutable();
          queueConfigurationsMap_.add(builderForValue.build());
          onChanged();
        } else {
          queueConfigurationsMapBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public Builder addQueueConfigurationsMap(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder builderForValue) {
        if (queueConfigurationsMapBuilder_ == null) {
          ensureQueueConfigurationsMapIsMutable();
          queueConfigurationsMap_.add(index, builderForValue.build());
          onChanged();
        } else {
          queueConfigurationsMapBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public Builder addAllQueueConfigurationsMap(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto> values) {
        if (queueConfigurationsMapBuilder_ == null) {
          ensureQueueConfigurationsMapIsMutable();
          super.addAll(values, queueConfigurationsMap_);
          onChanged();
        } else {
          queueConfigurationsMapBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public Builder clearQueueConfigurationsMap() {
        if (queueConfigurationsMapBuilder_ == null) {
          queueConfigurationsMap_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000800);
          onChanged();
        } else {
          queueConfigurationsMapBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public Builder removeQueueConfigurationsMap(int index) {
        if (queueConfigurationsMapBuilder_ == null) {
          ensureQueueConfigurationsMapIsMutable();
          queueConfigurationsMap_.remove(index);
          onChanged();
        } else {
          queueConfigurationsMapBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder getQueueConfigurationsMapBuilder(
          int index) {
        return getQueueConfigurationsMapFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProtoOrBuilder getQueueConfigurationsMapOrBuilder(
          int index) {
        if (queueConfigurationsMapBuilder_ == null) {
          return queueConfigurationsMap_.get(index);  } else {
          return queueConfigurationsMapBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProtoOrBuilder> 
           getQueueConfigurationsMapOrBuilderList() {
        if (queueConfigurationsMapBuilder_ != null) {
          return queueConfigurationsMapBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(queueConfigurationsMap_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder addQueueConfigurationsMapBuilder() {
        return getQueueConfigurationsMapFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder addQueueConfigurationsMapBuilder(
          int index) {
        return getQueueConfigurationsMapFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.QueueConfigurationsMapProto queueConfigurationsMap = 12;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder> 
           getQueueConfigurationsMapBuilderList() {
        return getQueueConfigurationsMapFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProtoOrBuilder> 
          getQueueConfigurationsMapFieldBuilder() {
        if (queueConfigurationsMapBuilder_ == null) {
          queueConfigurationsMapBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProtoOrBuilder>(
                  queueConfigurationsMap_,
                  ((bitField0_ & 0x00000800) == 0x00000800),
                  getParentForChildren(),
                  isClean());
          queueConfigurationsMap_ = null;
        }
        return queueConfigurationsMapBuilder_;
      }

      // optional bool intraQueuePreemptionDisabled = 13;
      private boolean intraQueuePreemptionDisabled_ ;
      /**
       * <code>optional bool intraQueuePreemptionDisabled = 13;</code>
       */
      public boolean hasIntraQueuePreemptionDisabled() {
        return ((bitField0_ & 0x00001000) == 0x00001000);
      }
      /**
       * <code>optional bool intraQueuePreemptionDisabled = 13;</code>
       */
      public boolean getIntraQueuePreemptionDisabled() {
        return intraQueuePreemptionDisabled_;
      }
      /**
       * <code>optional bool intraQueuePreemptionDisabled = 13;</code>
       */
      public Builder setIntraQueuePreemptionDisabled(boolean value) {
        bitField0_ |= 0x00001000;
        intraQueuePreemptionDisabled_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool intraQueuePreemptionDisabled = 13;</code>
       */
      public Builder clearIntraQueuePreemptionDisabled() {
        bitField0_ = (bitField0_ & ~0x00001000);
        intraQueuePreemptionDisabled_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.QueueInfoProto)
    }

    static {
      defaultInstance = new QueueInfoProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.QueueInfoProto)
  }

  public interface QueueConfigurationsProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional float capacity = 1;
    /**
     * <code>optional float capacity = 1;</code>
     */
    boolean hasCapacity();
    /**
     * <code>optional float capacity = 1;</code>
     */
    float getCapacity();

    // optional float absoluteCapacity = 2;
    /**
     * <code>optional float absoluteCapacity = 2;</code>
     */
    boolean hasAbsoluteCapacity();
    /**
     * <code>optional float absoluteCapacity = 2;</code>
     */
    float getAbsoluteCapacity();

    // optional float maxCapacity = 3;
    /**
     * <code>optional float maxCapacity = 3;</code>
     */
    boolean hasMaxCapacity();
    /**
     * <code>optional float maxCapacity = 3;</code>
     */
    float getMaxCapacity();

    // optional float absoluteMaxCapacity = 4;
    /**
     * <code>optional float absoluteMaxCapacity = 4;</code>
     */
    boolean hasAbsoluteMaxCapacity();
    /**
     * <code>optional float absoluteMaxCapacity = 4;</code>
     */
    float getAbsoluteMaxCapacity();

    // optional float maxAMPercentage = 5;
    /**
     * <code>optional float maxAMPercentage = 5;</code>
     */
    boolean hasMaxAMPercentage();
    /**
     * <code>optional float maxAMPercentage = 5;</code>
     */
    float getMaxAMPercentage();
  }
  /**
   * Protobuf type {@code hadoop.yarn.QueueConfigurationsProto}
   */
  public static final class QueueConfigurationsProto extends
      com.google.protobuf.GeneratedMessage
      implements QueueConfigurationsProtoOrBuilder {
    // Use QueueConfigurationsProto.newBuilder() to construct.
    private QueueConfigurationsProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private QueueConfigurationsProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final QueueConfigurationsProto defaultInstance;
    public static QueueConfigurationsProto getDefaultInstance() {
      return defaultInstance;
    }

    public QueueConfigurationsProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private QueueConfigurationsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 13: {
              bitField0_ |= 0x00000001;
              capacity_ = input.readFloat();
              break;
            }
            case 21: {
              bitField0_ |= 0x00000002;
              absoluteCapacity_ = input.readFloat();
              break;
            }
            case 29: {
              bitField0_ |= 0x00000004;
              maxCapacity_ = input.readFloat();
              break;
            }
            case 37: {
              bitField0_ |= 0x00000008;
              absoluteMaxCapacity_ = input.readFloat();
              break;
            }
            case 45: {
              bitField0_ |= 0x00000010;
              maxAMPercentage_ = input.readFloat();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueConfigurationsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueConfigurationsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.Builder.class);
    }

    public static com.google.protobuf.Parser<QueueConfigurationsProto> PARSER =
        new com.google.protobuf.AbstractParser<QueueConfigurationsProto>() {
      public QueueConfigurationsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new QueueConfigurationsProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<QueueConfigurationsProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional float capacity = 1;
    public static final int CAPACITY_FIELD_NUMBER = 1;
    private float capacity_;
    /**
     * <code>optional float capacity = 1;</code>
     */
    public boolean hasCapacity() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional float capacity = 1;</code>
     */
    public float getCapacity() {
      return capacity_;
    }

    // optional float absoluteCapacity = 2;
    public static final int ABSOLUTECAPACITY_FIELD_NUMBER = 2;
    private float absoluteCapacity_;
    /**
     * <code>optional float absoluteCapacity = 2;</code>
     */
    public boolean hasAbsoluteCapacity() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional float absoluteCapacity = 2;</code>
     */
    public float getAbsoluteCapacity() {
      return absoluteCapacity_;
    }

    // optional float maxCapacity = 3;
    public static final int MAXCAPACITY_FIELD_NUMBER = 3;
    private float maxCapacity_;
    /**
     * <code>optional float maxCapacity = 3;</code>
     */
    public boolean hasMaxCapacity() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional float maxCapacity = 3;</code>
     */
    public float getMaxCapacity() {
      return maxCapacity_;
    }

    // optional float absoluteMaxCapacity = 4;
    public static final int ABSOLUTEMAXCAPACITY_FIELD_NUMBER = 4;
    private float absoluteMaxCapacity_;
    /**
     * <code>optional float absoluteMaxCapacity = 4;</code>
     */
    public boolean hasAbsoluteMaxCapacity() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional float absoluteMaxCapacity = 4;</code>
     */
    public float getAbsoluteMaxCapacity() {
      return absoluteMaxCapacity_;
    }

    // optional float maxAMPercentage = 5;
    public static final int MAXAMPERCENTAGE_FIELD_NUMBER = 5;
    private float maxAMPercentage_;
    /**
     * <code>optional float maxAMPercentage = 5;</code>
     */
    public boolean hasMaxAMPercentage() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional float maxAMPercentage = 5;</code>
     */
    public float getMaxAMPercentage() {
      return maxAMPercentage_;
    }

    private void initFields() {
      capacity_ = 0F;
      absoluteCapacity_ = 0F;
      maxCapacity_ = 0F;
      absoluteMaxCapacity_ = 0F;
      maxAMPercentage_ = 0F;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeFloat(1, capacity_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeFloat(2, absoluteCapacity_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeFloat(3, maxCapacity_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeFloat(4, absoluteMaxCapacity_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeFloat(5, maxAMPercentage_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(1, capacity_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(2, absoluteCapacity_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(3, maxCapacity_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(4, absoluteMaxCapacity_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(5, maxAMPercentage_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto other = (org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto) obj;

      boolean result = true;
      result = result && (hasCapacity() == other.hasCapacity());
      if (hasCapacity()) {
        result = result && (Float.floatToIntBits(getCapacity())    == Float.floatToIntBits(other.getCapacity()));
      }
      result = result && (hasAbsoluteCapacity() == other.hasAbsoluteCapacity());
      if (hasAbsoluteCapacity()) {
        result = result && (Float.floatToIntBits(getAbsoluteCapacity())    == Float.floatToIntBits(other.getAbsoluteCapacity()));
      }
      result = result && (hasMaxCapacity() == other.hasMaxCapacity());
      if (hasMaxCapacity()) {
        result = result && (Float.floatToIntBits(getMaxCapacity())    == Float.floatToIntBits(other.getMaxCapacity()));
      }
      result = result && (hasAbsoluteMaxCapacity() == other.hasAbsoluteMaxCapacity());
      if (hasAbsoluteMaxCapacity()) {
        result = result && (Float.floatToIntBits(getAbsoluteMaxCapacity())    == Float.floatToIntBits(other.getAbsoluteMaxCapacity()));
      }
      result = result && (hasMaxAMPercentage() == other.hasMaxAMPercentage());
      if (hasMaxAMPercentage()) {
        result = result && (Float.floatToIntBits(getMaxAMPercentage())    == Float.floatToIntBits(other.getMaxAMPercentage()));
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasCapacity()) {
        hash = (37 * hash) + CAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getCapacity());
      }
      if (hasAbsoluteCapacity()) {
        hash = (37 * hash) + ABSOLUTECAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getAbsoluteCapacity());
      }
      if (hasMaxCapacity()) {
        hash = (37 * hash) + MAXCAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getMaxCapacity());
      }
      if (hasAbsoluteMaxCapacity()) {
        hash = (37 * hash) + ABSOLUTEMAXCAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getAbsoluteMaxCapacity());
      }
      if (hasMaxAMPercentage()) {
        hash = (37 * hash) + MAXAMPERCENTAGE_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getMaxAMPercentage());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.QueueConfigurationsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueConfigurationsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueConfigurationsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        capacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000001);
        absoluteCapacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000002);
        maxCapacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000004);
        absoluteMaxCapacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000008);
        maxAMPercentage_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueConfigurationsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto result = new org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.capacity_ = capacity_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.absoluteCapacity_ = absoluteCapacity_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.maxCapacity_ = maxCapacity_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.absoluteMaxCapacity_ = absoluteMaxCapacity_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.maxAMPercentage_ = maxAMPercentage_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.getDefaultInstance()) return this;
        if (other.hasCapacity()) {
          setCapacity(other.getCapacity());
        }
        if (other.hasAbsoluteCapacity()) {
          setAbsoluteCapacity(other.getAbsoluteCapacity());
        }
        if (other.hasMaxCapacity()) {
          setMaxCapacity(other.getMaxCapacity());
        }
        if (other.hasAbsoluteMaxCapacity()) {
          setAbsoluteMaxCapacity(other.getAbsoluteMaxCapacity());
        }
        if (other.hasMaxAMPercentage()) {
          setMaxAMPercentage(other.getMaxAMPercentage());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional float capacity = 1;
      private float capacity_ ;
      /**
       * <code>optional float capacity = 1;</code>
       */
      public boolean hasCapacity() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional float capacity = 1;</code>
       */
      public float getCapacity() {
        return capacity_;
      }
      /**
       * <code>optional float capacity = 1;</code>
       */
      public Builder setCapacity(float value) {
        bitField0_ |= 0x00000001;
        capacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float capacity = 1;</code>
       */
      public Builder clearCapacity() {
        bitField0_ = (bitField0_ & ~0x00000001);
        capacity_ = 0F;
        onChanged();
        return this;
      }

      // optional float absoluteCapacity = 2;
      private float absoluteCapacity_ ;
      /**
       * <code>optional float absoluteCapacity = 2;</code>
       */
      public boolean hasAbsoluteCapacity() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional float absoluteCapacity = 2;</code>
       */
      public float getAbsoluteCapacity() {
        return absoluteCapacity_;
      }
      /**
       * <code>optional float absoluteCapacity = 2;</code>
       */
      public Builder setAbsoluteCapacity(float value) {
        bitField0_ |= 0x00000002;
        absoluteCapacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float absoluteCapacity = 2;</code>
       */
      public Builder clearAbsoluteCapacity() {
        bitField0_ = (bitField0_ & ~0x00000002);
        absoluteCapacity_ = 0F;
        onChanged();
        return this;
      }

      // optional float maxCapacity = 3;
      private float maxCapacity_ ;
      /**
       * <code>optional float maxCapacity = 3;</code>
       */
      public boolean hasMaxCapacity() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional float maxCapacity = 3;</code>
       */
      public float getMaxCapacity() {
        return maxCapacity_;
      }
      /**
       * <code>optional float maxCapacity = 3;</code>
       */
      public Builder setMaxCapacity(float value) {
        bitField0_ |= 0x00000004;
        maxCapacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float maxCapacity = 3;</code>
       */
      public Builder clearMaxCapacity() {
        bitField0_ = (bitField0_ & ~0x00000004);
        maxCapacity_ = 0F;
        onChanged();
        return this;
      }

      // optional float absoluteMaxCapacity = 4;
      private float absoluteMaxCapacity_ ;
      /**
       * <code>optional float absoluteMaxCapacity = 4;</code>
       */
      public boolean hasAbsoluteMaxCapacity() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional float absoluteMaxCapacity = 4;</code>
       */
      public float getAbsoluteMaxCapacity() {
        return absoluteMaxCapacity_;
      }
      /**
       * <code>optional float absoluteMaxCapacity = 4;</code>
       */
      public Builder setAbsoluteMaxCapacity(float value) {
        bitField0_ |= 0x00000008;
        absoluteMaxCapacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float absoluteMaxCapacity = 4;</code>
       */
      public Builder clearAbsoluteMaxCapacity() {
        bitField0_ = (bitField0_ & ~0x00000008);
        absoluteMaxCapacity_ = 0F;
        onChanged();
        return this;
      }

      // optional float maxAMPercentage = 5;
      private float maxAMPercentage_ ;
      /**
       * <code>optional float maxAMPercentage = 5;</code>
       */
      public boolean hasMaxAMPercentage() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional float maxAMPercentage = 5;</code>
       */
      public float getMaxAMPercentage() {
        return maxAMPercentage_;
      }
      /**
       * <code>optional float maxAMPercentage = 5;</code>
       */
      public Builder setMaxAMPercentage(float value) {
        bitField0_ |= 0x00000010;
        maxAMPercentage_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float maxAMPercentage = 5;</code>
       */
      public Builder clearMaxAMPercentage() {
        bitField0_ = (bitField0_ & ~0x00000010);
        maxAMPercentage_ = 0F;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.QueueConfigurationsProto)
    }

    static {
      defaultInstance = new QueueConfigurationsProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.QueueConfigurationsProto)
  }

  public interface QueueConfigurationsMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required string partitionName = 1;
    /**
     * <code>required string partitionName = 1;</code>
     */
    boolean hasPartitionName();
    /**
     * <code>required string partitionName = 1;</code>
     */
    java.lang.String getPartitionName();
    /**
     * <code>required string partitionName = 1;</code>
     */
    com.google.protobuf.ByteString
        getPartitionNameBytes();

    // optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;
    /**
     * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
     */
    boolean hasQueueConfigurations();
    /**
     * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto getQueueConfigurations();
    /**
     * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProtoOrBuilder getQueueConfigurationsOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.QueueConfigurationsMapProto}
   */
  public static final class QueueConfigurationsMapProto extends
      com.google.protobuf.GeneratedMessage
      implements QueueConfigurationsMapProtoOrBuilder {
    // Use QueueConfigurationsMapProto.newBuilder() to construct.
    private QueueConfigurationsMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private QueueConfigurationsMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final QueueConfigurationsMapProto defaultInstance;
    public static QueueConfigurationsMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public QueueConfigurationsMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private QueueConfigurationsMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              partitionName_ = input.readBytes();
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = queueConfigurations_.toBuilder();
              }
              queueConfigurations_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(queueConfigurations_);
                queueConfigurations_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueConfigurationsMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueConfigurationsMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<QueueConfigurationsMapProto> PARSER =
        new com.google.protobuf.AbstractParser<QueueConfigurationsMapProto>() {
      public QueueConfigurationsMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new QueueConfigurationsMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<QueueConfigurationsMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required string partitionName = 1;
    public static final int PARTITIONNAME_FIELD_NUMBER = 1;
    private java.lang.Object partitionName_;
    /**
     * <code>required string partitionName = 1;</code>
     */
    public boolean hasPartitionName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string partitionName = 1;</code>
     */
    public java.lang.String getPartitionName() {
      java.lang.Object ref = partitionName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          partitionName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string partitionName = 1;</code>
     */
    public com.google.protobuf.ByteString
        getPartitionNameBytes() {
      java.lang.Object ref = partitionName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        partitionName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;
    public static final int QUEUECONFIGURATIONS_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto queueConfigurations_;
    /**
     * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
     */
    public boolean hasQueueConfigurations() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto getQueueConfigurations() {
      return queueConfigurations_;
    }
    /**
     * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProtoOrBuilder getQueueConfigurationsOrBuilder() {
      return queueConfigurations_;
    }

    private void initFields() {
      partitionName_ = "";
      queueConfigurations_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasPartitionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getPartitionNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, queueConfigurations_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getPartitionNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, queueConfigurations_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto) obj;

      boolean result = true;
      result = result && (hasPartitionName() == other.hasPartitionName());
      if (hasPartitionName()) {
        result = result && getPartitionName()
            .equals(other.getPartitionName());
      }
      result = result && (hasQueueConfigurations() == other.hasQueueConfigurations());
      if (hasQueueConfigurations()) {
        result = result && getQueueConfigurations()
            .equals(other.getQueueConfigurations());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasPartitionName()) {
        hash = (37 * hash) + PARTITIONNAME_FIELD_NUMBER;
        hash = (53 * hash) + getPartitionName().hashCode();
      }
      if (hasQueueConfigurations()) {
        hash = (37 * hash) + QUEUECONFIGURATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getQueueConfigurations().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.QueueConfigurationsMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueConfigurationsMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueConfigurationsMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getQueueConfigurationsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        partitionName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (queueConfigurationsBuilder_ == null) {
          queueConfigurations_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.getDefaultInstance();
        } else {
          queueConfigurationsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueConfigurationsMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.partitionName_ = partitionName_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (queueConfigurationsBuilder_ == null) {
          result.queueConfigurations_ = queueConfigurations_;
        } else {
          result.queueConfigurations_ = queueConfigurationsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto.getDefaultInstance()) return this;
        if (other.hasPartitionName()) {
          bitField0_ |= 0x00000001;
          partitionName_ = other.partitionName_;
          onChanged();
        }
        if (other.hasQueueConfigurations()) {
          mergeQueueConfigurations(other.getQueueConfigurations());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasPartitionName()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required string partitionName = 1;
      private java.lang.Object partitionName_ = "";
      /**
       * <code>required string partitionName = 1;</code>
       */
      public boolean hasPartitionName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string partitionName = 1;</code>
       */
      public java.lang.String getPartitionName() {
        java.lang.Object ref = partitionName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          partitionName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string partitionName = 1;</code>
       */
      public com.google.protobuf.ByteString
          getPartitionNameBytes() {
        java.lang.Object ref = partitionName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          partitionName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string partitionName = 1;</code>
       */
      public Builder setPartitionName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        partitionName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string partitionName = 1;</code>
       */
      public Builder clearPartitionName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        partitionName_ = getDefaultInstance().getPartitionName();
        onChanged();
        return this;
      }
      /**
       * <code>required string partitionName = 1;</code>
       */
      public Builder setPartitionNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        partitionName_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto queueConfigurations_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProtoOrBuilder> queueConfigurationsBuilder_;
      /**
       * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
       */
      public boolean hasQueueConfigurations() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto getQueueConfigurations() {
        if (queueConfigurationsBuilder_ == null) {
          return queueConfigurations_;
        } else {
          return queueConfigurationsBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
       */
      public Builder setQueueConfigurations(org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto value) {
        if (queueConfigurationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          queueConfigurations_ = value;
          onChanged();
        } else {
          queueConfigurationsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
       */
      public Builder setQueueConfigurations(
          org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.Builder builderForValue) {
        if (queueConfigurationsBuilder_ == null) {
          queueConfigurations_ = builderForValue.build();
          onChanged();
        } else {
          queueConfigurationsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
       */
      public Builder mergeQueueConfigurations(org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto value) {
        if (queueConfigurationsBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              queueConfigurations_ != org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.getDefaultInstance()) {
            queueConfigurations_ =
              org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.newBuilder(queueConfigurations_).mergeFrom(value).buildPartial();
          } else {
            queueConfigurations_ = value;
          }
          onChanged();
        } else {
          queueConfigurationsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
       */
      public Builder clearQueueConfigurations() {
        if (queueConfigurationsBuilder_ == null) {
          queueConfigurations_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.getDefaultInstance();
          onChanged();
        } else {
          queueConfigurationsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.Builder getQueueConfigurationsBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getQueueConfigurationsFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProtoOrBuilder getQueueConfigurationsOrBuilder() {
        if (queueConfigurationsBuilder_ != null) {
          return queueConfigurationsBuilder_.getMessageOrBuilder();
        } else {
          return queueConfigurations_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.QueueConfigurationsProto queueConfigurations = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProtoOrBuilder> 
          getQueueConfigurationsFieldBuilder() {
        if (queueConfigurationsBuilder_ == null) {
          queueConfigurationsBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueConfigurationsProtoOrBuilder>(
                  queueConfigurations_,
                  getParentForChildren(),
                  isClean());
          queueConfigurations_ = null;
        }
        return queueConfigurationsBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.QueueConfigurationsMapProto)
    }

    static {
      defaultInstance = new QueueConfigurationsMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.QueueConfigurationsMapProto)
  }

  public interface QueueUserACLInfoProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string queueName = 1;
    /**
     * <code>optional string queueName = 1;</code>
     */
    boolean hasQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    java.lang.String getQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    com.google.protobuf.ByteString
        getQueueNameBytes();

    // repeated .hadoop.yarn.QueueACLProto userAcls = 2;
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> getUserAclsList();
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    int getUserAclsCount();
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto getUserAcls(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.QueueUserACLInfoProto}
   */
  public static final class QueueUserACLInfoProto extends
      com.google.protobuf.GeneratedMessage
      implements QueueUserACLInfoProtoOrBuilder {
    // Use QueueUserACLInfoProto.newBuilder() to construct.
    private QueueUserACLInfoProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private QueueUserACLInfoProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final QueueUserACLInfoProto defaultInstance;
    public static QueueUserACLInfoProto getDefaultInstance() {
      return defaultInstance;
    }

    public QueueUserACLInfoProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private QueueUserACLInfoProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              queueName_ = input.readBytes();
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value = org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  userAcls_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto>();
                  mutable_bitField0_ |= 0x00000002;
                }
                userAcls_.add(value);
              }
              break;
            }
            case 18: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value = org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(2, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                    userAcls_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto>();
                    mutable_bitField0_ |= 0x00000002;
                  }
                  userAcls_.add(value);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          userAcls_ = java.util.Collections.unmodifiableList(userAcls_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder.class);
    }

    public static com.google.protobuf.Parser<QueueUserACLInfoProto> PARSER =
        new com.google.protobuf.AbstractParser<QueueUserACLInfoProto>() {
      public QueueUserACLInfoProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new QueueUserACLInfoProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<QueueUserACLInfoProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string queueName = 1;
    public static final int QUEUENAME_FIELD_NUMBER = 1;
    private java.lang.Object queueName_;
    /**
     * <code>optional string queueName = 1;</code>
     */
    public boolean hasQueueName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public java.lang.String getQueueName() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queueName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public com.google.protobuf.ByteString
        getQueueNameBytes() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queueName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // repeated .hadoop.yarn.QueueACLProto userAcls = 2;
    public static final int USERACLS_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> userAcls_;
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> getUserAclsList() {
      return userAcls_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    public int getUserAclsCount() {
      return userAcls_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto getUserAcls(int index) {
      return userAcls_.get(index);
    }

    private void initFields() {
      queueName_ = "";
      userAcls_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getQueueNameBytes());
      }
      for (int i = 0; i < userAcls_.size(); i++) {
        output.writeEnum(2, userAcls_.get(i).getNumber());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getQueueNameBytes());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < userAcls_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(userAcls_.get(i).getNumber());
        }
        size += dataSize;
        size += 1 * userAcls_.size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto other = (org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto) obj;

      boolean result = true;
      result = result && (hasQueueName() == other.hasQueueName());
      if (hasQueueName()) {
        result = result && getQueueName()
            .equals(other.getQueueName());
      }
      result = result && getUserAclsList()
          .equals(other.getUserAclsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQueueName()) {
        hash = (37 * hash) + QUEUENAME_FIELD_NUMBER;
        hash = (53 * hash) + getQueueName().hashCode();
      }
      if (getUserAclsCount() > 0) {
        hash = (37 * hash) + USERACLS_FIELD_NUMBER;
        hash = (53 * hash) + hashEnumList(getUserAclsList());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.QueueUserACLInfoProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        queueName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        userAcls_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto result = new org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.queueName_ = queueName_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          userAcls_ = java.util.Collections.unmodifiableList(userAcls_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.userAcls_ = userAcls_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.getDefaultInstance()) return this;
        if (other.hasQueueName()) {
          bitField0_ |= 0x00000001;
          queueName_ = other.queueName_;
          onChanged();
        }
        if (!other.userAcls_.isEmpty()) {
          if (userAcls_.isEmpty()) {
            userAcls_ = other.userAcls_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureUserAclsIsMutable();
            userAcls_.addAll(other.userAcls_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string queueName = 1;
      private java.lang.Object queueName_ = "";
      /**
       * <code>optional string queueName = 1;</code>
       */
      public boolean hasQueueName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public java.lang.String getQueueName() {
        java.lang.Object ref = queueName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          queueName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public com.google.protobuf.ByteString
          getQueueNameBytes() {
        java.lang.Object ref = queueName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queueName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder clearQueueName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        queueName_ = getDefaultInstance().getQueueName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.QueueACLProto userAcls = 2;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> userAcls_ =
        java.util.Collections.emptyList();
      private void ensureUserAclsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          userAcls_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto>(userAcls_);
          bitField0_ |= 0x00000002;
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> getUserAclsList() {
        return java.util.Collections.unmodifiableList(userAcls_);
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public int getUserAclsCount() {
        return userAcls_.size();
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto getUserAcls(int index) {
        return userAcls_.get(index);
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder setUserAcls(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureUserAclsIsMutable();
        userAcls_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder addUserAcls(org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureUserAclsIsMutable();
        userAcls_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder addAllUserAcls(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> values) {
        ensureUserAclsIsMutable();
        super.addAll(values, userAcls_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder clearUserAcls() {
        userAcls_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.QueueUserACLInfoProto)
    }

    static {
      defaultInstance = new QueueUserACLInfoProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.QueueUserACLInfoProto)
  }

  public interface ReservationIdProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int64 id = 1;
    /**
     * <code>optional int64 id = 1;</code>
     */
    boolean hasId();
    /**
     * <code>optional int64 id = 1;</code>
     */
    long getId();

    // optional int64 cluster_timestamp = 2;
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    boolean hasClusterTimestamp();
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    long getClusterTimestamp();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationIdProto}
   */
  public static final class ReservationIdProto extends
      com.google.protobuf.GeneratedMessage
      implements ReservationIdProtoOrBuilder {
    // Use ReservationIdProto.newBuilder() to construct.
    private ReservationIdProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ReservationIdProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ReservationIdProto defaultInstance;
    public static ReservationIdProto getDefaultInstance() {
      return defaultInstance;
    }

    public ReservationIdProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              id_ = input.readInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              clusterTimestamp_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ReservationIdProto> PARSER =
        new com.google.protobuf.AbstractParser<ReservationIdProto>() {
      public ReservationIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ReservationIdProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationIdProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int64 id = 1;
    public static final int ID_FIELD_NUMBER = 1;
    private long id_;
    /**
     * <code>optional int64 id = 1;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int64 id = 1;</code>
     */
    public long getId() {
      return id_;
    }

    // optional int64 cluster_timestamp = 2;
    public static final int CLUSTER_TIMESTAMP_FIELD_NUMBER = 2;
    private long clusterTimestamp_;
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    public boolean hasClusterTimestamp() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    public long getClusterTimestamp() {
      return clusterTimestamp_;
    }

    private void initFields() {
      id_ = 0L;
      clusterTimestamp_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt64(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, clusterTimestamp_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, clusterTimestamp_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto) obj;

      boolean result = true;
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && (getId()
            == other.getId());
      }
      result = result && (hasClusterTimestamp() == other.hasClusterTimestamp());
      if (hasClusterTimestamp()) {
        result = result && (getClusterTimestamp()
            == other.getClusterTimestamp());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getId());
      }
      if (hasClusterTimestamp()) {
        hash = (37 * hash) + CLUSTER_TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getClusterTimestamp());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        id_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        clusterTimestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.id_ = id_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.clusterTimestamp_ = clusterTimestamp_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance()) return this;
        if (other.hasId()) {
          setId(other.getId());
        }
        if (other.hasClusterTimestamp()) {
          setClusterTimestamp(other.getClusterTimestamp());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int64 id = 1;
      private long id_ ;
      /**
       * <code>optional int64 id = 1;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int64 id = 1;</code>
       */
      public long getId() {
        return id_;
      }
      /**
       * <code>optional int64 id = 1;</code>
       */
      public Builder setId(long value) {
        bitField0_ |= 0x00000001;
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 id = 1;</code>
       */
      public Builder clearId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        id_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 cluster_timestamp = 2;
      private long clusterTimestamp_ ;
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public boolean hasClusterTimestamp() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public long getClusterTimestamp() {
        return clusterTimestamp_;
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public Builder setClusterTimestamp(long value) {
        bitField0_ |= 0x00000002;
        clusterTimestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public Builder clearClusterTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000002);
        clusterTimestamp_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationIdProto)
    }

    static {
      defaultInstance = new ReservationIdProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationIdProto)
  }

  public interface ReservationRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ResourceProto capability = 1;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    // optional int32 num_containers = 2 [default = 1];
    /**
     * <code>optional int32 num_containers = 2 [default = 1];</code>
     */
    boolean hasNumContainers();
    /**
     * <code>optional int32 num_containers = 2 [default = 1];</code>
     */
    int getNumContainers();

    // optional int32 concurrency = 3 [default = 1];
    /**
     * <code>optional int32 concurrency = 3 [default = 1];</code>
     */
    boolean hasConcurrency();
    /**
     * <code>optional int32 concurrency = 3 [default = 1];</code>
     */
    int getConcurrency();

    // optional int64 duration = 4 [default = -1];
    /**
     * <code>optional int64 duration = 4 [default = -1];</code>
     */
    boolean hasDuration();
    /**
     * <code>optional int64 duration = 4 [default = -1];</code>
     */
    long getDuration();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationRequestProto}
   */
  public static final class ReservationRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements ReservationRequestProtoOrBuilder {
    // Use ReservationRequestProto.newBuilder() to construct.
    private ReservationRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ReservationRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ReservationRequestProto defaultInstance;
    public static ReservationRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public ReservationRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              numContainers_ = input.readInt32();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              concurrency_ = input.readInt32();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              duration_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ReservationRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<ReservationRequestProto>() {
      public ReservationRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ReservationRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ResourceProto capability = 1;
    public static final int CAPABILITY_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    // optional int32 num_containers = 2 [default = 1];
    public static final int NUM_CONTAINERS_FIELD_NUMBER = 2;
    private int numContainers_;
    /**
     * <code>optional int32 num_containers = 2 [default = 1];</code>
     */
    public boolean hasNumContainers() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 num_containers = 2 [default = 1];</code>
     */
    public int getNumContainers() {
      return numContainers_;
    }

    // optional int32 concurrency = 3 [default = 1];
    public static final int CONCURRENCY_FIELD_NUMBER = 3;
    private int concurrency_;
    /**
     * <code>optional int32 concurrency = 3 [default = 1];</code>
     */
    public boolean hasConcurrency() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int32 concurrency = 3 [default = 1];</code>
     */
    public int getConcurrency() {
      return concurrency_;
    }

    // optional int64 duration = 4 [default = -1];
    public static final int DURATION_FIELD_NUMBER = 4;
    private long duration_;
    /**
     * <code>optional int64 duration = 4 [default = -1];</code>
     */
    public boolean hasDuration() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int64 duration = 4 [default = -1];</code>
     */
    public long getDuration() {
      return duration_;
    }

    private void initFields() {
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      numContainers_ = 1;
      concurrency_ = 1;
      duration_ = -1L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, capability_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, numContainers_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(3, concurrency_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt64(4, duration_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, capability_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, numContainers_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, concurrency_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(4, duration_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto) obj;

      boolean result = true;
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasNumContainers() == other.hasNumContainers());
      if (hasNumContainers()) {
        result = result && (getNumContainers()
            == other.getNumContainers());
      }
      result = result && (hasConcurrency() == other.hasConcurrency());
      if (hasConcurrency()) {
        result = result && (getConcurrency()
            == other.getConcurrency());
      }
      result = result && (hasDuration() == other.hasDuration());
      if (hasDuration()) {
        result = result && (getDuration()
            == other.getDuration());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasNumContainers()) {
        hash = (37 * hash) + NUM_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumContainers();
      }
      if (hasConcurrency()) {
        hash = (37 * hash) + CONCURRENCY_FIELD_NUMBER;
        hash = (53 * hash) + getConcurrency();
      }
      if (hasDuration()) {
        hash = (37 * hash) + DURATION_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getDuration());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getCapabilityFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        numContainers_ = 1;
        bitField0_ = (bitField0_ & ~0x00000002);
        concurrency_ = 1;
        bitField0_ = (bitField0_ & ~0x00000004);
        duration_ = -1L;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.numContainers_ = numContainers_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.concurrency_ = concurrency_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.duration_ = duration_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.getDefaultInstance()) return this;
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasNumContainers()) {
          setNumContainers(other.getNumContainers());
        }
        if (other.hasConcurrency()) {
          setConcurrency(other.getConcurrency());
        }
        if (other.hasDuration()) {
          setDuration(other.getDuration());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ResourceProto capability = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // optional int32 num_containers = 2 [default = 1];
      private int numContainers_ = 1;
      /**
       * <code>optional int32 num_containers = 2 [default = 1];</code>
       */
      public boolean hasNumContainers() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 num_containers = 2 [default = 1];</code>
       */
      public int getNumContainers() {
        return numContainers_;
      }
      /**
       * <code>optional int32 num_containers = 2 [default = 1];</code>
       */
      public Builder setNumContainers(int value) {
        bitField0_ |= 0x00000002;
        numContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_containers = 2 [default = 1];</code>
       */
      public Builder clearNumContainers() {
        bitField0_ = (bitField0_ & ~0x00000002);
        numContainers_ = 1;
        onChanged();
        return this;
      }

      // optional int32 concurrency = 3 [default = 1];
      private int concurrency_ = 1;
      /**
       * <code>optional int32 concurrency = 3 [default = 1];</code>
       */
      public boolean hasConcurrency() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int32 concurrency = 3 [default = 1];</code>
       */
      public int getConcurrency() {
        return concurrency_;
      }
      /**
       * <code>optional int32 concurrency = 3 [default = 1];</code>
       */
      public Builder setConcurrency(int value) {
        bitField0_ |= 0x00000004;
        concurrency_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 concurrency = 3 [default = 1];</code>
       */
      public Builder clearConcurrency() {
        bitField0_ = (bitField0_ & ~0x00000004);
        concurrency_ = 1;
        onChanged();
        return this;
      }

      // optional int64 duration = 4 [default = -1];
      private long duration_ = -1L;
      /**
       * <code>optional int64 duration = 4 [default = -1];</code>
       */
      public boolean hasDuration() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int64 duration = 4 [default = -1];</code>
       */
      public long getDuration() {
        return duration_;
      }
      /**
       * <code>optional int64 duration = 4 [default = -1];</code>
       */
      public Builder setDuration(long value) {
        bitField0_ |= 0x00000008;
        duration_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 duration = 4 [default = -1];</code>
       */
      public Builder clearDuration() {
        bitField0_ = (bitField0_ & ~0x00000008);
        duration_ = -1L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationRequestProto)
    }

    static {
      defaultInstance = new ReservationRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationRequestProto)
  }

  public interface ReservationRequestsProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> 
        getReservationResourcesList();
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto getReservationResources(int index);
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    int getReservationResourcesCount();
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder> 
        getReservationResourcesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder getReservationResourcesOrBuilder(
        int index);

    // optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];
    /**
     * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
     */
    boolean hasInterpreter();
    /**
     * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto getInterpreter();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationRequestsProto}
   */
  public static final class ReservationRequestsProto extends
      com.google.protobuf.GeneratedMessage
      implements ReservationRequestsProtoOrBuilder {
    // Use ReservationRequestsProto.newBuilder() to construct.
    private ReservationRequestsProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ReservationRequestsProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ReservationRequestsProto defaultInstance;
    public static ReservationRequestsProto getDefaultInstance() {
      return defaultInstance;
    }

    public ReservationRequestsProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationRequestsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                reservationResources_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              reservationResources_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.PARSER, extensionRegistry));
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto value = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                interpreter_ = value;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          reservationResources_ = java.util.Collections.unmodifiableList(reservationResources_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ReservationRequestsProto> PARSER =
        new com.google.protobuf.AbstractParser<ReservationRequestsProto>() {
      public ReservationRequestsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ReservationRequestsProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationRequestsProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;
    public static final int RESERVATION_RESOURCES_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> reservationResources_;
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> getReservationResourcesList() {
      return reservationResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder> 
        getReservationResourcesOrBuilderList() {
      return reservationResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    public int getReservationResourcesCount() {
      return reservationResources_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto getReservationResources(int index) {
      return reservationResources_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder getReservationResourcesOrBuilder(
        int index) {
      return reservationResources_.get(index);
    }

    // optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];
    public static final int INTERPRETER_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto interpreter_;
    /**
     * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
     */
    public boolean hasInterpreter() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto getInterpreter() {
      return interpreter_;
    }

    private void initFields() {
      reservationResources_ = java.util.Collections.emptyList();
      interpreter_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto.R_ALL;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < reservationResources_.size(); i++) {
        output.writeMessage(1, reservationResources_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(2, interpreter_.getNumber());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < reservationResources_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, reservationResources_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, interpreter_.getNumber());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto) obj;

      boolean result = true;
      result = result && getReservationResourcesList()
          .equals(other.getReservationResourcesList());
      result = result && (hasInterpreter() == other.hasInterpreter());
      if (hasInterpreter()) {
        result = result &&
            (getInterpreter() == other.getInterpreter());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getReservationResourcesCount() > 0) {
        hash = (37 * hash) + RESERVATION_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getReservationResourcesList().hashCode();
      }
      if (hasInterpreter()) {
        hash = (37 * hash) + INTERPRETER_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getInterpreter());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationRequestsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getReservationResourcesFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (reservationResourcesBuilder_ == null) {
          reservationResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          reservationResourcesBuilder_.clear();
        }
        interpreter_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto.R_ALL;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (reservationResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            reservationResources_ = java.util.Collections.unmodifiableList(reservationResources_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.reservationResources_ = reservationResources_;
        } else {
          result.reservationResources_ = reservationResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000001;
        }
        result.interpreter_ = interpreter_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance()) return this;
        if (reservationResourcesBuilder_ == null) {
          if (!other.reservationResources_.isEmpty()) {
            if (reservationResources_.isEmpty()) {
              reservationResources_ = other.reservationResources_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureReservationResourcesIsMutable();
              reservationResources_.addAll(other.reservationResources_);
            }
            onChanged();
          }
        } else {
          if (!other.reservationResources_.isEmpty()) {
            if (reservationResourcesBuilder_.isEmpty()) {
              reservationResourcesBuilder_.dispose();
              reservationResourcesBuilder_ = null;
              reservationResources_ = other.reservationResources_;
              bitField0_ = (bitField0_ & ~0x00000001);
              reservationResourcesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getReservationResourcesFieldBuilder() : null;
            } else {
              reservationResourcesBuilder_.addAllMessages(other.reservationResources_);
            }
          }
        }
        if (other.hasInterpreter()) {
          setInterpreter(other.getInterpreter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> reservationResources_ =
        java.util.Collections.emptyList();
      private void ensureReservationResourcesIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          reservationResources_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto>(reservationResources_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder> reservationResourcesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> getReservationResourcesList() {
        if (reservationResourcesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(reservationResources_);
        } else {
          return reservationResourcesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public int getReservationResourcesCount() {
        if (reservationResourcesBuilder_ == null) {
          return reservationResources_.size();
        } else {
          return reservationResourcesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto getReservationResources(int index) {
        if (reservationResourcesBuilder_ == null) {
          return reservationResources_.get(index);
        } else {
          return reservationResourcesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder setReservationResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto value) {
        if (reservationResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReservationResourcesIsMutable();
          reservationResources_.set(index, value);
          onChanged();
        } else {
          reservationResourcesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder setReservationResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder builderForValue) {
        if (reservationResourcesBuilder_ == null) {
          ensureReservationResourcesIsMutable();
          reservationResources_.set(index, builderForValue.build());
          onChanged();
        } else {
          reservationResourcesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder addReservationResources(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto value) {
        if (reservationResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReservationResourcesIsMutable();
          reservationResources_.add(value);
          onChanged();
        } else {
          reservationResourcesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder addReservationResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto value) {
        if (reservationResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReservationResourcesIsMutable();
          reservationResources_.add(index, value);
          onChanged();
        } else {
          reservationResourcesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder addReservationResources(
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder builderForValue) {
        if (reservationResourcesBuilder_ == null) {
          ensureReservationResourcesIsMutable();
          reservationResources_.add(builderForValue.build());
          onChanged();
        } else {
          reservationResourcesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder addReservationResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder builderForValue) {
        if (reservationResourcesBuilder_ == null) {
          ensureReservationResourcesIsMutable();
          reservationResources_.add(index, builderForValue.build());
          onChanged();
        } else {
          reservationResourcesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder addAllReservationResources(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> values) {
        if (reservationResourcesBuilder_ == null) {
          ensureReservationResourcesIsMutable();
          super.addAll(values, reservationResources_);
          onChanged();
        } else {
          reservationResourcesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder clearReservationResources() {
        if (reservationResourcesBuilder_ == null) {
          reservationResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          reservationResourcesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder removeReservationResources(int index) {
        if (reservationResourcesBuilder_ == null) {
          ensureReservationResourcesIsMutable();
          reservationResources_.remove(index);
          onChanged();
        } else {
          reservationResourcesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder getReservationResourcesBuilder(
          int index) {
        return getReservationResourcesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder getReservationResourcesOrBuilder(
          int index) {
        if (reservationResourcesBuilder_ == null) {
          return reservationResources_.get(index);  } else {
          return reservationResourcesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder> 
           getReservationResourcesOrBuilderList() {
        if (reservationResourcesBuilder_ != null) {
          return reservationResourcesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(reservationResources_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder addReservationResourcesBuilder() {
        return getReservationResourcesFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder addReservationResourcesBuilder(
          int index) {
        return getReservationResourcesFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder> 
           getReservationResourcesBuilderList() {
        return getReservationResourcesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder> 
          getReservationResourcesFieldBuilder() {
        if (reservationResourcesBuilder_ == null) {
          reservationResourcesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder>(
                  reservationResources_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          reservationResources_ = null;
        }
        return reservationResourcesBuilder_;
      }

      // optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];
      private org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto interpreter_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto.R_ALL;
      /**
       * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
       */
      public boolean hasInterpreter() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto getInterpreter() {
        return interpreter_;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
       */
      public Builder setInterpreter(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        interpreter_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
       */
      public Builder clearInterpreter() {
        bitField0_ = (bitField0_ & ~0x00000002);
        interpreter_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto.R_ALL;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationRequestsProto)
    }

    static {
      defaultInstance = new ReservationRequestsProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationRequestsProto)
  }

  public interface ReservationDefinitionProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;
    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    boolean hasReservationRequests();
    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto getReservationRequests();
    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder getReservationRequestsOrBuilder();

    // optional int64 arrival = 2;
    /**
     * <code>optional int64 arrival = 2;</code>
     */
    boolean hasArrival();
    /**
     * <code>optional int64 arrival = 2;</code>
     */
    long getArrival();

    // optional int64 deadline = 3;
    /**
     * <code>optional int64 deadline = 3;</code>
     */
    boolean hasDeadline();
    /**
     * <code>optional int64 deadline = 3;</code>
     */
    long getDeadline();

    // optional string reservation_name = 4;
    /**
     * <code>optional string reservation_name = 4;</code>
     */
    boolean hasReservationName();
    /**
     * <code>optional string reservation_name = 4;</code>
     */
    java.lang.String getReservationName();
    /**
     * <code>optional string reservation_name = 4;</code>
     */
    com.google.protobuf.ByteString
        getReservationNameBytes();

    // optional string recurrence_expression = 5 [default = "0"];
    /**
     * <code>optional string recurrence_expression = 5 [default = "0"];</code>
     */
    boolean hasRecurrenceExpression();
    /**
     * <code>optional string recurrence_expression = 5 [default = "0"];</code>
     */
    java.lang.String getRecurrenceExpression();
    /**
     * <code>optional string recurrence_expression = 5 [default = "0"];</code>
     */
    com.google.protobuf.ByteString
        getRecurrenceExpressionBytes();

    // optional .hadoop.yarn.PriorityProto priority = 6;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationDefinitionProto}
   */
  public static final class ReservationDefinitionProto extends
      com.google.protobuf.GeneratedMessage
      implements ReservationDefinitionProtoOrBuilder {
    // Use ReservationDefinitionProto.newBuilder() to construct.
    private ReservationDefinitionProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ReservationDefinitionProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ReservationDefinitionProto defaultInstance;
    public static ReservationDefinitionProto getDefaultInstance() {
      return defaultInstance;
    }

    public ReservationDefinitionProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationDefinitionProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = reservationRequests_.toBuilder();
              }
              reservationRequests_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationRequests_);
                reservationRequests_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              arrival_ = input.readInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              deadline_ = input.readInt64();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              reservationName_ = input.readBytes();
              break;
            }
            case 42: {
              bitField0_ |= 0x00000010;
              recurrenceExpression_ = input.readBytes();
              break;
            }
            case 50: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000020) == 0x00000020)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000020;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationDefinitionProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ReservationDefinitionProto> PARSER =
        new com.google.protobuf.AbstractParser<ReservationDefinitionProto>() {
      public ReservationDefinitionProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ReservationDefinitionProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationDefinitionProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;
    public static final int RESERVATION_REQUESTS_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto reservationRequests_;
    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    public boolean hasReservationRequests() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto getReservationRequests() {
      return reservationRequests_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder getReservationRequestsOrBuilder() {
      return reservationRequests_;
    }

    // optional int64 arrival = 2;
    public static final int ARRIVAL_FIELD_NUMBER = 2;
    private long arrival_;
    /**
     * <code>optional int64 arrival = 2;</code>
     */
    public boolean hasArrival() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 arrival = 2;</code>
     */
    public long getArrival() {
      return arrival_;
    }

    // optional int64 deadline = 3;
    public static final int DEADLINE_FIELD_NUMBER = 3;
    private long deadline_;
    /**
     * <code>optional int64 deadline = 3;</code>
     */
    public boolean hasDeadline() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 deadline = 3;</code>
     */
    public long getDeadline() {
      return deadline_;
    }

    // optional string reservation_name = 4;
    public static final int RESERVATION_NAME_FIELD_NUMBER = 4;
    private java.lang.Object reservationName_;
    /**
     * <code>optional string reservation_name = 4;</code>
     */
    public boolean hasReservationName() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string reservation_name = 4;</code>
     */
    public java.lang.String getReservationName() {
      java.lang.Object ref = reservationName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          reservationName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string reservation_name = 4;</code>
     */
    public com.google.protobuf.ByteString
        getReservationNameBytes() {
      java.lang.Object ref = reservationName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        reservationName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string recurrence_expression = 5 [default = "0"];
    public static final int RECURRENCE_EXPRESSION_FIELD_NUMBER = 5;
    private java.lang.Object recurrenceExpression_;
    /**
     * <code>optional string recurrence_expression = 5 [default = "0"];</code>
     */
    public boolean hasRecurrenceExpression() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string recurrence_expression = 5 [default = "0"];</code>
     */
    public java.lang.String getRecurrenceExpression() {
      java.lang.Object ref = recurrenceExpression_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          recurrenceExpression_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string recurrence_expression = 5 [default = "0"];</code>
     */
    public com.google.protobuf.ByteString
        getRecurrenceExpressionBytes() {
      java.lang.Object ref = recurrenceExpression_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        recurrenceExpression_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.PriorityProto priority = 6;
    public static final int PRIORITY_FIELD_NUMBER = 6;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_;
    }

    private void initFields() {
      reservationRequests_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance();
      arrival_ = 0L;
      deadline_ = 0L;
      reservationName_ = "";
      recurrenceExpression_ = "0";
      priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, reservationRequests_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, arrival_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, deadline_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(4, getReservationNameBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBytes(5, getRecurrenceExpressionBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeMessage(6, priority_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, reservationRequests_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, arrival_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, deadline_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, getReservationNameBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(5, getRecurrenceExpressionBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, priority_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto) obj;

      boolean result = true;
      result = result && (hasReservationRequests() == other.hasReservationRequests());
      if (hasReservationRequests()) {
        result = result && getReservationRequests()
            .equals(other.getReservationRequests());
      }
      result = result && (hasArrival() == other.hasArrival());
      if (hasArrival()) {
        result = result && (getArrival()
            == other.getArrival());
      }
      result = result && (hasDeadline() == other.hasDeadline());
      if (hasDeadline()) {
        result = result && (getDeadline()
            == other.getDeadline());
      }
      result = result && (hasReservationName() == other.hasReservationName());
      if (hasReservationName()) {
        result = result && getReservationName()
            .equals(other.getReservationName());
      }
      result = result && (hasRecurrenceExpression() == other.hasRecurrenceExpression());
      if (hasRecurrenceExpression()) {
        result = result && getRecurrenceExpression()
            .equals(other.getRecurrenceExpression());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasReservationRequests()) {
        hash = (37 * hash) + RESERVATION_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getReservationRequests().hashCode();
      }
      if (hasArrival()) {
        hash = (37 * hash) + ARRIVAL_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getArrival());
      }
      if (hasDeadline()) {
        hash = (37 * hash) + DEADLINE_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getDeadline());
      }
      if (hasReservationName()) {
        hash = (37 * hash) + RESERVATION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getReservationName().hashCode();
      }
      if (hasRecurrenceExpression()) {
        hash = (37 * hash) + RECURRENCE_EXPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + getRecurrenceExpression().hashCode();
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationDefinitionProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationDefinitionProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getReservationRequestsFieldBuilder();
          getPriorityFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (reservationRequestsBuilder_ == null) {
          reservationRequests_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance();
        } else {
          reservationRequestsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        arrival_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        deadline_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        reservationName_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        recurrenceExpression_ = "0";
        bitField0_ = (bitField0_ & ~0x00000010);
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (reservationRequestsBuilder_ == null) {
          result.reservationRequests_ = reservationRequests_;
        } else {
          result.reservationRequests_ = reservationRequestsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.arrival_ = arrival_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.deadline_ = deadline_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.reservationName_ = reservationName_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.recurrenceExpression_ = recurrenceExpression_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance()) return this;
        if (other.hasReservationRequests()) {
          mergeReservationRequests(other.getReservationRequests());
        }
        if (other.hasArrival()) {
          setArrival(other.getArrival());
        }
        if (other.hasDeadline()) {
          setDeadline(other.getDeadline());
        }
        if (other.hasReservationName()) {
          bitField0_ |= 0x00000008;
          reservationName_ = other.reservationName_;
          onChanged();
        }
        if (other.hasRecurrenceExpression()) {
          bitField0_ |= 0x00000010;
          recurrenceExpression_ = other.recurrenceExpression_;
          onChanged();
        }
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto reservationRequests_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder> reservationRequestsBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public boolean hasReservationRequests() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto getReservationRequests() {
        if (reservationRequestsBuilder_ == null) {
          return reservationRequests_;
        } else {
          return reservationRequestsBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public Builder setReservationRequests(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto value) {
        if (reservationRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationRequests_ = value;
          onChanged();
        } else {
          reservationRequestsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public Builder setReservationRequests(
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder builderForValue) {
        if (reservationRequestsBuilder_ == null) {
          reservationRequests_ = builderForValue.build();
          onChanged();
        } else {
          reservationRequestsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public Builder mergeReservationRequests(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto value) {
        if (reservationRequestsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              reservationRequests_ != org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance()) {
            reservationRequests_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.newBuilder(reservationRequests_).mergeFrom(value).buildPartial();
          } else {
            reservationRequests_ = value;
          }
          onChanged();
        } else {
          reservationRequestsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public Builder clearReservationRequests() {
        if (reservationRequestsBuilder_ == null) {
          reservationRequests_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance();
          onChanged();
        } else {
          reservationRequestsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder getReservationRequestsBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getReservationRequestsFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder getReservationRequestsOrBuilder() {
        if (reservationRequestsBuilder_ != null) {
          return reservationRequestsBuilder_.getMessageOrBuilder();
        } else {
          return reservationRequests_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder> 
          getReservationRequestsFieldBuilder() {
        if (reservationRequestsBuilder_ == null) {
          reservationRequestsBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder>(
                  reservationRequests_,
                  getParentForChildren(),
                  isClean());
          reservationRequests_ = null;
        }
        return reservationRequestsBuilder_;
      }

      // optional int64 arrival = 2;
      private long arrival_ ;
      /**
       * <code>optional int64 arrival = 2;</code>
       */
      public boolean hasArrival() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 arrival = 2;</code>
       */
      public long getArrival() {
        return arrival_;
      }
      /**
       * <code>optional int64 arrival = 2;</code>
       */
      public Builder setArrival(long value) {
        bitField0_ |= 0x00000002;
        arrival_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 arrival = 2;</code>
       */
      public Builder clearArrival() {
        bitField0_ = (bitField0_ & ~0x00000002);
        arrival_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 deadline = 3;
      private long deadline_ ;
      /**
       * <code>optional int64 deadline = 3;</code>
       */
      public boolean hasDeadline() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 deadline = 3;</code>
       */
      public long getDeadline() {
        return deadline_;
      }
      /**
       * <code>optional int64 deadline = 3;</code>
       */
      public Builder setDeadline(long value) {
        bitField0_ |= 0x00000004;
        deadline_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 deadline = 3;</code>
       */
      public Builder clearDeadline() {
        bitField0_ = (bitField0_ & ~0x00000004);
        deadline_ = 0L;
        onChanged();
        return this;
      }

      // optional string reservation_name = 4;
      private java.lang.Object reservationName_ = "";
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public boolean hasReservationName() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public java.lang.String getReservationName() {
        java.lang.Object ref = reservationName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          reservationName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public com.google.protobuf.ByteString
          getReservationNameBytes() {
        java.lang.Object ref = reservationName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          reservationName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public Builder setReservationName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        reservationName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public Builder clearReservationName() {
        bitField0_ = (bitField0_ & ~0x00000008);
        reservationName_ = getDefaultInstance().getReservationName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public Builder setReservationNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        reservationName_ = value;
        onChanged();
        return this;
      }

      // optional string recurrence_expression = 5 [default = "0"];
      private java.lang.Object recurrenceExpression_ = "0";
      /**
       * <code>optional string recurrence_expression = 5 [default = "0"];</code>
       */
      public boolean hasRecurrenceExpression() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string recurrence_expression = 5 [default = "0"];</code>
       */
      public java.lang.String getRecurrenceExpression() {
        java.lang.Object ref = recurrenceExpression_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          recurrenceExpression_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string recurrence_expression = 5 [default = "0"];</code>
       */
      public com.google.protobuf.ByteString
          getRecurrenceExpressionBytes() {
        java.lang.Object ref = recurrenceExpression_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          recurrenceExpression_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string recurrence_expression = 5 [default = "0"];</code>
       */
      public Builder setRecurrenceExpression(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        recurrenceExpression_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string recurrence_expression = 5 [default = "0"];</code>
       */
      public Builder clearRecurrenceExpression() {
        bitField0_ = (bitField0_ & ~0x00000010);
        recurrenceExpression_ = getDefaultInstance().getRecurrenceExpression();
        onChanged();
        return this;
      }
      /**
       * <code>optional string recurrence_expression = 5 [default = "0"];</code>
       */
      public Builder setRecurrenceExpressionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        recurrenceExpression_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.PriorityProto priority = 6;
      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020) &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  priority_,
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationDefinitionProto)
    }

    static {
      defaultInstance = new ReservationDefinitionProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationDefinitionProto)
  }

  public interface ResourceAllocationRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int64 start_time = 1;
    /**
     * <code>optional int64 start_time = 1;</code>
     */
    boolean hasStartTime();
    /**
     * <code>optional int64 start_time = 1;</code>
     */
    long getStartTime();

    // optional int64 end_time = 2;
    /**
     * <code>optional int64 end_time = 2;</code>
     */
    boolean hasEndTime();
    /**
     * <code>optional int64 end_time = 2;</code>
     */
    long getEndTime();

    // optional .hadoop.yarn.ResourceProto resource = 3;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceAllocationRequestProto}
   */
  public static final class ResourceAllocationRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements ResourceAllocationRequestProtoOrBuilder {
    // Use ResourceAllocationRequestProto.newBuilder() to construct.
    private ResourceAllocationRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ResourceAllocationRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ResourceAllocationRequestProto defaultInstance;
    public static ResourceAllocationRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public ResourceAllocationRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceAllocationRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              startTime_ = input.readInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              endTime_ = input.readInt64();
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceAllocationRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceAllocationRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ResourceAllocationRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<ResourceAllocationRequestProto>() {
      public ResourceAllocationRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ResourceAllocationRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceAllocationRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int64 start_time = 1;
    public static final int START_TIME_FIELD_NUMBER = 1;
    private long startTime_;
    /**
     * <code>optional int64 start_time = 1;</code>
     */
    public boolean hasStartTime() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int64 start_time = 1;</code>
     */
    public long getStartTime() {
      return startTime_;
    }

    // optional int64 end_time = 2;
    public static final int END_TIME_FIELD_NUMBER = 2;
    private long endTime_;
    /**
     * <code>optional int64 end_time = 2;</code>
     */
    public boolean hasEndTime() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 end_time = 2;</code>
     */
    public long getEndTime() {
      return endTime_;
    }

    // optional .hadoop.yarn.ResourceProto resource = 3;
    public static final int RESOURCE_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    private void initFields() {
      startTime_ = 0L;
      endTime_ = 0L;
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt64(1, startTime_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, endTime_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, resource_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, startTime_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, endTime_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, resource_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto) obj;

      boolean result = true;
      result = result && (hasStartTime() == other.hasStartTime());
      if (hasStartTime()) {
        result = result && (getStartTime()
            == other.getStartTime());
      }
      result = result && (hasEndTime() == other.hasEndTime());
      if (hasEndTime()) {
        result = result && (getEndTime()
            == other.getEndTime());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasStartTime()) {
        hash = (37 * hash) + START_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getStartTime());
      }
      if (hasEndTime()) {
        hash = (37 * hash) + END_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getEndTime());
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceAllocationRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceAllocationRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceAllocationRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        startTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        endTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceAllocationRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.startTime_ = startTime_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.endTime_ = endTime_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.getDefaultInstance()) return this;
        if (other.hasStartTime()) {
          setStartTime(other.getStartTime());
        }
        if (other.hasEndTime()) {
          setEndTime(other.getEndTime());
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int64 start_time = 1;
      private long startTime_ ;
      /**
       * <code>optional int64 start_time = 1;</code>
       */
      public boolean hasStartTime() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int64 start_time = 1;</code>
       */
      public long getStartTime() {
        return startTime_;
      }
      /**
       * <code>optional int64 start_time = 1;</code>
       */
      public Builder setStartTime(long value) {
        bitField0_ |= 0x00000001;
        startTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 start_time = 1;</code>
       */
      public Builder clearStartTime() {
        bitField0_ = (bitField0_ & ~0x00000001);
        startTime_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 end_time = 2;
      private long endTime_ ;
      /**
       * <code>optional int64 end_time = 2;</code>
       */
      public boolean hasEndTime() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 end_time = 2;</code>
       */
      public long getEndTime() {
        return endTime_;
      }
      /**
       * <code>optional int64 end_time = 2;</code>
       */
      public Builder setEndTime(long value) {
        bitField0_ |= 0x00000002;
        endTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 end_time = 2;</code>
       */
      public Builder clearEndTime() {
        bitField0_ = (bitField0_ & ~0x00000002);
        endTime_ = 0L;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto resource = 3;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceAllocationRequestProto)
    }

    static {
      defaultInstance = new ResourceAllocationRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceAllocationRequestProto)
  }

  public interface ReservationAllocationStateProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    boolean hasReservationDefinition();
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getReservationDefinition();
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder getReservationDefinitionOrBuilder();

    // repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;
    /**
     * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto> 
        getAllocationRequestsList();
    /**
     * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto getAllocationRequests(int index);
    /**
     * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
     */
    int getAllocationRequestsCount();
    /**
     * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProtoOrBuilder> 
        getAllocationRequestsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProtoOrBuilder getAllocationRequestsOrBuilder(
        int index);

    // optional int64 start_time = 3;
    /**
     * <code>optional int64 start_time = 3;</code>
     */
    boolean hasStartTime();
    /**
     * <code>optional int64 start_time = 3;</code>
     */
    long getStartTime();

    // optional int64 end_time = 4;
    /**
     * <code>optional int64 end_time = 4;</code>
     */
    boolean hasEndTime();
    /**
     * <code>optional int64 end_time = 4;</code>
     */
    long getEndTime();

    // optional string user = 5;
    /**
     * <code>optional string user = 5;</code>
     */
    boolean hasUser();
    /**
     * <code>optional string user = 5;</code>
     */
    java.lang.String getUser();
    /**
     * <code>optional string user = 5;</code>
     */
    com.google.protobuf.ByteString
        getUserBytes();

    // optional bool contains_gangs = 6;
    /**
     * <code>optional bool contains_gangs = 6;</code>
     */
    boolean hasContainsGangs();
    /**
     * <code>optional bool contains_gangs = 6;</code>
     */
    boolean getContainsGangs();

    // optional int64 acceptance_time = 7;
    /**
     * <code>optional int64 acceptance_time = 7;</code>
     */
    boolean hasAcceptanceTime();
    /**
     * <code>optional int64 acceptance_time = 7;</code>
     */
    long getAcceptanceTime();

    // optional .hadoop.yarn.ReservationIdProto reservation_id = 8;
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
     */
    boolean hasReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationAllocationStateProto}
   */
  public static final class ReservationAllocationStateProto extends
      com.google.protobuf.GeneratedMessage
      implements ReservationAllocationStateProtoOrBuilder {
    // Use ReservationAllocationStateProto.newBuilder() to construct.
    private ReservationAllocationStateProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ReservationAllocationStateProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ReservationAllocationStateProto defaultInstance;
    public static ReservationAllocationStateProto getDefaultInstance() {
      return defaultInstance;
    }

    public ReservationAllocationStateProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationAllocationStateProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = reservationDefinition_.toBuilder();
              }
              reservationDefinition_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationDefinition_);
                reservationDefinition_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                allocationRequests_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              allocationRequests_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.PARSER, extensionRegistry));
              break;
            }
            case 24: {
              bitField0_ |= 0x00000002;
              startTime_ = input.readInt64();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000004;
              endTime_ = input.readInt64();
              break;
            }
            case 42: {
              bitField0_ |= 0x00000008;
              user_ = input.readBytes();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000010;
              containsGangs_ = input.readBool();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000020;
              acceptanceTime_ = input.readInt64();
              break;
            }
            case 66: {
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000040) == 0x00000040)) {
                subBuilder = reservationId_.toBuilder();
              }
              reservationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationId_);
                reservationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000040;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          allocationRequests_ = java.util.Collections.unmodifiableList(allocationRequests_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationAllocationStateProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationAllocationStateProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ReservationAllocationStateProto> PARSER =
        new com.google.protobuf.AbstractParser<ReservationAllocationStateProto>() {
      public ReservationAllocationStateProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ReservationAllocationStateProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationAllocationStateProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;
    public static final int RESERVATION_DEFINITION_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto reservationDefinition_;
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    public boolean hasReservationDefinition() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getReservationDefinition() {
      return reservationDefinition_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder getReservationDefinitionOrBuilder() {
      return reservationDefinition_;
    }

    // repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;
    public static final int ALLOCATION_REQUESTS_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto> allocationRequests_;
    /**
     * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto> getAllocationRequestsList() {
      return allocationRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProtoOrBuilder> 
        getAllocationRequestsOrBuilderList() {
      return allocationRequests_;
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
     */
    public int getAllocationRequestsCount() {
      return allocationRequests_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto getAllocationRequests(int index) {
      return allocationRequests_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProtoOrBuilder getAllocationRequestsOrBuilder(
        int index) {
      return allocationRequests_.get(index);
    }

    // optional int64 start_time = 3;
    public static final int START_TIME_FIELD_NUMBER = 3;
    private long startTime_;
    /**
     * <code>optional int64 start_time = 3;</code>
     */
    public boolean hasStartTime() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 start_time = 3;</code>
     */
    public long getStartTime() {
      return startTime_;
    }

    // optional int64 end_time = 4;
    public static final int END_TIME_FIELD_NUMBER = 4;
    private long endTime_;
    /**
     * <code>optional int64 end_time = 4;</code>
     */
    public boolean hasEndTime() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 end_time = 4;</code>
     */
    public long getEndTime() {
      return endTime_;
    }

    // optional string user = 5;
    public static final int USER_FIELD_NUMBER = 5;
    private java.lang.Object user_;
    /**
     * <code>optional string user = 5;</code>
     */
    public boolean hasUser() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string user = 5;</code>
     */
    public java.lang.String getUser() {
      java.lang.Object ref = user_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          user_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string user = 5;</code>
     */
    public com.google.protobuf.ByteString
        getUserBytes() {
      java.lang.Object ref = user_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        user_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional bool contains_gangs = 6;
    public static final int CONTAINS_GANGS_FIELD_NUMBER = 6;
    private boolean containsGangs_;
    /**
     * <code>optional bool contains_gangs = 6;</code>
     */
    public boolean hasContainsGangs() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional bool contains_gangs = 6;</code>
     */
    public boolean getContainsGangs() {
      return containsGangs_;
    }

    // optional int64 acceptance_time = 7;
    public static final int ACCEPTANCE_TIME_FIELD_NUMBER = 7;
    private long acceptanceTime_;
    /**
     * <code>optional int64 acceptance_time = 7;</code>
     */
    public boolean hasAcceptanceTime() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int64 acceptance_time = 7;</code>
     */
    public long getAcceptanceTime() {
      return acceptanceTime_;
    }

    // optional .hadoop.yarn.ReservationIdProto reservation_id = 8;
    public static final int RESERVATION_ID_FIELD_NUMBER = 8;
    private org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_;
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
     */
    public boolean hasReservationId() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
      return reservationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
      return reservationId_;
    }

    private void initFields() {
      reservationDefinition_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance();
      allocationRequests_ = java.util.Collections.emptyList();
      startTime_ = 0L;
      endTime_ = 0L;
      user_ = "";
      containsGangs_ = false;
      acceptanceTime_ = 0L;
      reservationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, reservationDefinition_);
      }
      for (int i = 0; i < allocationRequests_.size(); i++) {
        output.writeMessage(2, allocationRequests_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(3, startTime_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(4, endTime_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(5, getUserBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(6, containsGangs_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt64(7, acceptanceTime_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeMessage(8, reservationId_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, reservationDefinition_);
      }
      for (int i = 0; i < allocationRequests_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, allocationRequests_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, startTime_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(4, endTime_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(5, getUserBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, containsGangs_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(7, acceptanceTime_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, reservationId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto) obj;

      boolean result = true;
      result = result && (hasReservationDefinition() == other.hasReservationDefinition());
      if (hasReservationDefinition()) {
        result = result && getReservationDefinition()
            .equals(other.getReservationDefinition());
      }
      result = result && getAllocationRequestsList()
          .equals(other.getAllocationRequestsList());
      result = result && (hasStartTime() == other.hasStartTime());
      if (hasStartTime()) {
        result = result && (getStartTime()
            == other.getStartTime());
      }
      result = result && (hasEndTime() == other.hasEndTime());
      if (hasEndTime()) {
        result = result && (getEndTime()
            == other.getEndTime());
      }
      result = result && (hasUser() == other.hasUser());
      if (hasUser()) {
        result = result && getUser()
            .equals(other.getUser());
      }
      result = result && (hasContainsGangs() == other.hasContainsGangs());
      if (hasContainsGangs()) {
        result = result && (getContainsGangs()
            == other.getContainsGangs());
      }
      result = result && (hasAcceptanceTime() == other.hasAcceptanceTime());
      if (hasAcceptanceTime()) {
        result = result && (getAcceptanceTime()
            == other.getAcceptanceTime());
      }
      result = result && (hasReservationId() == other.hasReservationId());
      if (hasReservationId()) {
        result = result && getReservationId()
            .equals(other.getReservationId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasReservationDefinition()) {
        hash = (37 * hash) + RESERVATION_DEFINITION_FIELD_NUMBER;
        hash = (53 * hash) + getReservationDefinition().hashCode();
      }
      if (getAllocationRequestsCount() > 0) {
        hash = (37 * hash) + ALLOCATION_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getAllocationRequestsList().hashCode();
      }
      if (hasStartTime()) {
        hash = (37 * hash) + START_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getStartTime());
      }
      if (hasEndTime()) {
        hash = (37 * hash) + END_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getEndTime());
      }
      if (hasUser()) {
        hash = (37 * hash) + USER_FIELD_NUMBER;
        hash = (53 * hash) + getUser().hashCode();
      }
      if (hasContainsGangs()) {
        hash = (37 * hash) + CONTAINS_GANGS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getContainsGangs());
      }
      if (hasAcceptanceTime()) {
        hash = (37 * hash) + ACCEPTANCE_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getAcceptanceTime());
      }
      if (hasReservationId()) {
        hash = (37 * hash) + RESERVATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getReservationId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationAllocationStateProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationAllocationStateProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationAllocationStateProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getReservationDefinitionFieldBuilder();
          getAllocationRequestsFieldBuilder();
          getReservationIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinition_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance();
        } else {
          reservationDefinitionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (allocationRequestsBuilder_ == null) {
          allocationRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          allocationRequestsBuilder_.clear();
        }
        startTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        endTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        user_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        containsGangs_ = false;
        bitField0_ = (bitField0_ & ~0x00000020);
        acceptanceTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000040);
        if (reservationIdBuilder_ == null) {
          reservationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance();
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationAllocationStateProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (reservationDefinitionBuilder_ == null) {
          result.reservationDefinition_ = reservationDefinition_;
        } else {
          result.reservationDefinition_ = reservationDefinitionBuilder_.build();
        }
        if (allocationRequestsBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            allocationRequests_ = java.util.Collections.unmodifiableList(allocationRequests_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.allocationRequests_ = allocationRequests_;
        } else {
          result.allocationRequests_ = allocationRequestsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        result.startTime_ = startTime_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000004;
        }
        result.endTime_ = endTime_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000008;
        }
        result.user_ = user_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000010;
        }
        result.containsGangs_ = containsGangs_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000020;
        }
        result.acceptanceTime_ = acceptanceTime_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000040;
        }
        if (reservationIdBuilder_ == null) {
          result.reservationId_ = reservationId_;
        } else {
          result.reservationId_ = reservationIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto.getDefaultInstance()) return this;
        if (other.hasReservationDefinition()) {
          mergeReservationDefinition(other.getReservationDefinition());
        }
        if (allocationRequestsBuilder_ == null) {
          if (!other.allocationRequests_.isEmpty()) {
            if (allocationRequests_.isEmpty()) {
              allocationRequests_ = other.allocationRequests_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureAllocationRequestsIsMutable();
              allocationRequests_.addAll(other.allocationRequests_);
            }
            onChanged();
          }
        } else {
          if (!other.allocationRequests_.isEmpty()) {
            if (allocationRequestsBuilder_.isEmpty()) {
              allocationRequestsBuilder_.dispose();
              allocationRequestsBuilder_ = null;
              allocationRequests_ = other.allocationRequests_;
              bitField0_ = (bitField0_ & ~0x00000002);
              allocationRequestsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAllocationRequestsFieldBuilder() : null;
            } else {
              allocationRequestsBuilder_.addAllMessages(other.allocationRequests_);
            }
          }
        }
        if (other.hasStartTime()) {
          setStartTime(other.getStartTime());
        }
        if (other.hasEndTime()) {
          setEndTime(other.getEndTime());
        }
        if (other.hasUser()) {
          bitField0_ |= 0x00000010;
          user_ = other.user_;
          onChanged();
        }
        if (other.hasContainsGangs()) {
          setContainsGangs(other.getContainsGangs());
        }
        if (other.hasAcceptanceTime()) {
          setAcceptanceTime(other.getAcceptanceTime());
        }
        if (other.hasReservationId()) {
          mergeReservationId(other.getReservationId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationAllocationStateProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto reservationDefinition_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder> reservationDefinitionBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public boolean hasReservationDefinition() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getReservationDefinition() {
        if (reservationDefinitionBuilder_ == null) {
          return reservationDefinition_;
        } else {
          return reservationDefinitionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public Builder setReservationDefinition(org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto value) {
        if (reservationDefinitionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationDefinition_ = value;
          onChanged();
        } else {
          reservationDefinitionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public Builder setReservationDefinition(
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder builderForValue) {
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinition_ = builderForValue.build();
          onChanged();
        } else {
          reservationDefinitionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public Builder mergeReservationDefinition(org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto value) {
        if (reservationDefinitionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              reservationDefinition_ != org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance()) {
            reservationDefinition_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.newBuilder(reservationDefinition_).mergeFrom(value).buildPartial();
          } else {
            reservationDefinition_ = value;
          }
          onChanged();
        } else {
          reservationDefinitionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public Builder clearReservationDefinition() {
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinition_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance();
          onChanged();
        } else {
          reservationDefinitionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder getReservationDefinitionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getReservationDefinitionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder getReservationDefinitionOrBuilder() {
        if (reservationDefinitionBuilder_ != null) {
          return reservationDefinitionBuilder_.getMessageOrBuilder();
        } else {
          return reservationDefinition_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationDefinitionProto reservation_definition = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder> 
          getReservationDefinitionFieldBuilder() {
        if (reservationDefinitionBuilder_ == null) {
          reservationDefinitionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder>(
                  reservationDefinition_,
                  getParentForChildren(),
                  isClean());
          reservationDefinition_ = null;
        }
        return reservationDefinitionBuilder_;
      }

      // repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto> allocationRequests_ =
        java.util.Collections.emptyList();
      private void ensureAllocationRequestsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          allocationRequests_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto>(allocationRequests_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProtoOrBuilder> allocationRequestsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto> getAllocationRequestsList() {
        if (allocationRequestsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(allocationRequests_);
        } else {
          return allocationRequestsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public int getAllocationRequestsCount() {
        if (allocationRequestsBuilder_ == null) {
          return allocationRequests_.size();
        } else {
          return allocationRequestsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto getAllocationRequests(int index) {
        if (allocationRequestsBuilder_ == null) {
          return allocationRequests_.get(index);
        } else {
          return allocationRequestsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public Builder setAllocationRequests(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto value) {
        if (allocationRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAllocationRequestsIsMutable();
          allocationRequests_.set(index, value);
          onChanged();
        } else {
          allocationRequestsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public Builder setAllocationRequests(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder builderForValue) {
        if (allocationRequestsBuilder_ == null) {
          ensureAllocationRequestsIsMutable();
          allocationRequests_.set(index, builderForValue.build());
          onChanged();
        } else {
          allocationRequestsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public Builder addAllocationRequests(org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto value) {
        if (allocationRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAllocationRequestsIsMutable();
          allocationRequests_.add(value);
          onChanged();
        } else {
          allocationRequestsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public Builder addAllocationRequests(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto value) {
        if (allocationRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAllocationRequestsIsMutable();
          allocationRequests_.add(index, value);
          onChanged();
        } else {
          allocationRequestsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public Builder addAllocationRequests(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder builderForValue) {
        if (allocationRequestsBuilder_ == null) {
          ensureAllocationRequestsIsMutable();
          allocationRequests_.add(builderForValue.build());
          onChanged();
        } else {
          allocationRequestsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public Builder addAllocationRequests(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder builderForValue) {
        if (allocationRequestsBuilder_ == null) {
          ensureAllocationRequestsIsMutable();
          allocationRequests_.add(index, builderForValue.build());
          onChanged();
        } else {
          allocationRequestsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public Builder addAllAllocationRequests(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto> values) {
        if (allocationRequestsBuilder_ == null) {
          ensureAllocationRequestsIsMutable();
          super.addAll(values, allocationRequests_);
          onChanged();
        } else {
          allocationRequestsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public Builder clearAllocationRequests() {
        if (allocationRequestsBuilder_ == null) {
          allocationRequests_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          allocationRequestsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public Builder removeAllocationRequests(int index) {
        if (allocationRequestsBuilder_ == null) {
          ensureAllocationRequestsIsMutable();
          allocationRequests_.remove(index);
          onChanged();
        } else {
          allocationRequestsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder getAllocationRequestsBuilder(
          int index) {
        return getAllocationRequestsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProtoOrBuilder getAllocationRequestsOrBuilder(
          int index) {
        if (allocationRequestsBuilder_ == null) {
          return allocationRequests_.get(index);  } else {
          return allocationRequestsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProtoOrBuilder> 
           getAllocationRequestsOrBuilderList() {
        if (allocationRequestsBuilder_ != null) {
          return allocationRequestsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(allocationRequests_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder addAllocationRequestsBuilder() {
        return getAllocationRequestsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder addAllocationRequestsBuilder(
          int index) {
        return getAllocationRequestsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ResourceAllocationRequestProto allocation_requests = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder> 
           getAllocationRequestsBuilderList() {
        return getAllocationRequestsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProtoOrBuilder> 
          getAllocationRequestsFieldBuilder() {
        if (allocationRequestsBuilder_ == null) {
          allocationRequestsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceAllocationRequestProtoOrBuilder>(
                  allocationRequests_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          allocationRequests_ = null;
        }
        return allocationRequestsBuilder_;
      }

      // optional int64 start_time = 3;
      private long startTime_ ;
      /**
       * <code>optional int64 start_time = 3;</code>
       */
      public boolean hasStartTime() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 start_time = 3;</code>
       */
      public long getStartTime() {
        return startTime_;
      }
      /**
       * <code>optional int64 start_time = 3;</code>
       */
      public Builder setStartTime(long value) {
        bitField0_ |= 0x00000004;
        startTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 start_time = 3;</code>
       */
      public Builder clearStartTime() {
        bitField0_ = (bitField0_ & ~0x00000004);
        startTime_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 end_time = 4;
      private long endTime_ ;
      /**
       * <code>optional int64 end_time = 4;</code>
       */
      public boolean hasEndTime() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int64 end_time = 4;</code>
       */
      public long getEndTime() {
        return endTime_;
      }
      /**
       * <code>optional int64 end_time = 4;</code>
       */
      public Builder setEndTime(long value) {
        bitField0_ |= 0x00000008;
        endTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 end_time = 4;</code>
       */
      public Builder clearEndTime() {
        bitField0_ = (bitField0_ & ~0x00000008);
        endTime_ = 0L;
        onChanged();
        return this;
      }

      // optional string user = 5;
      private java.lang.Object user_ = "";
      /**
       * <code>optional string user = 5;</code>
       */
      public boolean hasUser() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string user = 5;</code>
       */
      public java.lang.String getUser() {
        java.lang.Object ref = user_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          user_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string user = 5;</code>
       */
      public com.google.protobuf.ByteString
          getUserBytes() {
        java.lang.Object ref = user_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          user_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string user = 5;</code>
       */
      public Builder setUser(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        user_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string user = 5;</code>
       */
      public Builder clearUser() {
        bitField0_ = (bitField0_ & ~0x00000010);
        user_ = getDefaultInstance().getUser();
        onChanged();
        return this;
      }
      /**
       * <code>optional string user = 5;</code>
       */
      public Builder setUserBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        user_ = value;
        onChanged();
        return this;
      }

      // optional bool contains_gangs = 6;
      private boolean containsGangs_ ;
      /**
       * <code>optional bool contains_gangs = 6;</code>
       */
      public boolean hasContainsGangs() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional bool contains_gangs = 6;</code>
       */
      public boolean getContainsGangs() {
        return containsGangs_;
      }
      /**
       * <code>optional bool contains_gangs = 6;</code>
       */
      public Builder setContainsGangs(boolean value) {
        bitField0_ |= 0x00000020;
        containsGangs_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool contains_gangs = 6;</code>
       */
      public Builder clearContainsGangs() {
        bitField0_ = (bitField0_ & ~0x00000020);
        containsGangs_ = false;
        onChanged();
        return this;
      }

      // optional int64 acceptance_time = 7;
      private long acceptanceTime_ ;
      /**
       * <code>optional int64 acceptance_time = 7;</code>
       */
      public boolean hasAcceptanceTime() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional int64 acceptance_time = 7;</code>
       */
      public long getAcceptanceTime() {
        return acceptanceTime_;
      }
      /**
       * <code>optional int64 acceptance_time = 7;</code>
       */
      public Builder setAcceptanceTime(long value) {
        bitField0_ |= 0x00000040;
        acceptanceTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 acceptance_time = 7;</code>
       */
      public Builder clearAcceptanceTime() {
        bitField0_ = (bitField0_ & ~0x00000040);
        acceptanceTime_ = 0L;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ReservationIdProto reservation_id = 8;
      private org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> reservationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
       */
      public boolean hasReservationId() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
        if (reservationIdBuilder_ == null) {
          return reservationId_;
        } else {
          return reservationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
       */
      public Builder setReservationId(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationId_ = value;
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
       */
      public Builder setReservationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder builderForValue) {
        if (reservationIdBuilder_ == null) {
          reservationId_ = builderForValue.build();
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
       */
      public Builder mergeReservationId(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000080) == 0x00000080) &&
              reservationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance()) {
            reservationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.newBuilder(reservationId_).mergeFrom(value).buildPartial();
          } else {
            reservationId_ = value;
          }
          onChanged();
        } else {
          reservationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
       */
      public Builder clearReservationId() {
        if (reservationIdBuilder_ == null) {
          reservationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance();
          onChanged();
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder getReservationIdBuilder() {
        bitField0_ |= 0x00000080;
        onChanged();
        return getReservationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
        if (reservationIdBuilder_ != null) {
          return reservationIdBuilder_.getMessageOrBuilder();
        } else {
          return reservationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> 
          getReservationIdFieldBuilder() {
        if (reservationIdBuilder_ == null) {
          reservationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder>(
                  reservationId_,
                  getParentForChildren(),
                  isClean());
          reservationId_ = null;
        }
        return reservationIdBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationAllocationStateProto)
    }

    static {
      defaultInstance = new ReservationAllocationStateProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationAllocationStateProto)
  }

  public interface ContainerLaunchContextProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> 
        getLocalResourcesList();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index);
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    int getLocalResourcesCount();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
        getLocalResourcesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
        int index);

    // optional bytes tokens = 2;
    /**
     * <code>optional bytes tokens = 2;</code>
     */
    boolean hasTokens();
    /**
     * <code>optional bytes tokens = 2;</code>
     */
    com.google.protobuf.ByteString getTokens();

    // repeated .hadoop.yarn.StringBytesMapProto service_data = 3;
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> 
        getServiceDataList();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceData(int index);
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    int getServiceDataCount();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServiceDataOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceDataOrBuilder(
        int index);

    // repeated .hadoop.yarn.StringStringMapProto environment = 4;
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> 
        getEnvironmentList();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getEnvironment(int index);
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    int getEnvironmentCount();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
        getEnvironmentOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getEnvironmentOrBuilder(
        int index);

    // repeated string command = 5;
    /**
     * <code>repeated string command = 5;</code>
     */
    java.util.List<java.lang.String>
    getCommandList();
    /**
     * <code>repeated string command = 5;</code>
     */
    int getCommandCount();
    /**
     * <code>repeated string command = 5;</code>
     */
    java.lang.String getCommand(int index);
    /**
     * <code>repeated string command = 5;</code>
     */
    com.google.protobuf.ByteString
        getCommandBytes(int index);

    // repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> 
        getApplicationACLsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    int getApplicationACLsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
        getApplicationACLsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
        int index);

    // optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;
    /**
     * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
     */
    boolean hasContainerRetryContext();
    /**
     * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto getContainerRetryContext();
    /**
     * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProtoOrBuilder getContainerRetryContextOrBuilder();

    // optional bytes tokens_conf = 8;
    /**
     * <code>optional bytes tokens_conf = 8;</code>
     */
    boolean hasTokensConf();
    /**
     * <code>optional bytes tokens_conf = 8;</code>
     */
    com.google.protobuf.ByteString getTokensConf();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerLaunchContextProto}
   */
  public static final class ContainerLaunchContextProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerLaunchContextProtoOrBuilder {
    // Use ContainerLaunchContextProto.newBuilder() to construct.
    private ContainerLaunchContextProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerLaunchContextProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerLaunchContextProto defaultInstance;
    public static ContainerLaunchContextProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerLaunchContextProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerLaunchContextProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                localResources_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              localResources_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              bitField0_ |= 0x00000001;
              tokens_ = input.readBytes();
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                serviceData_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto>();
                mutable_bitField0_ |= 0x00000004;
              }
              serviceData_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.PARSER, extensionRegistry));
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                environment_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto>();
                mutable_bitField0_ |= 0x00000008;
              }
              environment_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.PARSER, extensionRegistry));
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                command_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000010;
              }
              command_.add(input.readBytes());
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                applicationACLs_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              applicationACLs_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.PARSER, extensionRegistry));
              break;
            }
            case 58: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = containerRetryContext_.toBuilder();
              }
              containerRetryContext_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerRetryContext_);
                containerRetryContext_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 66: {
              bitField0_ |= 0x00000004;
              tokensConf_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          localResources_ = java.util.Collections.unmodifiableList(localResources_);
        }
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          serviceData_ = java.util.Collections.unmodifiableList(serviceData_);
        }
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          environment_ = java.util.Collections.unmodifiableList(environment_);
        }
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          command_ = new com.google.protobuf.UnmodifiableLazyStringList(command_);
        }
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          applicationACLs_ = java.util.Collections.unmodifiableList(applicationACLs_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerLaunchContextProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerLaunchContextProto>() {
      public ContainerLaunchContextProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerLaunchContextProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerLaunchContextProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;
    public static final int LOCALRESOURCES_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> localResources_;
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> getLocalResourcesList() {
      return localResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
        getLocalResourcesOrBuilderList() {
      return localResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public int getLocalResourcesCount() {
      return localResources_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index) {
      return localResources_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
        int index) {
      return localResources_.get(index);
    }

    // optional bytes tokens = 2;
    public static final int TOKENS_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString tokens_;
    /**
     * <code>optional bytes tokens = 2;</code>
     */
    public boolean hasTokens() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bytes tokens = 2;</code>
     */
    public com.google.protobuf.ByteString getTokens() {
      return tokens_;
    }

    // repeated .hadoop.yarn.StringBytesMapProto service_data = 3;
    public static final int SERVICE_DATA_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> serviceData_;
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServiceDataList() {
      return serviceData_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServiceDataOrBuilderList() {
      return serviceData_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public int getServiceDataCount() {
      return serviceData_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceData(int index) {
      return serviceData_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceDataOrBuilder(
        int index) {
      return serviceData_.get(index);
    }

    // repeated .hadoop.yarn.StringStringMapProto environment = 4;
    public static final int ENVIRONMENT_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> environment_;
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> getEnvironmentList() {
      return environment_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
        getEnvironmentOrBuilderList() {
      return environment_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public int getEnvironmentCount() {
      return environment_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getEnvironment(int index) {
      return environment_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getEnvironmentOrBuilder(
        int index) {
      return environment_.get(index);
    }

    // repeated string command = 5;
    public static final int COMMAND_FIELD_NUMBER = 5;
    private com.google.protobuf.LazyStringList command_;
    /**
     * <code>repeated string command = 5;</code>
     */
    public java.util.List<java.lang.String>
        getCommandList() {
      return command_;
    }
    /**
     * <code>repeated string command = 5;</code>
     */
    public int getCommandCount() {
      return command_.size();
    }
    /**
     * <code>repeated string command = 5;</code>
     */
    public java.lang.String getCommand(int index) {
      return command_.get(index);
    }
    /**
     * <code>repeated string command = 5;</code>
     */
    public com.google.protobuf.ByteString
        getCommandBytes(int index) {
      return command_.getByteString(index);
    }

    // repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;
    public static final int APPLICATION_ACLS_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> applicationACLs_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> getApplicationACLsList() {
      return applicationACLs_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
        getApplicationACLsOrBuilderList() {
      return applicationACLs_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public int getApplicationACLsCount() {
      return applicationACLs_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index) {
      return applicationACLs_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
        int index) {
      return applicationACLs_.get(index);
    }

    // optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;
    public static final int CONTAINER_RETRY_CONTEXT_FIELD_NUMBER = 7;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto containerRetryContext_;
    /**
     * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
     */
    public boolean hasContainerRetryContext() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto getContainerRetryContext() {
      return containerRetryContext_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProtoOrBuilder getContainerRetryContextOrBuilder() {
      return containerRetryContext_;
    }

    // optional bytes tokens_conf = 8;
    public static final int TOKENS_CONF_FIELD_NUMBER = 8;
    private com.google.protobuf.ByteString tokensConf_;
    /**
     * <code>optional bytes tokens_conf = 8;</code>
     */
    public boolean hasTokensConf() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bytes tokens_conf = 8;</code>
     */
    public com.google.protobuf.ByteString getTokensConf() {
      return tokensConf_;
    }

    private void initFields() {
      localResources_ = java.util.Collections.emptyList();
      tokens_ = com.google.protobuf.ByteString.EMPTY;
      serviceData_ = java.util.Collections.emptyList();
      environment_ = java.util.Collections.emptyList();
      command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      applicationACLs_ = java.util.Collections.emptyList();
      containerRetryContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.getDefaultInstance();
      tokensConf_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < localResources_.size(); i++) {
        output.writeMessage(1, localResources_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(2, tokens_);
      }
      for (int i = 0; i < serviceData_.size(); i++) {
        output.writeMessage(3, serviceData_.get(i));
      }
      for (int i = 0; i < environment_.size(); i++) {
        output.writeMessage(4, environment_.get(i));
      }
      for (int i = 0; i < command_.size(); i++) {
        output.writeBytes(5, command_.getByteString(i));
      }
      for (int i = 0; i < applicationACLs_.size(); i++) {
        output.writeMessage(6, applicationACLs_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(7, containerRetryContext_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(8, tokensConf_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < localResources_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, localResources_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, tokens_);
      }
      for (int i = 0; i < serviceData_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, serviceData_.get(i));
      }
      for (int i = 0; i < environment_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, environment_.get(i));
      }
      {
        int dataSize = 0;
        for (int i = 0; i < command_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(command_.getByteString(i));
        }
        size += dataSize;
        size += 1 * getCommandList().size();
      }
      for (int i = 0; i < applicationACLs_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, applicationACLs_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, containerRetryContext_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(8, tokensConf_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto) obj;

      boolean result = true;
      result = result && getLocalResourcesList()
          .equals(other.getLocalResourcesList());
      result = result && (hasTokens() == other.hasTokens());
      if (hasTokens()) {
        result = result && getTokens()
            .equals(other.getTokens());
      }
      result = result && getServiceDataList()
          .equals(other.getServiceDataList());
      result = result && getEnvironmentList()
          .equals(other.getEnvironmentList());
      result = result && getCommandList()
          .equals(other.getCommandList());
      result = result && getApplicationACLsList()
          .equals(other.getApplicationACLsList());
      result = result && (hasContainerRetryContext() == other.hasContainerRetryContext());
      if (hasContainerRetryContext()) {
        result = result && getContainerRetryContext()
            .equals(other.getContainerRetryContext());
      }
      result = result && (hasTokensConf() == other.hasTokensConf());
      if (hasTokensConf()) {
        result = result && getTokensConf()
            .equals(other.getTokensConf());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getLocalResourcesCount() > 0) {
        hash = (37 * hash) + LOCALRESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getLocalResourcesList().hashCode();
      }
      if (hasTokens()) {
        hash = (37 * hash) + TOKENS_FIELD_NUMBER;
        hash = (53 * hash) + getTokens().hashCode();
      }
      if (getServiceDataCount() > 0) {
        hash = (37 * hash) + SERVICE_DATA_FIELD_NUMBER;
        hash = (53 * hash) + getServiceDataList().hashCode();
      }
      if (getEnvironmentCount() > 0) {
        hash = (37 * hash) + ENVIRONMENT_FIELD_NUMBER;
        hash = (53 * hash) + getEnvironmentList().hashCode();
      }
      if (getCommandCount() > 0) {
        hash = (37 * hash) + COMMAND_FIELD_NUMBER;
        hash = (53 * hash) + getCommandList().hashCode();
      }
      if (getApplicationACLsCount() > 0) {
        hash = (37 * hash) + APPLICATION_ACLS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationACLsList().hashCode();
      }
      if (hasContainerRetryContext()) {
        hash = (37 * hash) + CONTAINER_RETRY_CONTEXT_FIELD_NUMBER;
        hash = (53 * hash) + getContainerRetryContext().hashCode();
      }
      if (hasTokensConf()) {
        hash = (37 * hash) + TOKENS_CONF_FIELD_NUMBER;
        hash = (53 * hash) + getTokensConf().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerLaunchContextProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getLocalResourcesFieldBuilder();
          getServiceDataFieldBuilder();
          getEnvironmentFieldBuilder();
          getApplicationACLsFieldBuilder();
          getContainerRetryContextFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (localResourcesBuilder_ == null) {
          localResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          localResourcesBuilder_.clear();
        }
        tokens_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (serviceDataBuilder_ == null) {
          serviceData_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          serviceDataBuilder_.clear();
        }
        if (environmentBuilder_ == null) {
          environment_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          environmentBuilder_.clear();
        }
        command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000010);
        if (applicationACLsBuilder_ == null) {
          applicationACLs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          applicationACLsBuilder_.clear();
        }
        if (containerRetryContextBuilder_ == null) {
          containerRetryContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.getDefaultInstance();
        } else {
          containerRetryContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        tokensConf_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (localResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            localResources_ = java.util.Collections.unmodifiableList(localResources_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.localResources_ = localResources_;
        } else {
          result.localResources_ = localResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000001;
        }
        result.tokens_ = tokens_;
        if (serviceDataBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            serviceData_ = java.util.Collections.unmodifiableList(serviceData_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.serviceData_ = serviceData_;
        } else {
          result.serviceData_ = serviceDataBuilder_.build();
        }
        if (environmentBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            environment_ = java.util.Collections.unmodifiableList(environment_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.environment_ = environment_;
        } else {
          result.environment_ = environmentBuilder_.build();
        }
        if (((bitField0_ & 0x00000010) == 0x00000010)) {
          command_ = new com.google.protobuf.UnmodifiableLazyStringList(
              command_);
          bitField0_ = (bitField0_ & ~0x00000010);
        }
        result.command_ = command_;
        if (applicationACLsBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            applicationACLs_ = java.util.Collections.unmodifiableList(applicationACLs_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.applicationACLs_ = applicationACLs_;
        } else {
          result.applicationACLs_ = applicationACLsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000002;
        }
        if (containerRetryContextBuilder_ == null) {
          result.containerRetryContext_ = containerRetryContext_;
        } else {
          result.containerRetryContext_ = containerRetryContextBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000004;
        }
        result.tokensConf_ = tokensConf_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance()) return this;
        if (localResourcesBuilder_ == null) {
          if (!other.localResources_.isEmpty()) {
            if (localResources_.isEmpty()) {
              localResources_ = other.localResources_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureLocalResourcesIsMutable();
              localResources_.addAll(other.localResources_);
            }
            onChanged();
          }
        } else {
          if (!other.localResources_.isEmpty()) {
            if (localResourcesBuilder_.isEmpty()) {
              localResourcesBuilder_.dispose();
              localResourcesBuilder_ = null;
              localResources_ = other.localResources_;
              bitField0_ = (bitField0_ & ~0x00000001);
              localResourcesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getLocalResourcesFieldBuilder() : null;
            } else {
              localResourcesBuilder_.addAllMessages(other.localResources_);
            }
          }
        }
        if (other.hasTokens()) {
          setTokens(other.getTokens());
        }
        if (serviceDataBuilder_ == null) {
          if (!other.serviceData_.isEmpty()) {
            if (serviceData_.isEmpty()) {
              serviceData_ = other.serviceData_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureServiceDataIsMutable();
              serviceData_.addAll(other.serviceData_);
            }
            onChanged();
          }
        } else {
          if (!other.serviceData_.isEmpty()) {
            if (serviceDataBuilder_.isEmpty()) {
              serviceDataBuilder_.dispose();
              serviceDataBuilder_ = null;
              serviceData_ = other.serviceData_;
              bitField0_ = (bitField0_ & ~0x00000004);
              serviceDataBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getServiceDataFieldBuilder() : null;
            } else {
              serviceDataBuilder_.addAllMessages(other.serviceData_);
            }
          }
        }
        if (environmentBuilder_ == null) {
          if (!other.environment_.isEmpty()) {
            if (environment_.isEmpty()) {
              environment_ = other.environment_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureEnvironmentIsMutable();
              environment_.addAll(other.environment_);
            }
            onChanged();
          }
        } else {
          if (!other.environment_.isEmpty()) {
            if (environmentBuilder_.isEmpty()) {
              environmentBuilder_.dispose();
              environmentBuilder_ = null;
              environment_ = other.environment_;
              bitField0_ = (bitField0_ & ~0x00000008);
              environmentBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getEnvironmentFieldBuilder() : null;
            } else {
              environmentBuilder_.addAllMessages(other.environment_);
            }
          }
        }
        if (!other.command_.isEmpty()) {
          if (command_.isEmpty()) {
            command_ = other.command_;
            bitField0_ = (bitField0_ & ~0x00000010);
          } else {
            ensureCommandIsMutable();
            command_.addAll(other.command_);
          }
          onChanged();
        }
        if (applicationACLsBuilder_ == null) {
          if (!other.applicationACLs_.isEmpty()) {
            if (applicationACLs_.isEmpty()) {
              applicationACLs_ = other.applicationACLs_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureApplicationACLsIsMutable();
              applicationACLs_.addAll(other.applicationACLs_);
            }
            onChanged();
          }
        } else {
          if (!other.applicationACLs_.isEmpty()) {
            if (applicationACLsBuilder_.isEmpty()) {
              applicationACLsBuilder_.dispose();
              applicationACLsBuilder_ = null;
              applicationACLs_ = other.applicationACLs_;
              bitField0_ = (bitField0_ & ~0x00000020);
              applicationACLsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getApplicationACLsFieldBuilder() : null;
            } else {
              applicationACLsBuilder_.addAllMessages(other.applicationACLs_);
            }
          }
        }
        if (other.hasContainerRetryContext()) {
          mergeContainerRetryContext(other.getContainerRetryContext());
        }
        if (other.hasTokensConf()) {
          setTokensConf(other.getTokensConf());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> localResources_ =
        java.util.Collections.emptyList();
      private void ensureLocalResourcesIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          localResources_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto>(localResources_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> localResourcesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> getLocalResourcesList() {
        if (localResourcesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(localResources_);
        } else {
          return localResourcesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public int getLocalResourcesCount() {
        if (localResourcesBuilder_ == null) {
          return localResources_.size();
        } else {
          return localResourcesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index) {
        if (localResourcesBuilder_ == null) {
          return localResources_.get(index);
        } else {
          return localResourcesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder setLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.set(index, value);
          onChanged();
        } else {
          localResourcesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder setLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.set(index, builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.add(value);
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.add(index, value);
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(
          org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.add(builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.add(index, builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addAllLocalResources(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> values) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          super.addAll(values, localResources_);
          onChanged();
        } else {
          localResourcesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder clearLocalResources() {
        if (localResourcesBuilder_ == null) {
          localResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          localResourcesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder removeLocalResources(int index) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.remove(index);
          onChanged();
        } else {
          localResourcesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder getLocalResourcesBuilder(
          int index) {
        return getLocalResourcesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
          int index) {
        if (localResourcesBuilder_ == null) {
          return localResources_.get(index);  } else {
          return localResourcesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
           getLocalResourcesOrBuilderList() {
        if (localResourcesBuilder_ != null) {
          return localResourcesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(localResources_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder addLocalResourcesBuilder() {
        return getLocalResourcesFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder addLocalResourcesBuilder(
          int index) {
        return getLocalResourcesFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder> 
           getLocalResourcesBuilderList() {
        return getLocalResourcesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
          getLocalResourcesFieldBuilder() {
        if (localResourcesBuilder_ == null) {
          localResourcesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder>(
                  localResources_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          localResources_ = null;
        }
        return localResourcesBuilder_;
      }

      // optional bytes tokens = 2;
      private com.google.protobuf.ByteString tokens_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public boolean hasTokens() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public com.google.protobuf.ByteString getTokens() {
        return tokens_;
      }
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public Builder setTokens(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        tokens_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public Builder clearTokens() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tokens_ = getDefaultInstance().getTokens();
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.StringBytesMapProto service_data = 3;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> serviceData_ =
        java.util.Collections.emptyList();
      private void ensureServiceDataIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          serviceData_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto>(serviceData_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> serviceDataBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServiceDataList() {
        if (serviceDataBuilder_ == null) {
          return java.util.Collections.unmodifiableList(serviceData_);
        } else {
          return serviceDataBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public int getServiceDataCount() {
        if (serviceDataBuilder_ == null) {
          return serviceData_.size();
        } else {
          return serviceDataBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceData(int index) {
        if (serviceDataBuilder_ == null) {
          return serviceData_.get(index);
        } else {
          return serviceDataBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder setServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceDataIsMutable();
          serviceData_.set(index, value);
          onChanged();
        } else {
          serviceDataBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder setServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.set(index, builderForValue.build());
          onChanged();
        } else {
          serviceDataBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceDataIsMutable();
          serviceData_.add(value);
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceDataIsMutable();
          serviceData_.add(index, value);
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.add(builderForValue.build());
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.add(index, builderForValue.build());
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addAllServiceData(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> values) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          super.addAll(values, serviceData_);
          onChanged();
        } else {
          serviceDataBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder clearServiceData() {
        if (serviceDataBuilder_ == null) {
          serviceData_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          serviceDataBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder removeServiceData(int index) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.remove(index);
          onChanged();
        } else {
          serviceDataBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder getServiceDataBuilder(
          int index) {
        return getServiceDataFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceDataOrBuilder(
          int index) {
        if (serviceDataBuilder_ == null) {
          return serviceData_.get(index);  } else {
          return serviceDataBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
           getServiceDataOrBuilderList() {
        if (serviceDataBuilder_ != null) {
          return serviceDataBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(serviceData_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServiceDataBuilder() {
        return getServiceDataFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServiceDataBuilder(
          int index) {
        return getServiceDataFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder> 
           getServiceDataBuilderList() {
        return getServiceDataFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
          getServiceDataFieldBuilder() {
        if (serviceDataBuilder_ == null) {
          serviceDataBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder>(
                  serviceData_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          serviceData_ = null;
        }
        return serviceDataBuilder_;
      }

      // repeated .hadoop.yarn.StringStringMapProto environment = 4;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> environment_ =
        java.util.Collections.emptyList();
      private void ensureEnvironmentIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          environment_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto>(environment_);
          bitField0_ |= 0x00000008;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> environmentBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> getEnvironmentList() {
        if (environmentBuilder_ == null) {
          return java.util.Collections.unmodifiableList(environment_);
        } else {
          return environmentBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public int getEnvironmentCount() {
        if (environmentBuilder_ == null) {
          return environment_.size();
        } else {
          return environmentBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getEnvironment(int index) {
        if (environmentBuilder_ == null) {
          return environment_.get(index);
        } else {
          return environmentBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder setEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (environmentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEnvironmentIsMutable();
          environment_.set(index, value);
          onChanged();
        } else {
          environmentBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder setEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.set(index, builderForValue.build());
          onChanged();
        } else {
          environmentBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (environmentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEnvironmentIsMutable();
          environment_.add(value);
          onChanged();
        } else {
          environmentBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (environmentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEnvironmentIsMutable();
          environment_.add(index, value);
          onChanged();
        } else {
          environmentBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.add(builderForValue.build());
          onChanged();
        } else {
          environmentBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.add(index, builderForValue.build());
          onChanged();
        } else {
          environmentBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addAllEnvironment(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> values) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          super.addAll(values, environment_);
          onChanged();
        } else {
          environmentBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder clearEnvironment() {
        if (environmentBuilder_ == null) {
          environment_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          environmentBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder removeEnvironment(int index) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.remove(index);
          onChanged();
        } else {
          environmentBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder getEnvironmentBuilder(
          int index) {
        return getEnvironmentFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getEnvironmentOrBuilder(
          int index) {
        if (environmentBuilder_ == null) {
          return environment_.get(index);  } else {
          return environmentBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
           getEnvironmentOrBuilderList() {
        if (environmentBuilder_ != null) {
          return environmentBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(environment_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder addEnvironmentBuilder() {
        return getEnvironmentFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder addEnvironmentBuilder(
          int index) {
        return getEnvironmentFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder> 
           getEnvironmentBuilderList() {
        return getEnvironmentFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
          getEnvironmentFieldBuilder() {
        if (environmentBuilder_ == null) {
          environmentBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder>(
                  environment_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          environment_ = null;
        }
        return environmentBuilder_;
      }

      // repeated string command = 5;
      private com.google.protobuf.LazyStringList command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureCommandIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          command_ = new com.google.protobuf.LazyStringArrayList(command_);
          bitField0_ |= 0x00000010;
         }
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public java.util.List<java.lang.String>
          getCommandList() {
        return java.util.Collections.unmodifiableList(command_);
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public int getCommandCount() {
        return command_.size();
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public java.lang.String getCommand(int index) {
        return command_.get(index);
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public com.google.protobuf.ByteString
          getCommandBytes(int index) {
        return command_.getByteString(index);
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder setCommand(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureCommandIsMutable();
        command_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder addCommand(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureCommandIsMutable();
        command_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder addAllCommand(
          java.lang.Iterable<java.lang.String> values) {
        ensureCommandIsMutable();
        super.addAll(values, command_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder clearCommand() {
        command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000010);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder addCommandBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureCommandIsMutable();
        command_.add(value);
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> applicationACLs_ =
        java.util.Collections.emptyList();
      private void ensureApplicationACLsIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          applicationACLs_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto>(applicationACLs_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> applicationACLsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> getApplicationACLsList() {
        if (applicationACLsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applicationACLs_);
        } else {
          return applicationACLsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public int getApplicationACLsCount() {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.size();
        } else {
          return applicationACLsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index) {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.get(index);
        } else {
          return applicationACLsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder setApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.set(index, value);
          onChanged();
        } else {
          applicationACLsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder setApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(value);
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(index, value);
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addAllApplicationACLs(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> values) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          super.addAll(values, applicationACLs_);
          onChanged();
        } else {
          applicationACLsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder clearApplicationACLs() {
        if (applicationACLsBuilder_ == null) {
          applicationACLs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          applicationACLsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder removeApplicationACLs(int index) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.remove(index);
          onChanged();
        } else {
          applicationACLsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder getApplicationACLsBuilder(
          int index) {
        return getApplicationACLsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
          int index) {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.get(index);  } else {
          return applicationACLsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
           getApplicationACLsOrBuilderList() {
        if (applicationACLsBuilder_ != null) {
          return applicationACLsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applicationACLs_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder addApplicationACLsBuilder() {
        return getApplicationACLsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder addApplicationACLsBuilder(
          int index) {
        return getApplicationACLsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder> 
           getApplicationACLsBuilderList() {
        return getApplicationACLsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
          getApplicationACLsFieldBuilder() {
        if (applicationACLsBuilder_ == null) {
          applicationACLsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder>(
                  applicationACLs_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          applicationACLs_ = null;
        }
        return applicationACLsBuilder_;
      }

      // optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto containerRetryContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProtoOrBuilder> containerRetryContextBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
       */
      public boolean hasContainerRetryContext() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto getContainerRetryContext() {
        if (containerRetryContextBuilder_ == null) {
          return containerRetryContext_;
        } else {
          return containerRetryContextBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
       */
      public Builder setContainerRetryContext(org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto value) {
        if (containerRetryContextBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerRetryContext_ = value;
          onChanged();
        } else {
          containerRetryContextBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
       */
      public Builder setContainerRetryContext(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.Builder builderForValue) {
        if (containerRetryContextBuilder_ == null) {
          containerRetryContext_ = builderForValue.build();
          onChanged();
        } else {
          containerRetryContextBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
       */
      public Builder mergeContainerRetryContext(org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto value) {
        if (containerRetryContextBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040) &&
              containerRetryContext_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.getDefaultInstance()) {
            containerRetryContext_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.newBuilder(containerRetryContext_).mergeFrom(value).buildPartial();
          } else {
            containerRetryContext_ = value;
          }
          onChanged();
        } else {
          containerRetryContextBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
       */
      public Builder clearContainerRetryContext() {
        if (containerRetryContextBuilder_ == null) {
          containerRetryContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.getDefaultInstance();
          onChanged();
        } else {
          containerRetryContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.Builder getContainerRetryContextBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getContainerRetryContextFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProtoOrBuilder getContainerRetryContextOrBuilder() {
        if (containerRetryContextBuilder_ != null) {
          return containerRetryContextBuilder_.getMessageOrBuilder();
        } else {
          return containerRetryContext_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerRetryContextProto container_retry_context = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProtoOrBuilder> 
          getContainerRetryContextFieldBuilder() {
        if (containerRetryContextBuilder_ == null) {
          containerRetryContextBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProtoOrBuilder>(
                  containerRetryContext_,
                  getParentForChildren(),
                  isClean());
          containerRetryContext_ = null;
        }
        return containerRetryContextBuilder_;
      }

      // optional bytes tokens_conf = 8;
      private com.google.protobuf.ByteString tokensConf_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes tokens_conf = 8;</code>
       */
      public boolean hasTokensConf() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional bytes tokens_conf = 8;</code>
       */
      public com.google.protobuf.ByteString getTokensConf() {
        return tokensConf_;
      }
      /**
       * <code>optional bytes tokens_conf = 8;</code>
       */
      public Builder setTokensConf(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        tokensConf_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes tokens_conf = 8;</code>
       */
      public Builder clearTokensConf() {
        bitField0_ = (bitField0_ & ~0x00000080);
        tokensConf_ = getDefaultInstance().getTokensConf();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerLaunchContextProto)
    }

    static {
      defaultInstance = new ContainerLaunchContextProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerLaunchContextProto)
  }

  public interface ContainerStatusProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    // optional .hadoop.yarn.ContainerStateProto state = 2;
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    boolean hasState();
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getState();

    // optional string diagnostics = 3 [default = "N/A"];
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    boolean hasDiagnostics();
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    java.lang.String getDiagnostics();
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsBytes();

    // optional int32 exit_status = 4 [default = -1000];
    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    boolean hasExitStatus();
    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    int getExitStatus();

    // optional .hadoop.yarn.ResourceProto capability = 5;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    // optional .hadoop.yarn.ExecutionTypeProto executionType = 6 [default = GUARANTEED];
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 6 [default = GUARANTEED];</code>
     */
    boolean hasExecutionType();
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 6 [default = GUARANTEED];</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType();

    // repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> 
        getContainerAttributesList();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getContainerAttributes(int index);
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
     */
    int getContainerAttributesCount();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
        getContainerAttributesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getContainerAttributesOrBuilder(
        int index);

    // optional .hadoop.yarn.ContainerSubStateProto container_sub_state = 8;
    /**
     * <code>optional .hadoop.yarn.ContainerSubStateProto container_sub_state = 8;</code>
     */
    boolean hasContainerSubState();
    /**
     * <code>optional .hadoop.yarn.ContainerSubStateProto container_sub_state = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto getContainerSubState();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerStatusProto}
   */
  public static final class ContainerStatusProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerStatusProtoOrBuilder {
    // Use ContainerStatusProto.newBuilder() to construct.
    private ContainerStatusProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerStatusProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerStatusProto defaultInstance;
    public static ContainerStatusProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerStatusProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerStatusProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                state_ = value;
              }
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              diagnostics_ = input.readBytes();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              exitStatus_ = input.readInt32();
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 48: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(6, rawValue);
              } else {
                bitField0_ |= 0x00000020;
                executionType_ = value;
              }
              break;
            }
            case 58: {
              if (!((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
                containerAttributes_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto>();
                mutable_bitField0_ |= 0x00000040;
              }
              containerAttributes_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.PARSER, extensionRegistry));
              break;
            }
            case 64: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(8, rawValue);
              } else {
                bitField0_ |= 0x00000040;
                containerSubState_ = value;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
          containerAttributes_ = java.util.Collections.unmodifiableList(containerAttributes_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerStatusProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerStatusProto>() {
      public ContainerStatusProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerStatusProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerStatusProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }

    // optional .hadoop.yarn.ContainerStateProto state = 2;
    public static final int STATE_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto state_;
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    public boolean hasState() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getState() {
      return state_;
    }

    // optional string diagnostics = 3 [default = "N/A"];
    public static final int DIAGNOSTICS_FIELD_NUMBER = 3;
    private java.lang.Object diagnostics_;
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int32 exit_status = 4 [default = -1000];
    public static final int EXIT_STATUS_FIELD_NUMBER = 4;
    private int exitStatus_;
    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    public boolean hasExitStatus() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    public int getExitStatus() {
      return exitStatus_;
    }

    // optional .hadoop.yarn.ResourceProto capability = 5;
    public static final int CAPABILITY_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    // optional .hadoop.yarn.ExecutionTypeProto executionType = 6 [default = GUARANTEED];
    public static final int EXECUTIONTYPE_FIELD_NUMBER = 6;
    private org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto executionType_;
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 6 [default = GUARANTEED];</code>
     */
    public boolean hasExecutionType() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 6 [default = GUARANTEED];</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType() {
      return executionType_;
    }

    // repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;
    public static final int CONTAINER_ATTRIBUTES_FIELD_NUMBER = 7;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> containerAttributes_;
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> getContainerAttributesList() {
      return containerAttributes_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
        getContainerAttributesOrBuilderList() {
      return containerAttributes_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
     */
    public int getContainerAttributesCount() {
      return containerAttributes_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getContainerAttributes(int index) {
      return containerAttributes_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getContainerAttributesOrBuilder(
        int index) {
      return containerAttributes_.get(index);
    }

    // optional .hadoop.yarn.ContainerSubStateProto container_sub_state = 8;
    public static final int CONTAINER_SUB_STATE_FIELD_NUMBER = 8;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto containerSubState_;
    /**
     * <code>optional .hadoop.yarn.ContainerSubStateProto container_sub_state = 8;</code>
     */
    public boolean hasContainerSubState() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerSubStateProto container_sub_state = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto getContainerSubState() {
      return containerSubState_;
    }

    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      state_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
      diagnostics_ = "N/A";
      exitStatus_ = -1000;
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
      containerAttributes_ = java.util.Collections.emptyList();
      containerSubState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto.CSS_SCHEDULED;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, state_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt32(4, exitStatus_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, capability_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeEnum(6, executionType_.getNumber());
      }
      for (int i = 0; i < containerAttributes_.size(); i++) {
        output.writeMessage(7, containerAttributes_.get(i));
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeEnum(8, containerSubState_.getNumber());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, state_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, exitStatus_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, capability_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(6, executionType_.getNumber());
      }
      for (int i = 0; i < containerAttributes_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, containerAttributes_.get(i));
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(8, containerSubState_.getNumber());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasState() == other.hasState());
      if (hasState()) {
        result = result &&
            (getState() == other.getState());
      }
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result && (hasExitStatus() == other.hasExitStatus());
      if (hasExitStatus()) {
        result = result && (getExitStatus()
            == other.getExitStatus());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasExecutionType() == other.hasExecutionType());
      if (hasExecutionType()) {
        result = result &&
            (getExecutionType() == other.getExecutionType());
      }
      result = result && getContainerAttributesList()
          .equals(other.getContainerAttributesList());
      result = result && (hasContainerSubState() == other.hasContainerSubState());
      if (hasContainerSubState()) {
        result = result &&
            (getContainerSubState() == other.getContainerSubState());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getState());
      }
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      if (hasExitStatus()) {
        hash = (37 * hash) + EXIT_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getExitStatus();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasExecutionType()) {
        hash = (37 * hash) + EXECUTIONTYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getExecutionType());
      }
      if (getContainerAttributesCount() > 0) {
        hash = (37 * hash) + CONTAINER_ATTRIBUTES_FIELD_NUMBER;
        hash = (53 * hash) + getContainerAttributesList().hashCode();
      }
      if (hasContainerSubState()) {
        hash = (37 * hash) + CONTAINER_SUB_STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getContainerSubState());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerStatusProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getCapabilityFieldBuilder();
          getContainerAttributesFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        state_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
        bitField0_ = (bitField0_ & ~0x00000002);
        diagnostics_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000004);
        exitStatus_ = -1000;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
        bitField0_ = (bitField0_ & ~0x00000020);
        if (containerAttributesBuilder_ == null) {
          containerAttributes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
        } else {
          containerAttributesBuilder_.clear();
        }
        containerSubState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto.CSS_SCHEDULED;
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.state_ = state_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.diagnostics_ = diagnostics_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.exitStatus_ = exitStatus_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.executionType_ = executionType_;
        if (containerAttributesBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040)) {
            containerAttributes_ = java.util.Collections.unmodifiableList(containerAttributes_);
            bitField0_ = (bitField0_ & ~0x00000040);
          }
          result.containerAttributes_ = containerAttributes_;
        } else {
          result.containerAttributes_ = containerAttributesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000040;
        }
        result.containerSubState_ = containerSubState_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (other.hasDiagnostics()) {
          bitField0_ |= 0x00000004;
          diagnostics_ = other.diagnostics_;
          onChanged();
        }
        if (other.hasExitStatus()) {
          setExitStatus(other.getExitStatus());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasExecutionType()) {
          setExecutionType(other.getExecutionType());
        }
        if (containerAttributesBuilder_ == null) {
          if (!other.containerAttributes_.isEmpty()) {
            if (containerAttributes_.isEmpty()) {
              containerAttributes_ = other.containerAttributes_;
              bitField0_ = (bitField0_ & ~0x00000040);
            } else {
              ensureContainerAttributesIsMutable();
              containerAttributes_.addAll(other.containerAttributes_);
            }
            onChanged();
          }
        } else {
          if (!other.containerAttributes_.isEmpty()) {
            if (containerAttributesBuilder_.isEmpty()) {
              containerAttributesBuilder_.dispose();
              containerAttributesBuilder_ = null;
              containerAttributes_ = other.containerAttributes_;
              bitField0_ = (bitField0_ & ~0x00000040);
              containerAttributesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getContainerAttributesFieldBuilder() : null;
            } else {
              containerAttributesBuilder_.addAllMessages(other.containerAttributes_);
            }
          }
        }
        if (other.hasContainerSubState()) {
          setContainerSubState(other.getContainerSubState());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      // optional .hadoop.yarn.ContainerStateProto state = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto state_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public boolean hasState() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getState() {
        return state_;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public Builder setState(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        state_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000002);
        state_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
        onChanged();
        return this;
      }

      // optional string diagnostics = 3 [default = "N/A"];
      private java.lang.Object diagnostics_ = "N/A";
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          diagnostics_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsBytes() {
        java.lang.Object ref = diagnostics_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnostics_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder setDiagnostics(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000004);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        diagnostics_ = value;
        onChanged();
        return this;
      }

      // optional int32 exit_status = 4 [default = -1000];
      private int exitStatus_ = -1000;
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public boolean hasExitStatus() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public int getExitStatus() {
        return exitStatus_;
      }
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public Builder setExitStatus(int value) {
        bitField0_ |= 0x00000008;
        exitStatus_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public Builder clearExitStatus() {
        bitField0_ = (bitField0_ & ~0x00000008);
        exitStatus_ = -1000;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto capability = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // optional .hadoop.yarn.ExecutionTypeProto executionType = 6 [default = GUARANTEED];
      private org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 6 [default = GUARANTEED];</code>
       */
      public boolean hasExecutionType() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 6 [default = GUARANTEED];</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto getExecutionType() {
        return executionType_;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 6 [default = GUARANTEED];</code>
       */
      public Builder setExecutionType(org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000020;
        executionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ExecutionTypeProto executionType = 6 [default = GUARANTEED];</code>
       */
      public Builder clearExecutionType() {
        bitField0_ = (bitField0_ & ~0x00000020);
        executionType_ = org.apache.hadoop.yarn.proto.YarnProtos.ExecutionTypeProto.GUARANTEED;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> containerAttributes_ =
        java.util.Collections.emptyList();
      private void ensureContainerAttributesIsMutable() {
        if (!((bitField0_ & 0x00000040) == 0x00000040)) {
          containerAttributes_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto>(containerAttributes_);
          bitField0_ |= 0x00000040;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> containerAttributesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> getContainerAttributesList() {
        if (containerAttributesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(containerAttributes_);
        } else {
          return containerAttributesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public int getContainerAttributesCount() {
        if (containerAttributesBuilder_ == null) {
          return containerAttributes_.size();
        } else {
          return containerAttributesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getContainerAttributes(int index) {
        if (containerAttributesBuilder_ == null) {
          return containerAttributes_.get(index);
        } else {
          return containerAttributesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public Builder setContainerAttributes(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (containerAttributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerAttributesIsMutable();
          containerAttributes_.set(index, value);
          onChanged();
        } else {
          containerAttributesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public Builder setContainerAttributes(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (containerAttributesBuilder_ == null) {
          ensureContainerAttributesIsMutable();
          containerAttributes_.set(index, builderForValue.build());
          onChanged();
        } else {
          containerAttributesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public Builder addContainerAttributes(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (containerAttributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerAttributesIsMutable();
          containerAttributes_.add(value);
          onChanged();
        } else {
          containerAttributesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public Builder addContainerAttributes(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (containerAttributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerAttributesIsMutable();
          containerAttributes_.add(index, value);
          onChanged();
        } else {
          containerAttributesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public Builder addContainerAttributes(
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (containerAttributesBuilder_ == null) {
          ensureContainerAttributesIsMutable();
          containerAttributes_.add(builderForValue.build());
          onChanged();
        } else {
          containerAttributesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public Builder addContainerAttributes(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (containerAttributesBuilder_ == null) {
          ensureContainerAttributesIsMutable();
          containerAttributes_.add(index, builderForValue.build());
          onChanged();
        } else {
          containerAttributesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public Builder addAllContainerAttributes(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> values) {
        if (containerAttributesBuilder_ == null) {
          ensureContainerAttributesIsMutable();
          super.addAll(values, containerAttributes_);
          onChanged();
        } else {
          containerAttributesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public Builder clearContainerAttributes() {
        if (containerAttributesBuilder_ == null) {
          containerAttributes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
          onChanged();
        } else {
          containerAttributesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public Builder removeContainerAttributes(int index) {
        if (containerAttributesBuilder_ == null) {
          ensureContainerAttributesIsMutable();
          containerAttributes_.remove(index);
          onChanged();
        } else {
          containerAttributesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder getContainerAttributesBuilder(
          int index) {
        return getContainerAttributesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getContainerAttributesOrBuilder(
          int index) {
        if (containerAttributesBuilder_ == null) {
          return containerAttributes_.get(index);  } else {
          return containerAttributesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
           getContainerAttributesOrBuilderList() {
        if (containerAttributesBuilder_ != null) {
          return containerAttributesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(containerAttributes_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder addContainerAttributesBuilder() {
        return getContainerAttributesFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder addContainerAttributesBuilder(
          int index) {
        return getContainerAttributesFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto container_attributes = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder> 
           getContainerAttributesBuilderList() {
        return getContainerAttributesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
          getContainerAttributesFieldBuilder() {
        if (containerAttributesBuilder_ == null) {
          containerAttributesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder>(
                  containerAttributes_,
                  ((bitField0_ & 0x00000040) == 0x00000040),
                  getParentForChildren(),
                  isClean());
          containerAttributes_ = null;
        }
        return containerAttributesBuilder_;
      }

      // optional .hadoop.yarn.ContainerSubStateProto container_sub_state = 8;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto containerSubState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto.CSS_SCHEDULED;
      /**
       * <code>optional .hadoop.yarn.ContainerSubStateProto container_sub_state = 8;</code>
       */
      public boolean hasContainerSubState() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerSubStateProto container_sub_state = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto getContainerSubState() {
        return containerSubState_;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerSubStateProto container_sub_state = 8;</code>
       */
      public Builder setContainerSubState(org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000080;
        containerSubState_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerSubStateProto container_sub_state = 8;</code>
       */
      public Builder clearContainerSubState() {
        bitField0_ = (bitField0_ & ~0x00000080);
        containerSubState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerSubStateProto.CSS_SCHEDULED;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerStatusProto)
    }

    static {
      defaultInstance = new ContainerStatusProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerStatusProto)
  }

  public interface ContainerRetryContextProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerRetryPolicyProto retry_policy = 1 [default = NEVER_RETRY];
    /**
     * <code>optional .hadoop.yarn.ContainerRetryPolicyProto retry_policy = 1 [default = NEVER_RETRY];</code>
     */
    boolean hasRetryPolicy();
    /**
     * <code>optional .hadoop.yarn.ContainerRetryPolicyProto retry_policy = 1 [default = NEVER_RETRY];</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto getRetryPolicy();

    // repeated int32 error_codes = 2;
    /**
     * <code>repeated int32 error_codes = 2;</code>
     */
    java.util.List<java.lang.Integer> getErrorCodesList();
    /**
     * <code>repeated int32 error_codes = 2;</code>
     */
    int getErrorCodesCount();
    /**
     * <code>repeated int32 error_codes = 2;</code>
     */
    int getErrorCodes(int index);

    // optional int32 max_retries = 3 [default = 0];
    /**
     * <code>optional int32 max_retries = 3 [default = 0];</code>
     */
    boolean hasMaxRetries();
    /**
     * <code>optional int32 max_retries = 3 [default = 0];</code>
     */
    int getMaxRetries();

    // optional int32 retry_interval = 4 [default = 0];
    /**
     * <code>optional int32 retry_interval = 4 [default = 0];</code>
     */
    boolean hasRetryInterval();
    /**
     * <code>optional int32 retry_interval = 4 [default = 0];</code>
     */
    int getRetryInterval();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerRetryContextProto}
   */
  public static final class ContainerRetryContextProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerRetryContextProtoOrBuilder {
    // Use ContainerRetryContextProto.newBuilder() to construct.
    private ContainerRetryContextProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerRetryContextProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerRetryContextProto defaultInstance;
    public static ContainerRetryContextProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerRetryContextProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerRetryContextProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto value = org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                retryPolicy_ = value;
              }
              break;
            }
            case 16: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                errorCodes_ = new java.util.ArrayList<java.lang.Integer>();
                mutable_bitField0_ |= 0x00000002;
              }
              errorCodes_.add(input.readInt32());
              break;
            }
            case 18: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002) && input.getBytesUntilLimit() > 0) {
                errorCodes_ = new java.util.ArrayList<java.lang.Integer>();
                mutable_bitField0_ |= 0x00000002;
              }
              while (input.getBytesUntilLimit() > 0) {
                errorCodes_.add(input.readInt32());
              }
              input.popLimit(limit);
              break;
            }
            case 24: {
              bitField0_ |= 0x00000002;
              maxRetries_ = input.readInt32();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000004;
              retryInterval_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          errorCodes_ = java.util.Collections.unmodifiableList(errorCodes_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerRetryContextProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerRetryContextProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerRetryContextProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerRetryContextProto>() {
      public ContainerRetryContextProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerRetryContextProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerRetryContextProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerRetryPolicyProto retry_policy = 1 [default = NEVER_RETRY];
    public static final int RETRY_POLICY_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto retryPolicy_;
    /**
     * <code>optional .hadoop.yarn.ContainerRetryPolicyProto retry_policy = 1 [default = NEVER_RETRY];</code>
     */
    public boolean hasRetryPolicy() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerRetryPolicyProto retry_policy = 1 [default = NEVER_RETRY];</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto getRetryPolicy() {
      return retryPolicy_;
    }

    // repeated int32 error_codes = 2;
    public static final int ERROR_CODES_FIELD_NUMBER = 2;
    private java.util.List<java.lang.Integer> errorCodes_;
    /**
     * <code>repeated int32 error_codes = 2;</code>
     */
    public java.util.List<java.lang.Integer>
        getErrorCodesList() {
      return errorCodes_;
    }
    /**
     * <code>repeated int32 error_codes = 2;</code>
     */
    public int getErrorCodesCount() {
      return errorCodes_.size();
    }
    /**
     * <code>repeated int32 error_codes = 2;</code>
     */
    public int getErrorCodes(int index) {
      return errorCodes_.get(index);
    }

    // optional int32 max_retries = 3 [default = 0];
    public static final int MAX_RETRIES_FIELD_NUMBER = 3;
    private int maxRetries_;
    /**
     * <code>optional int32 max_retries = 3 [default = 0];</code>
     */
    public boolean hasMaxRetries() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 max_retries = 3 [default = 0];</code>
     */
    public int getMaxRetries() {
      return maxRetries_;
    }

    // optional int32 retry_interval = 4 [default = 0];
    public static final int RETRY_INTERVAL_FIELD_NUMBER = 4;
    private int retryInterval_;
    /**
     * <code>optional int32 retry_interval = 4 [default = 0];</code>
     */
    public boolean hasRetryInterval() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int32 retry_interval = 4 [default = 0];</code>
     */
    public int getRetryInterval() {
      return retryInterval_;
    }

    private void initFields() {
      retryPolicy_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto.NEVER_RETRY;
      errorCodes_ = java.util.Collections.emptyList();
      maxRetries_ = 0;
      retryInterval_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, retryPolicy_.getNumber());
      }
      for (int i = 0; i < errorCodes_.size(); i++) {
        output.writeInt32(2, errorCodes_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(3, maxRetries_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(4, retryInterval_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, retryPolicy_.getNumber());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < errorCodes_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeInt32SizeNoTag(errorCodes_.get(i));
        }
        size += dataSize;
        size += 1 * getErrorCodesList().size();
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, maxRetries_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, retryInterval_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto) obj;

      boolean result = true;
      result = result && (hasRetryPolicy() == other.hasRetryPolicy());
      if (hasRetryPolicy()) {
        result = result &&
            (getRetryPolicy() == other.getRetryPolicy());
      }
      result = result && getErrorCodesList()
          .equals(other.getErrorCodesList());
      result = result && (hasMaxRetries() == other.hasMaxRetries());
      if (hasMaxRetries()) {
        result = result && (getMaxRetries()
            == other.getMaxRetries());
      }
      result = result && (hasRetryInterval() == other.hasRetryInterval());
      if (hasRetryInterval()) {
        result = result && (getRetryInterval()
            == other.getRetryInterval());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRetryPolicy()) {
        hash = (37 * hash) + RETRY_POLICY_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getRetryPolicy());
      }
      if (getErrorCodesCount() > 0) {
        hash = (37 * hash) + ERROR_CODES_FIELD_NUMBER;
        hash = (53 * hash) + getErrorCodesList().hashCode();
      }
      if (hasMaxRetries()) {
        hash = (37 * hash) + MAX_RETRIES_FIELD_NUMBER;
        hash = (53 * hash) + getMaxRetries();
      }
      if (hasRetryInterval()) {
        hash = (37 * hash) + RETRY_INTERVAL_FIELD_NUMBER;
        hash = (53 * hash) + getRetryInterval();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerRetryContextProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerRetryContextProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerRetryContextProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        retryPolicy_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto.NEVER_RETRY;
        bitField0_ = (bitField0_ & ~0x00000001);
        errorCodes_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        maxRetries_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        retryInterval_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerRetryContextProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.retryPolicy_ = retryPolicy_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          errorCodes_ = java.util.Collections.unmodifiableList(errorCodes_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.errorCodes_ = errorCodes_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        result.maxRetries_ = maxRetries_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000004;
        }
        result.retryInterval_ = retryInterval_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto.getDefaultInstance()) return this;
        if (other.hasRetryPolicy()) {
          setRetryPolicy(other.getRetryPolicy());
        }
        if (!other.errorCodes_.isEmpty()) {
          if (errorCodes_.isEmpty()) {
            errorCodes_ = other.errorCodes_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureErrorCodesIsMutable();
            errorCodes_.addAll(other.errorCodes_);
          }
          onChanged();
        }
        if (other.hasMaxRetries()) {
          setMaxRetries(other.getMaxRetries());
        }
        if (other.hasRetryInterval()) {
          setRetryInterval(other.getRetryInterval());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryContextProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerRetryPolicyProto retry_policy = 1 [default = NEVER_RETRY];
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto retryPolicy_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto.NEVER_RETRY;
      /**
       * <code>optional .hadoop.yarn.ContainerRetryPolicyProto retry_policy = 1 [default = NEVER_RETRY];</code>
       */
      public boolean hasRetryPolicy() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerRetryPolicyProto retry_policy = 1 [default = NEVER_RETRY];</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto getRetryPolicy() {
        return retryPolicy_;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerRetryPolicyProto retry_policy = 1 [default = NEVER_RETRY];</code>
       */
      public Builder setRetryPolicy(org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        retryPolicy_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerRetryPolicyProto retry_policy = 1 [default = NEVER_RETRY];</code>
       */
      public Builder clearRetryPolicy() {
        bitField0_ = (bitField0_ & ~0x00000001);
        retryPolicy_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerRetryPolicyProto.NEVER_RETRY;
        onChanged();
        return this;
      }

      // repeated int32 error_codes = 2;
      private java.util.List<java.lang.Integer> errorCodes_ = java.util.Collections.emptyList();
      private void ensureErrorCodesIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          errorCodes_ = new java.util.ArrayList<java.lang.Integer>(errorCodes_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated int32 error_codes = 2;</code>
       */
      public java.util.List<java.lang.Integer>
          getErrorCodesList() {
        return java.util.Collections.unmodifiableList(errorCodes_);
      }
      /**
       * <code>repeated int32 error_codes = 2;</code>
       */
      public int getErrorCodesCount() {
        return errorCodes_.size();
      }
      /**
       * <code>repeated int32 error_codes = 2;</code>
       */
      public int getErrorCodes(int index) {
        return errorCodes_.get(index);
      }
      /**
       * <code>repeated int32 error_codes = 2;</code>
       */
      public Builder setErrorCodes(
          int index, int value) {
        ensureErrorCodesIsMutable();
        errorCodes_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated int32 error_codes = 2;</code>
       */
      public Builder addErrorCodes(int value) {
        ensureErrorCodesIsMutable();
        errorCodes_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated int32 error_codes = 2;</code>
       */
      public Builder addAllErrorCodes(
          java.lang.Iterable<? extends java.lang.Integer> values) {
        ensureErrorCodesIsMutable();
        super.addAll(values, errorCodes_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated int32 error_codes = 2;</code>
       */
      public Builder clearErrorCodes() {
        errorCodes_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }

      // optional int32 max_retries = 3 [default = 0];
      private int maxRetries_ ;
      /**
       * <code>optional int32 max_retries = 3 [default = 0];</code>
       */
      public boolean hasMaxRetries() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int32 max_retries = 3 [default = 0];</code>
       */
      public int getMaxRetries() {
        return maxRetries_;
      }
      /**
       * <code>optional int32 max_retries = 3 [default = 0];</code>
       */
      public Builder setMaxRetries(int value) {
        bitField0_ |= 0x00000004;
        maxRetries_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 max_retries = 3 [default = 0];</code>
       */
      public Builder clearMaxRetries() {
        bitField0_ = (bitField0_ & ~0x00000004);
        maxRetries_ = 0;
        onChanged();
        return this;
      }

      // optional int32 retry_interval = 4 [default = 0];
      private int retryInterval_ ;
      /**
       * <code>optional int32 retry_interval = 4 [default = 0];</code>
       */
      public boolean hasRetryInterval() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int32 retry_interval = 4 [default = 0];</code>
       */
      public int getRetryInterval() {
        return retryInterval_;
      }
      /**
       * <code>optional int32 retry_interval = 4 [default = 0];</code>
       */
      public Builder setRetryInterval(int value) {
        bitField0_ |= 0x00000008;
        retryInterval_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 retry_interval = 4 [default = 0];</code>
       */
      public Builder clearRetryInterval() {
        bitField0_ = (bitField0_ & ~0x00000008);
        retryInterval_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerRetryContextProto)
    }

    static {
      defaultInstance = new ContainerRetryContextProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerRetryContextProto)
  }

  public interface StringLocalResourceMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string key = 1;
    /**
     * <code>optional string key = 1;</code>
     */
    boolean hasKey();
    /**
     * <code>optional string key = 1;</code>
     */
    java.lang.String getKey();
    /**
     * <code>optional string key = 1;</code>
     */
    com.google.protobuf.ByteString
        getKeyBytes();

    // optional .hadoop.yarn.LocalResourceProto value = 2;
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getValue();
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder getValueOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.StringLocalResourceMapProto}
   *
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////
   * //// From common//////////////////////////////////////////////////////
   * //////////////////////////////////////////////////////////////////////
   * </pre>
   */
  public static final class StringLocalResourceMapProto extends
      com.google.protobuf.GeneratedMessage
      implements StringLocalResourceMapProtoOrBuilder {
    // Use StringLocalResourceMapProto.newBuilder() to construct.
    private StringLocalResourceMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private StringLocalResourceMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final StringLocalResourceMapProto defaultInstance;
    public static StringLocalResourceMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public StringLocalResourceMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private StringLocalResourceMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              key_ = input.readBytes();
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = value_.toBuilder();
              }
              value_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(value_);
                value_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<StringLocalResourceMapProto> PARSER =
        new com.google.protobuf.AbstractParser<StringLocalResourceMapProto>() {
      public StringLocalResourceMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new StringLocalResourceMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<StringLocalResourceMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string key = 1;
    public static final int KEY_FIELD_NUMBER = 1;
    private java.lang.Object key_;
    /**
     * <code>optional string key = 1;</code>
     */
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public java.lang.String getKey() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          key_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public com.google.protobuf.ByteString
        getKeyBytes() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        key_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.LocalResourceProto value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value_;
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getValue() {
      return value_;
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder getValueOrBuilder() {
      return value_;
    }

    private void initFields() {
      key_ = "";
      value_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, value_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto) obj;

      boolean result = true;
      result = result && (hasKey() == other.hasKey());
      if (hasKey()) {
        result = result && getKey()
            .equals(other.getKey());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StringLocalResourceMapProto}
     *
     * <pre>
     *&#47;/////////////////////////////////////////////////////////////////////
     * //// From common//////////////////////////////////////////////////////
     * //////////////////////////////////////////////////////////////////////
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getValueFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        key_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.key_ = key_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (valueBuilder_ == null) {
          result.value_ = value_;
        } else {
          result.value_ = valueBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance()) return this;
        if (other.hasKey()) {
          bitField0_ |= 0x00000001;
          key_ = other.key_;
          onChanged();
        }
        if (other.hasValue()) {
          mergeValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string key = 1;
      private java.lang.Object key_ = "";
      /**
       * <code>optional string key = 1;</code>
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public java.lang.String getKey() {
        java.lang.Object ref = key_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          key_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getKeyBytes() {
        java.lang.Object ref = key_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          key_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder clearKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        key_ = getDefaultInstance().getKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.LocalResourceProto value = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder> valueBuilder_;
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getValue() {
        if (valueBuilder_ == null) {
          return value_;
        } else {
          return valueBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder setValue(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value) {
        if (valueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          value_ = value;
          onChanged();
        } else {
          valueBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder setValue(
          org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder builderForValue) {
        if (valueBuilder_ == null) {
          value_ = builderForValue.build();
          onChanged();
        } else {
          valueBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder mergeValue(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value) {
        if (valueBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              value_ != org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance()) {
            value_ =
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.newBuilder(value_).mergeFrom(value).buildPartial();
          } else {
            value_ = value;
          }
          onChanged();
        } else {
          valueBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder clearValue() {
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance();
          onChanged();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder getValueBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getValueFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder getValueOrBuilder() {
        if (valueBuilder_ != null) {
          return valueBuilder_.getMessageOrBuilder();
        } else {
          return value_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder> 
          getValueFieldBuilder() {
        if (valueBuilder_ == null) {
          valueBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder>(
                  value_,
                  getParentForChildren(),
                  isClean());
          value_ = null;
        }
        return valueBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StringLocalResourceMapProto)
    }

    static {
      defaultInstance = new StringLocalResourceMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StringLocalResourceMapProto)
  }

  public interface StringStringMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string key = 1;
    /**
     * <code>optional string key = 1;</code>
     */
    boolean hasKey();
    /**
     * <code>optional string key = 1;</code>
     */
    java.lang.String getKey();
    /**
     * <code>optional string key = 1;</code>
     */
    com.google.protobuf.ByteString
        getKeyBytes();

    // optional string value = 2;
    /**
     * <code>optional string value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>optional string value = 2;</code>
     */
    java.lang.String getValue();
    /**
     * <code>optional string value = 2;</code>
     */
    com.google.protobuf.ByteString
        getValueBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.StringStringMapProto}
   */
  public static final class StringStringMapProto extends
      com.google.protobuf.GeneratedMessage
      implements StringStringMapProtoOrBuilder {
    // Use StringStringMapProto.newBuilder() to construct.
    private StringStringMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private StringStringMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final StringStringMapProto defaultInstance;
    public static StringStringMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public StringStringMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private StringStringMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              key_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              value_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<StringStringMapProto> PARSER =
        new com.google.protobuf.AbstractParser<StringStringMapProto>() {
      public StringStringMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new StringStringMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<StringStringMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string key = 1;
    public static final int KEY_FIELD_NUMBER = 1;
    private java.lang.Object key_;
    /**
     * <code>optional string key = 1;</code>
     */
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public java.lang.String getKey() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          key_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public com.google.protobuf.ByteString
        getKeyBytes() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        key_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private java.lang.Object value_;
    /**
     * <code>optional string value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string value = 2;</code>
     */
    public java.lang.String getValue() {
      java.lang.Object ref = value_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          value_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string value = 2;</code>
     */
    public com.google.protobuf.ByteString
        getValueBytes() {
      java.lang.Object ref = value_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        value_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      key_ = "";
      value_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getValueBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getValueBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto) obj;

      boolean result = true;
      result = result && (hasKey() == other.hasKey());
      if (hasKey()) {
        result = result && getKey()
            .equals(other.getKey());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StringStringMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        key_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.key_ = key_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance()) return this;
        if (other.hasKey()) {
          bitField0_ |= 0x00000001;
          key_ = other.key_;
          onChanged();
        }
        if (other.hasValue()) {
          bitField0_ |= 0x00000002;
          value_ = other.value_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string key = 1;
      private java.lang.Object key_ = "";
      /**
       * <code>optional string key = 1;</code>
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public java.lang.String getKey() {
        java.lang.Object ref = key_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          key_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getKeyBytes() {
        java.lang.Object ref = key_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          key_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder clearKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        key_ = getDefaultInstance().getKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }

      // optional string value = 2;
      private java.lang.Object value_ = "";
      /**
       * <code>optional string value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public java.lang.String getValue() {
        java.lang.Object ref = value_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          value_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public com.google.protobuf.ByteString
          getValueBytes() {
        java.lang.Object ref = value_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          value_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public Builder setValue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public Builder setValueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StringStringMapProto)
    }

    static {
      defaultInstance = new StringStringMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StringStringMapProto)
  }

  public interface StringBytesMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string key = 1;
    /**
     * <code>optional string key = 1;</code>
     */
    boolean hasKey();
    /**
     * <code>optional string key = 1;</code>
     */
    java.lang.String getKey();
    /**
     * <code>optional string key = 1;</code>
     */
    com.google.protobuf.ByteString
        getKeyBytes();

    // optional bytes value = 2;
    /**
     * <code>optional bytes value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>optional bytes value = 2;</code>
     */
    com.google.protobuf.ByteString getValue();
  }
  /**
   * Protobuf type {@code hadoop.yarn.StringBytesMapProto}
   */
  public static final class StringBytesMapProto extends
      com.google.protobuf.GeneratedMessage
      implements StringBytesMapProtoOrBuilder {
    // Use StringBytesMapProto.newBuilder() to construct.
    private StringBytesMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private StringBytesMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final StringBytesMapProto defaultInstance;
    public static StringBytesMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public StringBytesMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private StringBytesMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              key_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              value_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<StringBytesMapProto> PARSER =
        new com.google.protobuf.AbstractParser<StringBytesMapProto>() {
      public StringBytesMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new StringBytesMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<StringBytesMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string key = 1;
    public static final int KEY_FIELD_NUMBER = 1;
    private java.lang.Object key_;
    /**
     * <code>optional string key = 1;</code>
     */
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public java.lang.String getKey() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          key_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public com.google.protobuf.ByteString
        getKeyBytes() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        key_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional bytes value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString value_;
    /**
     * <code>optional bytes value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bytes value = 2;</code>
     */
    public com.google.protobuf.ByteString getValue() {
      return value_;
    }

    private void initFields() {
      key_ = "";
      value_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, value_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto) obj;

      boolean result = true;
      result = result && (hasKey() == other.hasKey());
      if (hasKey()) {
        result = result && getKey()
            .equals(other.getKey());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StringBytesMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        key_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.key_ = key_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance()) return this;
        if (other.hasKey()) {
          bitField0_ |= 0x00000001;
          key_ = other.key_;
          onChanged();
        }
        if (other.hasValue()) {
          setValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string key = 1;
      private java.lang.Object key_ = "";
      /**
       * <code>optional string key = 1;</code>
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public java.lang.String getKey() {
        java.lang.Object ref = key_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          key_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getKeyBytes() {
        java.lang.Object ref = key_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          key_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder clearKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        key_ = getDefaultInstance().getKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }

      // optional bytes value = 2;
      private com.google.protobuf.ByteString value_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public com.google.protobuf.ByteString getValue() {
        return value_;
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public Builder setValue(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StringBytesMapProto)
    }

    static {
      defaultInstance = new StringBytesMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StringBytesMapProto)
  }

  public interface ContainerResourceIncreaseRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    // optional .hadoop.yarn.ResourceProto capability = 2;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseRequestProto}
   *
   * <pre>
   *&#47;////////////////////////////////////////////////////////////////////
   * ///// DEPRECATED ////////////////////////////////////////////////////
   * </pre>
   */
  public static final class ContainerResourceIncreaseRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerResourceIncreaseRequestProtoOrBuilder {
    // Use ContainerResourceIncreaseRequestProto.newBuilder() to construct.
    private ContainerResourceIncreaseRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerResourceIncreaseRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerResourceIncreaseRequestProto defaultInstance;
    public static ContainerResourceIncreaseRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerResourceIncreaseRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerResourceIncreaseRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerResourceIncreaseRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerResourceIncreaseRequestProto>() {
      public ContainerResourceIncreaseRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerResourceIncreaseRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerResourceIncreaseRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }

    // optional .hadoop.yarn.ResourceProto capability = 2;
    public static final int CAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, capability_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, capability_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseRequestProto}
     *
     * <pre>
     *&#47;////////////////////////////////////////////////////////////////////
     * ///// DEPRECATED ////////////////////////////////////////////////////
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getCapabilityFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto capability = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerResourceIncreaseRequestProto)
    }

    static {
      defaultInstance = new ContainerResourceIncreaseRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceIncreaseRequestProto)
  }

  public interface ContainerResourceIncreaseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    // optional .hadoop.yarn.ResourceProto capability = 2;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    // optional .hadoop.common.TokenProto container_token = 3;
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    boolean hasContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseProto}
   */
  public static final class ContainerResourceIncreaseProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerResourceIncreaseProtoOrBuilder {
    // Use ContainerResourceIncreaseProto.newBuilder() to construct.
    private ContainerResourceIncreaseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerResourceIncreaseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerResourceIncreaseProto defaultInstance;
    public static ContainerResourceIncreaseProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerResourceIncreaseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerResourceIncreaseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = containerToken_.toBuilder();
              }
              containerToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerToken_);
                containerToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerResourceIncreaseProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerResourceIncreaseProto>() {
      public ContainerResourceIncreaseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerResourceIncreaseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerResourceIncreaseProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }

    // optional .hadoop.yarn.ResourceProto capability = 2;
    public static final int CAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    // optional .hadoop.common.TokenProto container_token = 3;
    public static final int CONTAINER_TOKEN_FIELD_NUMBER = 3;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_;
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    public boolean hasContainerToken() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
      return containerToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
      return containerToken_;
    }

    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasContainerToken()) {
        if (!getContainerToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, capability_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, containerToken_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, capability_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, containerToken_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasContainerToken() == other.hasContainerToken());
      if (hasContainerToken()) {
        result = result && getContainerToken()
            .equals(other.getContainerToken());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasContainerToken()) {
        hash = (37 * hash) + CONTAINER_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getContainerToken().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getCapabilityFieldBuilder();
          getContainerTokenFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (containerTokenBuilder_ == null) {
          containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (containerTokenBuilder_ == null) {
          result.containerToken_ = containerToken_;
        } else {
          result.containerToken_ = containerTokenBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasContainerToken()) {
          mergeContainerToken(other.getContainerToken());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasContainerToken()) {
          if (!getContainerToken().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto capability = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // optional .hadoop.common.TokenProto container_token = 3;
      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> containerTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public boolean hasContainerToken() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
        if (containerTokenBuilder_ == null) {
          return containerToken_;
        } else {
          return containerTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder setContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerToken_ = value;
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder setContainerToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (containerTokenBuilder_ == null) {
          containerToken_ = builderForValue.build();
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder mergeContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              containerToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            containerToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(containerToken_).mergeFrom(value).buildPartial();
          } else {
            containerToken_ = value;
          }
          onChanged();
        } else {
          containerTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder clearContainerToken() {
        if (containerTokenBuilder_ == null) {
          containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
          onChanged();
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getContainerTokenBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getContainerTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
        if (containerTokenBuilder_ != null) {
          return containerTokenBuilder_.getMessageOrBuilder();
        } else {
          return containerToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getContainerTokenFieldBuilder() {
        if (containerTokenBuilder_ == null) {
          containerTokenBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  containerToken_,
                  getParentForChildren(),
                  isClean());
          containerToken_ = null;
        }
        return containerTokenBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerResourceIncreaseProto)
    }

    static {
      defaultInstance = new ContainerResourceIncreaseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceIncreaseProto)
  }

  public interface ContainerResourceDecreaseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    // optional .hadoop.yarn.ResourceProto capability = 2;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerResourceDecreaseProto}
   */
  public static final class ContainerResourceDecreaseProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerResourceDecreaseProtoOrBuilder {
    // Use ContainerResourceDecreaseProto.newBuilder() to construct.
    private ContainerResourceDecreaseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerResourceDecreaseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerResourceDecreaseProto defaultInstance;
    public static ContainerResourceDecreaseProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerResourceDecreaseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerResourceDecreaseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerResourceDecreaseProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerResourceDecreaseProto>() {
      public ContainerResourceDecreaseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerResourceDecreaseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerResourceDecreaseProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }

    // optional .hadoop.yarn.ResourceProto capability = 2;
    public static final int CAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, capability_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, capability_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerResourceDecreaseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getCapabilityFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto capability = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerResourceDecreaseProto)
    }

    static {
      defaultInstance = new ContainerResourceDecreaseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceDecreaseProto)
  }

  public interface CollectorInfoProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string collector_addr = 1;
    /**
     * <code>optional string collector_addr = 1;</code>
     */
    boolean hasCollectorAddr();
    /**
     * <code>optional string collector_addr = 1;</code>
     */
    java.lang.String getCollectorAddr();
    /**
     * <code>optional string collector_addr = 1;</code>
     */
    com.google.protobuf.ByteString
        getCollectorAddrBytes();

    // optional .hadoop.common.TokenProto collector_token = 2;
    /**
     * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
     */
    boolean hasCollectorToken();
    /**
     * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getCollectorToken();
    /**
     * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getCollectorTokenOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.CollectorInfoProto}
   */
  public static final class CollectorInfoProto extends
      com.google.protobuf.GeneratedMessage
      implements CollectorInfoProtoOrBuilder {
    // Use CollectorInfoProto.newBuilder() to construct.
    private CollectorInfoProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private CollectorInfoProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final CollectorInfoProto defaultInstance;
    public static CollectorInfoProto getDefaultInstance() {
      return defaultInstance;
    }

    public CollectorInfoProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private CollectorInfoProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              collectorAddr_ = input.readBytes();
              break;
            }
            case 18: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = collectorToken_.toBuilder();
              }
              collectorToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(collectorToken_);
                collectorToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_CollectorInfoProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_CollectorInfoProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto.Builder.class);
    }

    public static com.google.protobuf.Parser<CollectorInfoProto> PARSER =
        new com.google.protobuf.AbstractParser<CollectorInfoProto>() {
      public CollectorInfoProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CollectorInfoProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<CollectorInfoProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string collector_addr = 1;
    public static final int COLLECTOR_ADDR_FIELD_NUMBER = 1;
    private java.lang.Object collectorAddr_;
    /**
     * <code>optional string collector_addr = 1;</code>
     */
    public boolean hasCollectorAddr() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string collector_addr = 1;</code>
     */
    public java.lang.String getCollectorAddr() {
      java.lang.Object ref = collectorAddr_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          collectorAddr_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string collector_addr = 1;</code>
     */
    public com.google.protobuf.ByteString
        getCollectorAddrBytes() {
      java.lang.Object ref = collectorAddr_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        collectorAddr_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.common.TokenProto collector_token = 2;
    public static final int COLLECTOR_TOKEN_FIELD_NUMBER = 2;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto collectorToken_;
    /**
     * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
     */
    public boolean hasCollectorToken() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getCollectorToken() {
      return collectorToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getCollectorTokenOrBuilder() {
      return collectorToken_;
    }

    private void initFields() {
      collectorAddr_ = "";
      collectorToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasCollectorToken()) {
        if (!getCollectorToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getCollectorAddrBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, collectorToken_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getCollectorAddrBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, collectorToken_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto other = (org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto) obj;

      boolean result = true;
      result = result && (hasCollectorAddr() == other.hasCollectorAddr());
      if (hasCollectorAddr()) {
        result = result && getCollectorAddr()
            .equals(other.getCollectorAddr());
      }
      result = result && (hasCollectorToken() == other.hasCollectorToken());
      if (hasCollectorToken()) {
        result = result && getCollectorToken()
            .equals(other.getCollectorToken());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasCollectorAddr()) {
        hash = (37 * hash) + COLLECTOR_ADDR_FIELD_NUMBER;
        hash = (53 * hash) + getCollectorAddr().hashCode();
      }
      if (hasCollectorToken()) {
        hash = (37 * hash) + COLLECTOR_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getCollectorToken().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.CollectorInfoProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_CollectorInfoProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_CollectorInfoProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getCollectorTokenFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        collectorAddr_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (collectorTokenBuilder_ == null) {
          collectorToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
        } else {
          collectorTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_CollectorInfoProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto result = new org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.collectorAddr_ = collectorAddr_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (collectorTokenBuilder_ == null) {
          result.collectorToken_ = collectorToken_;
        } else {
          result.collectorToken_ = collectorTokenBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto.getDefaultInstance()) return this;
        if (other.hasCollectorAddr()) {
          bitField0_ |= 0x00000001;
          collectorAddr_ = other.collectorAddr_;
          onChanged();
        }
        if (other.hasCollectorToken()) {
          mergeCollectorToken(other.getCollectorToken());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasCollectorToken()) {
          if (!getCollectorToken().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.CollectorInfoProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string collector_addr = 1;
      private java.lang.Object collectorAddr_ = "";
      /**
       * <code>optional string collector_addr = 1;</code>
       */
      public boolean hasCollectorAddr() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string collector_addr = 1;</code>
       */
      public java.lang.String getCollectorAddr() {
        java.lang.Object ref = collectorAddr_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          collectorAddr_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string collector_addr = 1;</code>
       */
      public com.google.protobuf.ByteString
          getCollectorAddrBytes() {
        java.lang.Object ref = collectorAddr_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          collectorAddr_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string collector_addr = 1;</code>
       */
      public Builder setCollectorAddr(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        collectorAddr_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string collector_addr = 1;</code>
       */
      public Builder clearCollectorAddr() {
        bitField0_ = (bitField0_ & ~0x00000001);
        collectorAddr_ = getDefaultInstance().getCollectorAddr();
        onChanged();
        return this;
      }
      /**
       * <code>optional string collector_addr = 1;</code>
       */
      public Builder setCollectorAddrBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        collectorAddr_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.common.TokenProto collector_token = 2;
      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto collectorToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> collectorTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
       */
      public boolean hasCollectorToken() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getCollectorToken() {
        if (collectorTokenBuilder_ == null) {
          return collectorToken_;
        } else {
          return collectorTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
       */
      public Builder setCollectorToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (collectorTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          collectorToken_ = value;
          onChanged();
        } else {
          collectorTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
       */
      public Builder setCollectorToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (collectorTokenBuilder_ == null) {
          collectorToken_ = builderForValue.build();
          onChanged();
        } else {
          collectorTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
       */
      public Builder mergeCollectorToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (collectorTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              collectorToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            collectorToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(collectorToken_).mergeFrom(value).buildPartial();
          } else {
            collectorToken_ = value;
          }
          onChanged();
        } else {
          collectorTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
       */
      public Builder clearCollectorToken() {
        if (collectorTokenBuilder_ == null) {
          collectorToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
          onChanged();
        } else {
          collectorTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getCollectorTokenBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCollectorTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getCollectorTokenOrBuilder() {
        if (collectorTokenBuilder_ != null) {
          return collectorTokenBuilder_.getMessageOrBuilder();
        } else {
          return collectorToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto collector_token = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getCollectorTokenFieldBuilder() {
        if (collectorTokenBuilder_ == null) {
          collectorTokenBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  collectorToken_,
                  getParentForChildren(),
                  isClean());
          collectorToken_ = null;
        }
        return collectorTokenBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.CollectorInfoProto)
    }

    static {
      defaultInstance = new CollectorInfoProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.CollectorInfoProto)
  }

  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerIdProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceUtilizationProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceUtilizationProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PriorityProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerReportProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerReportProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_URLProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_URLProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_LocalResourceProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_AppTimeoutsMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_AppTimeoutsMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationTimeoutProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationTimeoutProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationAttemptReportProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeIdProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeReportProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeIdToLabelsProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_LabelsToNodeIdsProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_LabelsToNodeIdsProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeLabelProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeLabelProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_AMBlackListingRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_AMBlackListingRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ExecutionTypeRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ExecutionTypeRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationTimeoutMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationTimeoutMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationUpdateTimeoutMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationUpdateTimeoutMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_LogAggregationContextProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_LogAggregationContextProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_QueueStatisticsProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_QueueStatisticsProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_QueueInfoProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_QueueConfigurationsProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_QueueConfigurationsProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_QueueConfigurationsMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_QueueConfigurationsMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationIdProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationIdProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationRequestsProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationRequestsProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationDefinitionProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceAllocationRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceAllocationRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationAllocationStateProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationAllocationStateProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerRetryContextProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerRetryContextProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StringStringMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_CollectorInfoProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_CollectorInfoProto_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\021yarn_protos.proto\022\013hadoop.yarn\032\016Securi" +
      "ty.proto\"\204\001\n\030SerializedExceptionProto\022\017\n" +
      "\007message\030\001 \001(\t\022\r\n\005trace\030\002 \001(\t\022\022\n\nclass_n" +
      "ame\030\003 \001(\t\0224\n\005cause\030\004 \001(\0132%.hadoop.yarn.S" +
      "erializedExceptionProto\";\n\022ApplicationId" +
      "Proto\022\n\n\002id\030\001 \001(\005\022\031\n\021cluster_timestamp\030\002" +
      " \001(\003\"g\n\031ApplicationAttemptIdProto\0227\n\016app" +
      "lication_id\030\001 \001(\0132\037.hadoop.yarn.Applicat" +
      "ionIdProto\022\021\n\tattemptId\030\002 \001(\005\"\217\001\n\020Contai" +
      "nerIdProto\022/\n\006app_id\030\001 \001(\0132\037.hadoop.yarn",
      ".ApplicationIdProto\022>\n\016app_attempt_id\030\002 " +
      "\001(\0132&.hadoop.yarn.ApplicationAttemptIdPr" +
      "oto\022\n\n\002id\030\003 \001(\003\"6\n\rResourceProto\022\016\n\006memo" +
      "ry\030\001 \001(\003\022\025\n\rvirtual_cores\030\002 \001(\005\"C\n\030Resou" +
      "rceUtilizationProto\022\014\n\004pmem\030\001 \001(\005\022\014\n\004vme" +
      "m\030\002 \001(\005\022\013\n\003cpu\030\003 \001(\002\"`\n\023ResourceOptionPr" +
      "oto\022,\n\010resource\030\001 \001(\0132\032.hadoop.yarn.Reso" +
      "urceProto\022\033\n\023over_commit_timeout\030\002 \001(\005\"|" +
      "\n\024NodeResourceMapProto\022)\n\007node_id\030\001 \001(\0132" +
      "\030.hadoop.yarn.NodeIdProto\0229\n\017resource_op",
      "tion\030\002 \001(\0132 .hadoop.yarn.ResourceOptionP" +
      "roto\"!\n\rPriorityProto\022\020\n\010priority\030\001 \001(\005\"" +
      "\214\003\n\016ContainerProto\022)\n\002id\030\001 \001(\0132\035.hadoop." +
      "yarn.ContainerIdProto\022(\n\006nodeId\030\002 \001(\0132\030." +
      "hadoop.yarn.NodeIdProto\022\031\n\021node_http_add" +
      "ress\030\003 \001(\t\022,\n\010resource\030\004 \001(\0132\032.hadoop.ya" +
      "rn.ResourceProto\022,\n\010priority\030\005 \001(\0132\032.had" +
      "oop.yarn.PriorityProto\0222\n\017container_toke" +
      "n\030\006 \001(\0132\031.hadoop.common.TokenProto\022C\n\016ex" +
      "ecution_type\030\007 \001(\0162\037.hadoop.yarn.Executi",
      "onTypeProto:\nGUARANTEED\022!\n\025allocation_re" +
      "quest_id\030\010 \001(\003:\002-1\022\022\n\007version\030\t \001(\005:\0010\"\347" +
      "\003\n\024ContainerReportProto\0223\n\014container_id\030" +
      "\001 \001(\0132\035.hadoop.yarn.ContainerIdProto\022,\n\010" +
      "resource\030\002 \001(\0132\032.hadoop.yarn.ResourcePro" +
      "to\022)\n\007node_id\030\003 \001(\0132\030.hadoop.yarn.NodeId" +
      "Proto\022,\n\010priority\030\004 \001(\0132\032.hadoop.yarn.Pr" +
      "iorityProto\022\025\n\rcreation_time\030\005 \001(\003\022\023\n\013fi" +
      "nish_time\030\006 \001(\003\022\035\n\020diagnostics_info\030\007 \001(" +
      "\t:\003N/A\022\017\n\007log_url\030\010 \001(\t\022\035\n\025container_exi",
      "t_status\030\t \001(\005\0229\n\017container_state\030\n \001(\0162" +
      " .hadoop.yarn.ContainerStateProto\022\031\n\021nod" +
      "e_http_address\030\013 \001(\t\022B\n\rexecutionType\030\014 " +
      "\001(\0162\037.hadoop.yarn.ExecutionTypeProto:\nGU" +
      "ARANTEED\"V\n\010URLProto\022\016\n\006scheme\030\001 \001(\t\022\014\n\004" +
      "host\030\002 \001(\t\022\014\n\004port\030\003 \001(\005\022\014\n\004file\030\004 \001(\t\022\020" +
      "\n\010userInfo\030\005 \001(\t\"\215\002\n\022LocalResourceProto\022" +
      "\'\n\010resource\030\001 \001(\0132\025.hadoop.yarn.URLProto" +
      "\022\014\n\004size\030\002 \001(\003\022\021\n\ttimestamp\030\003 \001(\003\0221\n\004typ" +
      "e\030\004 \001(\0162#.hadoop.yarn.LocalResourceTypeP",
      "roto\022=\n\nvisibility\030\005 \001(\0162).hadoop.yarn.L" +
      "ocalResourceVisibilityProto\022\017\n\007pattern\030\006" +
      " \001(\t\022*\n\"should_be_uploaded_to_shared_cac" +
      "he\030\007 \001(\010\"\271\003\n#ApplicationResourceUsageRep" +
      "ortProto\022\033\n\023num_used_containers\030\001 \001(\005\022\037\n" +
      "\027num_reserved_containers\030\002 \001(\005\0222\n\016used_r" +
      "esources\030\003 \001(\0132\032.hadoop.yarn.ResourcePro" +
      "to\0226\n\022reserved_resources\030\004 \001(\0132\032.hadoop." +
      "yarn.ResourceProto\0224\n\020needed_resources\030\005" +
      " \001(\0132\032.hadoop.yarn.ResourceProto\022\026\n\016memo",
      "ry_seconds\030\006 \001(\003\022\025\n\rvcore_seconds\030\007 \001(\003\022" +
      "\036\n\026queue_usage_percentage\030\010 \001(\002\022 \n\030clust" +
      "er_usage_percentage\030\t \001(\002\022 \n\030preempted_m" +
      "emory_seconds\030\n \001(\003\022\037\n\027preempted_vcore_s" +
      "econds\030\013 \001(\003\"\372\007\n\026ApplicationReportProto\022" +
      "6\n\rapplicationId\030\001 \001(\0132\037.hadoop.yarn.App" +
      "licationIdProto\022\014\n\004user\030\002 \001(\t\022\r\n\005queue\030\003" +
      " \001(\t\022\014\n\004name\030\004 \001(\t\022\014\n\004host\030\005 \001(\t\022\020\n\010rpc_" +
      "port\030\006 \001(\005\0225\n\022client_to_am_token\030\007 \001(\0132\031" +
      ".hadoop.common.TokenProto\022F\n\026yarn_applic",
      "ation_state\030\010 \001(\0162&.hadoop.yarn.YarnAppl" +
      "icationStateProto\022\023\n\013trackingUrl\030\t \001(\t\022\030" +
      "\n\013diagnostics\030\n \001(\t:\003N/A\022\021\n\tstartTime\030\013 " +
      "\001(\003\022\022\n\nfinishTime\030\014 \001(\003\022J\n\030final_applica" +
      "tion_status\030\r \001(\0162(.hadoop.yarn.FinalApp" +
      "licationStatusProto\022L\n\022app_resource_Usag" +
      "e\030\016 \001(\01320.hadoop.yarn.ApplicationResourc" +
      "eUsageReportProto\022\033\n\023originalTrackingUrl" +
      "\030\017 \001(\t\022K\n\033currentApplicationAttemptId\030\020 " +
      "\001(\0132&.hadoop.yarn.ApplicationAttemptIdPr",
      "oto\022\020\n\010progress\030\021 \001(\002\022\027\n\017applicationType" +
      "\030\022 \001(\t\022.\n\013am_rm_token\030\023 \001(\0132\031.hadoop.com" +
      "mon.TokenProto\022\027\n\017applicationTags\030\024 \003(\t\022" +
      "F\n\026log_aggregation_status\030\025 \001(\0162&.hadoop" +
      ".yarn.LogAggregationStatusProto\022$\n\025unman" +
      "aged_application\030\026 \001(\010:\005false\022,\n\010priorit" +
      "y\030\027 \001(\0132\032.hadoop.yarn.PriorityProto\022\036\n\026a" +
      "ppNodeLabelExpression\030\030 \001(\t\022\035\n\025amNodeLab" +
      "elExpression\030\031 \001(\t\0225\n\013appTimeouts\030\032 \003(\0132" +
      " .hadoop.yarn.AppTimeoutsMapProto\"\244\001\n\023Ap",
      "pTimeoutsMapProto\022J\n\030application_timeout" +
      "_type\030\001 \001(\0162(.hadoop.yarn.ApplicationTim" +
      "eoutTypeProto\022A\n\023application_timeout\030\002 \001" +
      "(\0132$.hadoop.yarn.ApplicationTimeoutProto" +
      "\"\222\001\n\027ApplicationTimeoutProto\022J\n\030applicat" +
      "ion_timeout_type\030\001 \002(\0162(.hadoop.yarn.App" +
      "licationTimeoutTypeProto\022\023\n\013expire_time\030" +
      "\002 \001(\t\022\026\n\016remaining_time\030\003 \001(\003\"\214\003\n\035Applic" +
      "ationAttemptReportProto\022F\n\026application_a" +
      "ttempt_id\030\001 \001(\0132&.hadoop.yarn.Applicatio",
      "nAttemptIdProto\022\014\n\004host\030\002 \001(\t\022\020\n\010rpc_por" +
      "t\030\003 \001(\005\022\024\n\014tracking_url\030\004 \001(\t\022\030\n\013diagnos" +
      "tics\030\005 \001(\t:\003N/A\022U\n\036yarn_application_atte" +
      "mpt_state\030\006 \001(\0162-.hadoop.yarn.YarnApplic" +
      "ationAttemptStateProto\0226\n\017am_container_i" +
      "d\030\007 \001(\0132\035.hadoop.yarn.ContainerIdProto\022\035" +
      "\n\025original_tracking_url\030\010 \001(\t\022\021\n\tstartTi" +
      "me\030\t \001(\003\022\022\n\nfinishTime\030\n \001(\003\")\n\013NodeIdPr" +
      "oto\022\014\n\004host\030\001 \001(\t\022\014\n\004port\030\002 \001(\005\"\331\003\n\017Node" +
      "ReportProto\022(\n\006nodeId\030\001 \001(\0132\030.hadoop.yar",
      "n.NodeIdProto\022\023\n\013httpAddress\030\002 \001(\t\022\020\n\010ra" +
      "ckName\030\003 \001(\t\022(\n\004used\030\004 \001(\0132\032.hadoop.yarn" +
      ".ResourceProto\022.\n\ncapability\030\005 \001(\0132\032.had" +
      "oop.yarn.ResourceProto\022\025\n\rnumContainers\030" +
      "\006 \001(\005\022/\n\nnode_state\030\007 \001(\0162\033.hadoop.yarn." +
      "NodeStateProto\022\025\n\rhealth_report\030\010 \001(\t\022\037\n" +
      "\027last_health_report_time\030\t \001(\003\022\023\n\013node_l" +
      "abels\030\n \003(\t\022E\n\026containers_utilization\030\013 " +
      "\001(\0132%.hadoop.yarn.ResourceUtilizationPro" +
      "to\022?\n\020node_utilization\030\014 \001(\0132%.hadoop.ya",
      "rn.ResourceUtilizationProto\"S\n\023NodeIdToL" +
      "abelsProto\022(\n\006nodeId\030\001 \001(\0132\030.hadoop.yarn" +
      ".NodeIdProto\022\022\n\nnodeLabels\030\002 \003(\t\"T\n\024Labe" +
      "lsToNodeIdsProto\022\022\n\nnodeLabels\030\001 \001(\t\022(\n\006" +
      "nodeId\030\002 \003(\0132\030.hadoop.yarn.NodeIdProto\"9" +
      "\n\016NodeLabelProto\022\014\n\004name\030\001 \001(\t\022\031\n\013isExcl" +
      "usive\030\002 \001(\010:\004true\"i\n\032AMBlackListingReque" +
      "stProto\022#\n\024blacklisting_enabled\030\001 \001(\010:\005f" +
      "alse\022&\n\036blacklisting_failure_threshold\030\002" +
      " \001(\002\"\312\002\n\024ResourceRequestProto\022,\n\010priorit",
      "y\030\001 \001(\0132\032.hadoop.yarn.PriorityProto\022\025\n\rr" +
      "esource_name\030\002 \001(\t\022.\n\ncapability\030\003 \001(\0132\032" +
      ".hadoop.yarn.ResourceProto\022\026\n\016num_contai" +
      "ners\030\004 \001(\005\022\034\n\016relax_locality\030\005 \001(\010:\004true" +
      "\022\035\n\025node_label_expression\030\006 \001(\t\022F\n\026execu" +
      "tion_type_request\030\007 \001(\0132&.hadoop.yarn.Ex" +
      "ecutionTypeRequestProto\022 \n\025allocation_re" +
      "quest_id\030\010 \001(\003:\0010\"\207\001\n\031ExecutionTypeReque" +
      "stProto\022C\n\016execution_type\030\001 \001(\0162\037.hadoop" +
      ".yarn.ExecutionTypeProto:\nGUARANTEED\022%\n\026",
      "enforce_execution_type\030\002 \001(\010:\005false\"\224\001\n\026" +
      "PreemptionMessageProto\022B\n\016strictContract" +
      "\030\001 \001(\0132*.hadoop.yarn.StrictPreemptionCon" +
      "tractProto\0226\n\010contract\030\002 \001(\0132$.hadoop.ya" +
      "rn.PreemptionContractProto\"Y\n\035StrictPree" +
      "mptionContractProto\0228\n\tcontainer\030\001 \003(\0132%" +
      ".hadoop.yarn.PreemptionContainerProto\"\222\001" +
      "\n\027PreemptionContractProto\022=\n\010resource\030\001 " +
      "\003(\0132+.hadoop.yarn.PreemptionResourceRequ" +
      "estProto\0228\n\tcontainer\030\002 \003(\0132%.hadoop.yar",
      "n.PreemptionContainerProto\"E\n\030Preemption" +
      "ContainerProto\022)\n\002id\030\001 \001(\0132\035.hadoop.yarn" +
      ".ContainerIdProto\"U\n\036PreemptionResourceR" +
      "equestProto\0223\n\010resource\030\001 \001(\0132!.hadoop.y" +
      "arn.ResourceRequestProto\"X\n\035ResourceBlac" +
      "klistRequestProto\022\033\n\023blacklist_additions" +
      "\030\001 \003(\t\022\032\n\022blacklist_removals\030\002 \003(\t\"\356\006\n!A" +
      "pplicationSubmissionContextProto\0227\n\016appl" +
      "ication_id\030\001 \001(\0132\037.hadoop.yarn.Applicati" +
      "onIdProto\022\035\n\020application_name\030\002 \001(\t:\003N/A",
      "\022\026\n\005queue\030\003 \001(\t:\007default\022,\n\010priority\030\004 \001" +
      "(\0132\032.hadoop.yarn.PriorityProto\022C\n\021am_con" +
      "tainer_spec\030\005 \001(\0132(.hadoop.yarn.Containe" +
      "rLaunchContextProto\022)\n\033cancel_tokens_whe" +
      "n_complete\030\006 \001(\010:\004true\022\033\n\014unmanaged_am\030\007" +
      " \001(\010:\005false\022\031\n\016maxAppAttempts\030\010 \001(\005:\0010\022," +
      "\n\010resource\030\t \001(\0132\032.hadoop.yarn.ResourceP" +
      "roto\022\035\n\017applicationType\030\n \001(\t:\004YARN\022:\n+k" +
      "eep_containers_across_application_attemp" +
      "ts\030\013 \001(\010:\005false\022\027\n\017applicationTags\030\014 \003(\t",
      "\022.\n\"attempt_failures_validity_interval\030\r" +
      " \001(\003:\002-1\022H\n\027log_aggregation_context\030\016 \001(" +
      "\0132\'.hadoop.yarn.LogAggregationContextPro" +
      "to\0227\n\016reservation_id\030\017 \001(\0132\037.hadoop.yarn" +
      ".ReservationIdProto\022\035\n\025node_label_expres" +
      "sion\030\020 \001(\t\022H\n\035am_container_resource_requ" +
      "est\030\021 \003(\0132!.hadoop.yarn.ResourceRequestP" +
      "roto\022E\n\024application_timeouts\030\022 \003(\0132\'.had" +
      "oop.yarn.ApplicationTimeoutMapProto\"y\n\032A" +
      "pplicationTimeoutMapProto\022J\n\030application",
      "_timeout_type\030\001 \001(\0162(.hadoop.yarn.Applic" +
      "ationTimeoutTypeProto\022\017\n\007timeout\030\002 \001(\003\"\203" +
      "\001\n ApplicationUpdateTimeoutMapProto\022J\n\030a" +
      "pplication_timeout_type\030\001 \001(\0162(.hadoop.y" +
      "arn.ApplicationTimeoutTypeProto\022\023\n\013expir" +
      "e_time\030\002 \001(\t\"\372\001\n\032LogAggregationContextPr" +
      "oto\022\033\n\017include_pattern\030\001 \001(\t:\002.*\022\031\n\017excl" +
      "ude_pattern\030\002 \001(\t:\000\022%\n\033rolled_logs_inclu" +
      "de_pattern\030\003 \001(\t:\000\022\'\n\033rolled_logs_exclud" +
      "e_pattern\030\004 \001(\t:\002.*\022)\n!log_aggregation_p",
      "olicy_class_name\030\005 \001(\t\022)\n!log_aggregatio" +
      "n_policy_parameters\030\006 \001(\t\"e\n\026Application" +
      "ACLMapProto\022;\n\naccessType\030\001 \001(\0162\'.hadoop" +
      ".yarn.ApplicationAccessTypeProto\022\016\n\003acl\030" +
      "\002 \001(\t:\001 \"\267\001\n\027YarnClusterMetricsProto\022\031\n\021" +
      "num_node_managers\030\001 \001(\005\022\036\n\026num_decommiss" +
      "ioned_nms\030\002 \001(\005\022\026\n\016num_active_nms\030\003 \001(\005\022" +
      "\024\n\014num_lost_nms\030\004 \001(\005\022\031\n\021num_unhealthy_n" +
      "ms\030\005 \001(\005\022\030\n\020num_rebooted_nms\030\006 \001(\005\"\336\003\n\024Q" +
      "ueueStatisticsProto\022\030\n\020numAppsSubmitted\030",
      "\001 \001(\003\022\026\n\016numAppsRunning\030\002 \001(\003\022\026\n\016numApps" +
      "Pending\030\003 \001(\003\022\030\n\020numAppsCompleted\030\004 \001(\003\022" +
      "\025\n\rnumAppsKilled\030\005 \001(\003\022\025\n\rnumAppsFailed\030" +
      "\006 \001(\003\022\026\n\016numActiveUsers\030\007 \001(\003\022\031\n\021availab" +
      "leMemoryMB\030\010 \001(\003\022\031\n\021allocatedMemoryMB\030\t " +
      "\001(\003\022\027\n\017pendingMemoryMB\030\n \001(\003\022\030\n\020reserved" +
      "MemoryMB\030\013 \001(\003\022\027\n\017availableVCores\030\014 \001(\003\022" +
      "\027\n\017allocatedVCores\030\r \001(\003\022\025\n\rpendingVCore" +
      "s\030\016 \001(\003\022\026\n\016reservedVCores\030\017 \001(\003\022\033\n\023alloc" +
      "atedContainers\030\020 \001(\003\022\031\n\021pendingContainer",
      "s\030\021 \001(\003\022\032\n\022reservedContainers\030\022 \001(\003\"\213\004\n\016" +
      "QueueInfoProto\022\021\n\tqueueName\030\001 \001(\t\022\020\n\010cap" +
      "acity\030\002 \001(\002\022\027\n\017maximumCapacity\030\003 \001(\002\022\027\n\017" +
      "currentCapacity\030\004 \001(\002\022+\n\005state\030\005 \001(\0162\034.h" +
      "adoop.yarn.QueueStateProto\0220\n\013childQueue" +
      "s\030\006 \003(\0132\033.hadoop.yarn.QueueInfoProto\0229\n\014" +
      "applications\030\007 \003(\0132#.hadoop.yarn.Applica" +
      "tionReportProto\022\034\n\024accessibleNodeLabels\030" +
      "\010 \003(\t\022\"\n\032defaultNodeLabelExpression\030\t \001(" +
      "\t\022:\n\017queueStatistics\030\n \001(\0132!.hadoop.yarn",
      ".QueueStatisticsProto\022\032\n\022preemptionDisab" +
      "led\030\013 \001(\010\022H\n\026queueConfigurationsMap\030\014 \003(" +
      "\0132(.hadoop.yarn.QueueConfigurationsMapPr" +
      "oto\022$\n\034intraQueuePreemptionDisabled\030\r \001(" +
      "\010\"\221\001\n\030QueueConfigurationsProto\022\020\n\010capaci" +
      "ty\030\001 \001(\002\022\030\n\020absoluteCapacity\030\002 \001(\002\022\023\n\013ma" +
      "xCapacity\030\003 \001(\002\022\033\n\023absoluteMaxCapacity\030\004" +
      " \001(\002\022\027\n\017maxAMPercentage\030\005 \001(\002\"x\n\033QueueCo" +
      "nfigurationsMapProto\022\025\n\rpartitionName\030\001 " +
      "\002(\t\022B\n\023queueConfigurations\030\002 \001(\0132%.hadoo",
      "p.yarn.QueueConfigurationsProto\"X\n\025Queue" +
      "UserACLInfoProto\022\021\n\tqueueName\030\001 \001(\t\022,\n\010u" +
      "serAcls\030\002 \003(\0162\032.hadoop.yarn.QueueACLProt" +
      "o\";\n\022ReservationIdProto\022\n\n\002id\030\001 \001(\003\022\031\n\021c" +
      "luster_timestamp\030\002 \001(\003\"\222\001\n\027ReservationRe" +
      "questProto\022.\n\ncapability\030\001 \001(\0132\032.hadoop." +
      "yarn.ResourceProto\022\031\n\016num_containers\030\002 \001" +
      "(\005:\0011\022\026\n\013concurrency\030\003 \001(\005:\0011\022\024\n\010duratio" +
      "n\030\004 \001(\003:\002-1\"\254\001\n\030ReservationRequestsProto" +
      "\022C\n\025reservation_resources\030\001 \003(\0132$.hadoop",
      ".yarn.ReservationRequestProto\022K\n\013interpr" +
      "eter\030\002 \001(\0162/.hadoop.yarn.ReservationRequ" +
      "estInterpreterProto:\005R_ALL\"\356\001\n\032Reservati" +
      "onDefinitionProto\022C\n\024reservation_request" +
      "s\030\001 \001(\0132%.hadoop.yarn.ReservationRequest" +
      "sProto\022\017\n\007arrival\030\002 \001(\003\022\020\n\010deadline\030\003 \001(" +
      "\003\022\030\n\020reservation_name\030\004 \001(\t\022 \n\025recurrenc" +
      "e_expression\030\005 \001(\t:\0010\022,\n\010priority\030\006 \001(\0132" +
      "\032.hadoop.yarn.PriorityProto\"t\n\036ResourceA" +
      "llocationRequestProto\022\022\n\nstart_time\030\001 \001(",
      "\003\022\020\n\010end_time\030\002 \001(\003\022,\n\010resource\030\003 \001(\0132\032." +
      "hadoop.yarn.ResourceProto\"\322\002\n\037Reservatio" +
      "nAllocationStateProto\022G\n\026reservation_def" +
      "inition\030\001 \001(\0132\'.hadoop.yarn.ReservationD" +
      "efinitionProto\022H\n\023allocation_requests\030\002 " +
      "\003(\0132+.hadoop.yarn.ResourceAllocationRequ" +
      "estProto\022\022\n\nstart_time\030\003 \001(\003\022\020\n\010end_time" +
      "\030\004 \001(\003\022\014\n\004user\030\005 \001(\t\022\026\n\016contains_gangs\030\006" +
      " \001(\010\022\027\n\017acceptance_time\030\007 \001(\003\0227\n\016reserva" +
      "tion_id\030\010 \001(\0132\037.hadoop.yarn.ReservationI",
      "dProto\"\216\003\n\033ContainerLaunchContextProto\022@" +
      "\n\016localResources\030\001 \003(\0132(.hadoop.yarn.Str" +
      "ingLocalResourceMapProto\022\016\n\006tokens\030\002 \001(\014" +
      "\0226\n\014service_data\030\003 \003(\0132 .hadoop.yarn.Str" +
      "ingBytesMapProto\0226\n\013environment\030\004 \003(\0132!." +
      "hadoop.yarn.StringStringMapProto\022\017\n\007comm" +
      "and\030\005 \003(\t\022=\n\020application_ACLs\030\006 \003(\0132#.ha" +
      "doop.yarn.ApplicationACLMapProto\022H\n\027cont" +
      "ainer_retry_context\030\007 \001(\0132\'.hadoop.yarn." +
      "ContainerRetryContextProto\022\023\n\013tokens_con",
      "f\030\010 \001(\014\"\251\003\n\024ContainerStatusProto\0223\n\014cont" +
      "ainer_id\030\001 \001(\0132\035.hadoop.yarn.ContainerId" +
      "Proto\022/\n\005state\030\002 \001(\0162 .hadoop.yarn.Conta" +
      "inerStateProto\022\030\n\013diagnostics\030\003 \001(\t:\003N/A" +
      "\022\032\n\013exit_status\030\004 \001(\005:\005-1000\022.\n\ncapabili" +
      "ty\030\005 \001(\0132\032.hadoop.yarn.ResourceProto\022B\n\r" +
      "executionType\030\006 \001(\0162\037.hadoop.yarn.Execut" +
      "ionTypeProto:\nGUARANTEED\022?\n\024container_at" +
      "tributes\030\007 \003(\0132!.hadoop.yarn.StringStrin" +
      "gMapProto\022@\n\023container_sub_state\030\010 \001(\0162#",
      ".hadoop.yarn.ContainerSubStateProto\"\257\001\n\032" +
      "ContainerRetryContextProto\022I\n\014retry_poli" +
      "cy\030\001 \001(\0162&.hadoop.yarn.ContainerRetryPol" +
      "icyProto:\013NEVER_RETRY\022\023\n\013error_codes\030\002 \003" +
      "(\005\022\026\n\013max_retries\030\003 \001(\005:\0010\022\031\n\016retry_inte" +
      "rval\030\004 \001(\005:\0010\"Z\n\033StringLocalResourceMapP" +
      "roto\022\013\n\003key\030\001 \001(\t\022.\n\005value\030\002 \001(\0132\037.hadoo" +
      "p.yarn.LocalResourceProto\"2\n\024StringStrin" +
      "gMapProto\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t\"1\n" +
      "\023StringBytesMapProto\022\013\n\003key\030\001 \001(\t\022\r\n\005val",
      "ue\030\002 \001(\014\"\214\001\n%ContainerResourceIncreaseRe" +
      "questProto\0223\n\014container_id\030\001 \001(\0132\035.hadoo" +
      "p.yarn.ContainerIdProto\022.\n\ncapability\030\002 " +
      "\001(\0132\032.hadoop.yarn.ResourceProto\"\271\001\n\036Cont" +
      "ainerResourceIncreaseProto\0223\n\014container_" +
      "id\030\001 \001(\0132\035.hadoop.yarn.ContainerIdProto\022" +
      ".\n\ncapability\030\002 \001(\0132\032.hadoop.yarn.Resour" +
      "ceProto\0222\n\017container_token\030\003 \001(\0132\031.hadoo" +
      "p.common.TokenProto\"\205\001\n\036ContainerResourc" +
      "eDecreaseProto\0223\n\014container_id\030\001 \001(\0132\035.h",
      "adoop.yarn.ContainerIdProto\022.\n\ncapabilit" +
      "y\030\002 \001(\0132\032.hadoop.yarn.ResourceProto\"`\n\022C" +
      "ollectorInfoProto\022\026\n\016collector_addr\030\001 \001(" +
      "\t\0222\n\017collector_token\030\002 \001(\0132\031.hadoop.comm" +
      "on.TokenProto*?\n\023ContainerStateProto\022\t\n\005" +
      "C_NEW\020\001\022\r\n\tC_RUNNING\020\002\022\016\n\nC_COMPLETE\020\003*n" +
      "\n\026ContainerSubStateProto\022\021\n\rCSS_SCHEDULE" +
      "D\020\001\022\017\n\013CSS_RUNNING\020\002\022\016\n\nCSS_PAUSED\020\003\022\022\n\016" +
      "CSS_COMPLETING\020\004\022\014\n\010CSS_DONE\020\005*\204\001\n\031YarnA" +
      "pplicationStateProto\022\007\n\003NEW\020\001\022\016\n\nNEW_SAV",
      "ING\020\002\022\r\n\tSUBMITTED\020\003\022\014\n\010ACCEPTED\020\004\022\013\n\007RU" +
      "NNING\020\005\022\014\n\010FINISHED\020\006\022\n\n\006FAILED\020\007\022\n\n\006KIL" +
      "LED\020\010*\302\002\n YarnApplicationAttemptStatePro" +
      "to\022\023\n\017APP_ATTEMPT_NEW\020\001\022\031\n\025APP_ATTEMPT_S" +
      "UBMITTED\020\002\022\031\n\025APP_ATTEMPT_SCHEDULED\020\003\022 \n" +
      "\034APP_ATTEMPT_ALLOCATED_SAVING\020\004\022\031\n\025APP_A" +
      "TTEMPT_ALLOCATED\020\005\022\030\n\024APP_ATTEMPT_LAUNCH" +
      "ED\020\006\022\026\n\022APP_ATTEMPT_FAILED\020\007\022\027\n\023APP_ATTE" +
      "MPT_RUNNING\020\010\022\031\n\025APP_ATTEMPT_FINISHING\020\t" +
      "\022\030\n\024APP_ATTEMPT_FINISHED\020\n\022\026\n\022APP_ATTEMP",
      "T_KILLED\020\013*r\n\033FinalApplicationStatusProt" +
      "o\022\021\n\rAPP_UNDEFINED\020\000\022\021\n\rAPP_SUCCEEDED\020\001\022" +
      "\016\n\nAPP_FAILED\020\002\022\016\n\nAPP_KILLED\020\003\022\r\n\tAPP_E" +
      "NDED\020\004*H\n\034LocalResourceVisibilityProto\022\n" +
      "\n\006PUBLIC\020\001\022\013\n\007PRIVATE\020\002\022\017\n\013APPLICATION\020\003" +
      "*<\n\026LocalResourceTypeProto\022\013\n\007ARCHIVE\020\001\022" +
      "\010\n\004FILE\020\002\022\013\n\007PATTERN\020\003*\244\001\n\031LogAggregatio" +
      "nStatusProto\022\020\n\014LOG_DISABLED\020\001\022\021\n\rLOG_NO" +
      "T_START\020\002\022\017\n\013LOG_RUNNING\020\003\022\021\n\rLOG_SUCCEE" +
      "DED\020\004\022\016\n\nLOG_FAILED\020\005\022\020\n\014LOG_TIME_OUT\020\006\022",
      "\034\n\030LOG_RUNNING_WITH_FAILURE\020\007*\234\001\n\016NodeSt" +
      "ateProto\022\n\n\006NS_NEW\020\001\022\016\n\nNS_RUNNING\020\002\022\020\n\014" +
      "NS_UNHEALTHY\020\003\022\025\n\021NS_DECOMMISSIONED\020\004\022\013\n" +
      "\007NS_LOST\020\005\022\017\n\013NS_REBOOTED\020\006\022\026\n\022NS_DECOMM" +
      "ISSIONING\020\007\022\017\n\013NS_SHUTDOWN\020\010*6\n\022Containe" +
      "rTypeProto\022\026\n\022APPLICATION_MASTER\020\001\022\010\n\004TA" +
      "SK\020\002*7\n\022ExecutionTypeProto\022\016\n\nGUARANTEED" +
      "\020\001\022\021\n\rOPPORTUNISTIC\020\002*0\n\016AMCommandProto\022" +
      "\r\n\tAM_RESYNC\020\001\022\017\n\013AM_SHUTDOWN\020\002*7\n\033Appli" +
      "cationTimeoutTypeProto\022\030\n\024APP_TIMEOUT_LI",
      "FETIME\020\001*N\n\032ApplicationAccessTypeProto\022\026" +
      "\n\022APPACCESS_VIEW_APP\020\001\022\030\n\024APPACCESS_MODI" +
      "FY_APP\020\002*?\n\017QueueStateProto\022\r\n\tQ_STOPPED" +
      "\020\001\022\r\n\tQ_RUNNING\020\002\022\016\n\nQ_DRAINING\020\003*H\n\rQue" +
      "ueACLProto\022\034\n\030QACL_SUBMIT_APPLICATIONS\020\001" +
      "\022\031\n\025QACL_ADMINISTER_QUEUE\020\002*c\n\033SignalCon" +
      "tainerCommandProto\022\026\n\022OUTPUT_THREAD_DUMP" +
      "\020\001\022\025\n\021GRACEFUL_SHUTDOWN\020\002\022\025\n\021FORCEFUL_SH" +
      "UTDOWN\020\003*[\n\"ReservationRequestInterprete" +
      "rProto\022\t\n\005R_ANY\020\000\022\t\n\005R_ALL\020\001\022\013\n\007R_ORDER\020",
      "\002\022\022\n\016R_ORDER_NO_GAP\020\003*n\n\030ContainerExitSt" +
      "atusProto\022\013\n\007SUCCESS\020\000\022\024\n\007INVALID\020\230\370\377\377\377\377" +
      "\377\377\377\001\022\024\n\007ABORTED\020\234\377\377\377\377\377\377\377\377\001\022\031\n\014DISKS_FAIL" +
      "ED\020\233\377\377\377\377\377\377\377\377\001*h\n\031ContainerRetryPolicyPro" +
      "to\022\017\n\013NEVER_RETRY\020\000\022\027\n\023RETRY_ON_ALL_ERRO" +
      "RS\020\001\022!\n\035RETRY_ON_SPECIFIC_ERROR_CODES\020\002B" +
      "0\n\034org.apache.hadoop.yarn.protoB\nYarnPro" +
      "tos\210\001\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_hadoop_yarn_SerializedExceptionProto_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_SerializedExceptionProto_descriptor,
              new java.lang.String[] { "Message", "Trace", "ClassName", "Cause", });
          internal_static_hadoop_yarn_ApplicationIdProto_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationIdProto_descriptor,
              new java.lang.String[] { "Id", "ClusterTimestamp", });
          internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor,
              new java.lang.String[] { "ApplicationId", "AttemptId", });
          internal_static_hadoop_yarn_ContainerIdProto_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerIdProto_descriptor,
              new java.lang.String[] { "AppId", "AppAttemptId", "Id", });
          internal_static_hadoop_yarn_ResourceProto_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ResourceProto_descriptor,
              new java.lang.String[] { "Memory", "VirtualCores", });
          internal_static_hadoop_yarn_ResourceUtilizationProto_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_hadoop_yarn_ResourceUtilizationProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ResourceUtilizationProto_descriptor,
              new java.lang.String[] { "Pmem", "Vmem", "Cpu", });
          internal_static_hadoop_yarn_ResourceOptionProto_descriptor =
            getDescriptor().getMessageTypes().get(6);
          internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ResourceOptionProto_descriptor,
              new java.lang.String[] { "Resource", "OverCommitTimeout", });
          internal_static_hadoop_yarn_NodeResourceMapProto_descriptor =
            getDescriptor().getMessageTypes().get(7);
          internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeResourceMapProto_descriptor,
              new java.lang.String[] { "NodeId", "ResourceOption", });
          internal_static_hadoop_yarn_PriorityProto_descriptor =
            getDescriptor().getMessageTypes().get(8);
          internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_PriorityProto_descriptor,
              new java.lang.String[] { "Priority", });
          internal_static_hadoop_yarn_ContainerProto_descriptor =
            getDescriptor().getMessageTypes().get(9);
          internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerProto_descriptor,
              new java.lang.String[] { "Id", "NodeId", "NodeHttpAddress", "Resource", "Priority", "ContainerToken", "ExecutionType", "AllocationRequestId", "Version", });
          internal_static_hadoop_yarn_ContainerReportProto_descriptor =
            getDescriptor().getMessageTypes().get(10);
          internal_static_hadoop_yarn_ContainerReportProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerReportProto_descriptor,
              new java.lang.String[] { "ContainerId", "Resource", "NodeId", "Priority", "CreationTime", "FinishTime", "DiagnosticsInfo", "LogUrl", "ContainerExitStatus", "ContainerState", "NodeHttpAddress", "ExecutionType", });
          internal_static_hadoop_yarn_URLProto_descriptor =
            getDescriptor().getMessageTypes().get(11);
          internal_static_hadoop_yarn_URLProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_URLProto_descriptor,
              new java.lang.String[] { "Scheme", "Host", "Port", "File", "UserInfo", });
          internal_static_hadoop_yarn_LocalResourceProto_descriptor =
            getDescriptor().getMessageTypes().get(12);
          internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_LocalResourceProto_descriptor,
              new java.lang.String[] { "Resource", "Size", "Timestamp", "Type", "Visibility", "Pattern", "ShouldBeUploadedToSharedCache", });
          internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor =
            getDescriptor().getMessageTypes().get(13);
          internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor,
              new java.lang.String[] { "NumUsedContainers", "NumReservedContainers", "UsedResources", "ReservedResources", "NeededResources", "MemorySeconds", "VcoreSeconds", "QueueUsagePercentage", "ClusterUsagePercentage", "PreemptedMemorySeconds", "PreemptedVcoreSeconds", });
          internal_static_hadoop_yarn_ApplicationReportProto_descriptor =
            getDescriptor().getMessageTypes().get(14);
          internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationReportProto_descriptor,
              new java.lang.String[] { "ApplicationId", "User", "Queue", "Name", "Host", "RpcPort", "ClientToAmToken", "YarnApplicationState", "TrackingUrl", "Diagnostics", "StartTime", "FinishTime", "FinalApplicationStatus", "AppResourceUsage", "OriginalTrackingUrl", "CurrentApplicationAttemptId", "Progress", "ApplicationType", "AmRmToken", "ApplicationTags", "LogAggregationStatus", "UnmanagedApplication", "Priority", "AppNodeLabelExpression", "AmNodeLabelExpression", "AppTimeouts", });
          internal_static_hadoop_yarn_AppTimeoutsMapProto_descriptor =
            getDescriptor().getMessageTypes().get(15);
          internal_static_hadoop_yarn_AppTimeoutsMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_AppTimeoutsMapProto_descriptor,
              new java.lang.String[] { "ApplicationTimeoutType", "ApplicationTimeout", });
          internal_static_hadoop_yarn_ApplicationTimeoutProto_descriptor =
            getDescriptor().getMessageTypes().get(16);
          internal_static_hadoop_yarn_ApplicationTimeoutProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationTimeoutProto_descriptor,
              new java.lang.String[] { "ApplicationTimeoutType", "ExpireTime", "RemainingTime", });
          internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor =
            getDescriptor().getMessageTypes().get(17);
          internal_static_hadoop_yarn_ApplicationAttemptReportProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor,
              new java.lang.String[] { "ApplicationAttemptId", "Host", "RpcPort", "TrackingUrl", "Diagnostics", "YarnApplicationAttemptState", "AmContainerId", "OriginalTrackingUrl", "StartTime", "FinishTime", });
          internal_static_hadoop_yarn_NodeIdProto_descriptor =
            getDescriptor().getMessageTypes().get(18);
          internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeIdProto_descriptor,
              new java.lang.String[] { "Host", "Port", });
          internal_static_hadoop_yarn_NodeReportProto_descriptor =
            getDescriptor().getMessageTypes().get(19);
          internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeReportProto_descriptor,
              new java.lang.String[] { "NodeId", "HttpAddress", "RackName", "Used", "Capability", "NumContainers", "NodeState", "HealthReport", "LastHealthReportTime", "NodeLabels", "ContainersUtilization", "NodeUtilization", });
          internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor =
            getDescriptor().getMessageTypes().get(20);
          internal_static_hadoop_yarn_NodeIdToLabelsProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor,
              new java.lang.String[] { "NodeId", "NodeLabels", });
          internal_static_hadoop_yarn_LabelsToNodeIdsProto_descriptor =
            getDescriptor().getMessageTypes().get(21);
          internal_static_hadoop_yarn_LabelsToNodeIdsProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_LabelsToNodeIdsProto_descriptor,
              new java.lang.String[] { "NodeLabels", "NodeId", });
          internal_static_hadoop_yarn_NodeLabelProto_descriptor =
            getDescriptor().getMessageTypes().get(22);
          internal_static_hadoop_yarn_NodeLabelProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeLabelProto_descriptor,
              new java.lang.String[] { "Name", "IsExclusive", });
          internal_static_hadoop_yarn_AMBlackListingRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(23);
          internal_static_hadoop_yarn_AMBlackListingRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_AMBlackListingRequestProto_descriptor,
              new java.lang.String[] { "BlacklistingEnabled", "BlacklistingFailureThreshold", });
          internal_static_hadoop_yarn_ResourceRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(24);
          internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ResourceRequestProto_descriptor,
              new java.lang.String[] { "Priority", "ResourceName", "Capability", "NumContainers", "RelaxLocality", "NodeLabelExpression", "ExecutionTypeRequest", "AllocationRequestId", });
          internal_static_hadoop_yarn_ExecutionTypeRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(25);
          internal_static_hadoop_yarn_ExecutionTypeRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ExecutionTypeRequestProto_descriptor,
              new java.lang.String[] { "ExecutionType", "EnforceExecutionType", });
          internal_static_hadoop_yarn_PreemptionMessageProto_descriptor =
            getDescriptor().getMessageTypes().get(26);
          internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_PreemptionMessageProto_descriptor,
              new java.lang.String[] { "StrictContract", "Contract", });
          internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor =
            getDescriptor().getMessageTypes().get(27);
          internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor,
              new java.lang.String[] { "Container", });
          internal_static_hadoop_yarn_PreemptionContractProto_descriptor =
            getDescriptor().getMessageTypes().get(28);
          internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_PreemptionContractProto_descriptor,
              new java.lang.String[] { "Resource", "Container", });
          internal_static_hadoop_yarn_PreemptionContainerProto_descriptor =
            getDescriptor().getMessageTypes().get(29);
          internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_PreemptionContainerProto_descriptor,
              new java.lang.String[] { "Id", });
          internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(30);
          internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor,
              new java.lang.String[] { "Resource", });
          internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(31);
          internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor,
              new java.lang.String[] { "BlacklistAdditions", "BlacklistRemovals", });
          internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor =
            getDescriptor().getMessageTypes().get(32);
          internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor,
              new java.lang.String[] { "ApplicationId", "ApplicationName", "Queue", "Priority", "AmContainerSpec", "CancelTokensWhenComplete", "UnmanagedAm", "MaxAppAttempts", "Resource", "ApplicationType", "KeepContainersAcrossApplicationAttempts", "ApplicationTags", "AttemptFailuresValidityInterval", "LogAggregationContext", "ReservationId", "NodeLabelExpression", "AmContainerResourceRequest", "ApplicationTimeouts", });
          internal_static_hadoop_yarn_ApplicationTimeoutMapProto_descriptor =
            getDescriptor().getMessageTypes().get(33);
          internal_static_hadoop_yarn_ApplicationTimeoutMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationTimeoutMapProto_descriptor,
              new java.lang.String[] { "ApplicationTimeoutType", "Timeout", });
          internal_static_hadoop_yarn_ApplicationUpdateTimeoutMapProto_descriptor =
            getDescriptor().getMessageTypes().get(34);
          internal_static_hadoop_yarn_ApplicationUpdateTimeoutMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationUpdateTimeoutMapProto_descriptor,
              new java.lang.String[] { "ApplicationTimeoutType", "ExpireTime", });
          internal_static_hadoop_yarn_LogAggregationContextProto_descriptor =
            getDescriptor().getMessageTypes().get(35);
          internal_static_hadoop_yarn_LogAggregationContextProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_LogAggregationContextProto_descriptor,
              new java.lang.String[] { "IncludePattern", "ExcludePattern", "RolledLogsIncludePattern", "RolledLogsExcludePattern", "LogAggregationPolicyClassName", "LogAggregationPolicyParameters", });
          internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor =
            getDescriptor().getMessageTypes().get(36);
          internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor,
              new java.lang.String[] { "AccessType", "Acl", });
          internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor =
            getDescriptor().getMessageTypes().get(37);
          internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor,
              new java.lang.String[] { "NumNodeManagers", "NumDecommissionedNms", "NumActiveNms", "NumLostNms", "NumUnhealthyNms", "NumRebootedNms", });
          internal_static_hadoop_yarn_QueueStatisticsProto_descriptor =
            getDescriptor().getMessageTypes().get(38);
          internal_static_hadoop_yarn_QueueStatisticsProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_QueueStatisticsProto_descriptor,
              new java.lang.String[] { "NumAppsSubmitted", "NumAppsRunning", "NumAppsPending", "NumAppsCompleted", "NumAppsKilled", "NumAppsFailed", "NumActiveUsers", "AvailableMemoryMB", "AllocatedMemoryMB", "PendingMemoryMB", "ReservedMemoryMB", "AvailableVCores", "AllocatedVCores", "PendingVCores", "ReservedVCores", "AllocatedContainers", "PendingContainers", "ReservedContainers", });
          internal_static_hadoop_yarn_QueueInfoProto_descriptor =
            getDescriptor().getMessageTypes().get(39);
          internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_QueueInfoProto_descriptor,
              new java.lang.String[] { "QueueName", "Capacity", "MaximumCapacity", "CurrentCapacity", "State", "ChildQueues", "Applications", "AccessibleNodeLabels", "DefaultNodeLabelExpression", "QueueStatistics", "PreemptionDisabled", "QueueConfigurationsMap", "IntraQueuePreemptionDisabled", });
          internal_static_hadoop_yarn_QueueConfigurationsProto_descriptor =
            getDescriptor().getMessageTypes().get(40);
          internal_static_hadoop_yarn_QueueConfigurationsProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_QueueConfigurationsProto_descriptor,
              new java.lang.String[] { "Capacity", "AbsoluteCapacity", "MaxCapacity", "AbsoluteMaxCapacity", "MaxAMPercentage", });
          internal_static_hadoop_yarn_QueueConfigurationsMapProto_descriptor =
            getDescriptor().getMessageTypes().get(41);
          internal_static_hadoop_yarn_QueueConfigurationsMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_QueueConfigurationsMapProto_descriptor,
              new java.lang.String[] { "PartitionName", "QueueConfigurations", });
          internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor =
            getDescriptor().getMessageTypes().get(42);
          internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor,
              new java.lang.String[] { "QueueName", "UserAcls", });
          internal_static_hadoop_yarn_ReservationIdProto_descriptor =
            getDescriptor().getMessageTypes().get(43);
          internal_static_hadoop_yarn_ReservationIdProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ReservationIdProto_descriptor,
              new java.lang.String[] { "Id", "ClusterTimestamp", });
          internal_static_hadoop_yarn_ReservationRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(44);
          internal_static_hadoop_yarn_ReservationRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ReservationRequestProto_descriptor,
              new java.lang.String[] { "Capability", "NumContainers", "Concurrency", "Duration", });
          internal_static_hadoop_yarn_ReservationRequestsProto_descriptor =
            getDescriptor().getMessageTypes().get(45);
          internal_static_hadoop_yarn_ReservationRequestsProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ReservationRequestsProto_descriptor,
              new java.lang.String[] { "ReservationResources", "Interpreter", });
          internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor =
            getDescriptor().getMessageTypes().get(46);
          internal_static_hadoop_yarn_ReservationDefinitionProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor,
              new java.lang.String[] { "ReservationRequests", "Arrival", "Deadline", "ReservationName", "RecurrenceExpression", "Priority", });
          internal_static_hadoop_yarn_ResourceAllocationRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(47);
          internal_static_hadoop_yarn_ResourceAllocationRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ResourceAllocationRequestProto_descriptor,
              new java.lang.String[] { "StartTime", "EndTime", "Resource", });
          internal_static_hadoop_yarn_ReservationAllocationStateProto_descriptor =
            getDescriptor().getMessageTypes().get(48);
          internal_static_hadoop_yarn_ReservationAllocationStateProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ReservationAllocationStateProto_descriptor,
              new java.lang.String[] { "ReservationDefinition", "AllocationRequests", "StartTime", "EndTime", "User", "ContainsGangs", "AcceptanceTime", "ReservationId", });
          internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor =
            getDescriptor().getMessageTypes().get(49);
          internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor,
              new java.lang.String[] { "LocalResources", "Tokens", "ServiceData", "Environment", "Command", "ApplicationACLs", "ContainerRetryContext", "TokensConf", });
          internal_static_hadoop_yarn_ContainerStatusProto_descriptor =
            getDescriptor().getMessageTypes().get(50);
          internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerStatusProto_descriptor,
              new java.lang.String[] { "ContainerId", "State", "Diagnostics", "ExitStatus", "Capability", "ExecutionType", "ContainerAttributes", "ContainerSubState", });
          internal_static_hadoop_yarn_ContainerRetryContextProto_descriptor =
            getDescriptor().getMessageTypes().get(51);
          internal_static_hadoop_yarn_ContainerRetryContextProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerRetryContextProto_descriptor,
              new java.lang.String[] { "RetryPolicy", "ErrorCodes", "MaxRetries", "RetryInterval", });
          internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor =
            getDescriptor().getMessageTypes().get(52);
          internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor,
              new java.lang.String[] { "Key", "Value", });
          internal_static_hadoop_yarn_StringStringMapProto_descriptor =
            getDescriptor().getMessageTypes().get(53);
          internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_StringStringMapProto_descriptor,
              new java.lang.String[] { "Key", "Value", });
          internal_static_hadoop_yarn_StringBytesMapProto_descriptor =
            getDescriptor().getMessageTypes().get(54);
          internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_StringBytesMapProto_descriptor,
              new java.lang.String[] { "Key", "Value", });
          internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(55);
          internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor,
              new java.lang.String[] { "ContainerId", "Capability", });
          internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor =
            getDescriptor().getMessageTypes().get(56);
          internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor,
              new java.lang.String[] { "ContainerId", "Capability", "ContainerToken", });
          internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor =
            getDescriptor().getMessageTypes().get(57);
          internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor,
              new java.lang.String[] { "ContainerId", "Capability", });
          internal_static_hadoop_yarn_CollectorInfoProto_descriptor =
            getDescriptor().getMessageTypes().get(58);
          internal_static_hadoop_yarn_CollectorInfoProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_CollectorInfoProto_descriptor,
              new java.lang.String[] { "CollectorAddr", "CollectorToken", });
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.security.proto.SecurityProtos.getDescriptor(),
        }, assigner);
  }

  // @@protoc_insertion_point(outer_class_scope)
}
